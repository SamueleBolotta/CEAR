{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "GSDYVWHWm8CR",
   "metadata": {
    "id": "GSDYVWHWm8CR"
   },
   "source": [
    "# Natural Language Processing: Approccio Classico e Deep Learning\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "Il **Natural Language Processing (NLP)** e' il campo dell'AI che\n",
    "permette ai computer di comprendere, interpretare e generare\n",
    "linguaggio umano.\n",
    "\n",
    "### Applicazioni NLP\n",
    "\n",
    "- **Analisi sentiment**: opinioni su prodotti, brand\n",
    "- **Chatbot e assistenti virtuali**: Siri, Alexa, ChatGPT\n",
    "- **Traduzione automatica**: Google Translate\n",
    "- **Summarization**: riassunti automatici\n",
    "- **Named Entity Recognition**: estrazione nomi, luoghi, organizzazioni\n",
    "- **Question Answering**: sistemi di Q&A\n",
    "- **Text generation**: scrittura creativa, code generation\n",
    "\n",
    "### Evoluzione NLP\n",
    "\n",
    "```\n",
    "1950s: Regole linguistiche manuali\n",
    "1990s: Statistical NLP (n-grams, HMM)\n",
    "2013:  Word2Vec (embeddings)\n",
    "2017:  Transformers (Attention is All You Need)\n",
    "2018:  BERT (bidirectional pre-training)\n",
    "2020:  GPT-3 (175B parametri)\n",
    "2022:  ChatGPT (conversational AI)\n",
    "2023+: LLM multimodali (GPT-4, Claude)\n",
    "```\n",
    "\n",
    "### Sfide del NLP\n",
    "\n",
    "1. **Ambiguita'**: \"Il pollo e' pronto da mangiare\" (chi mangia?)\n",
    "2. **Contesto**: \"Fa freddo qui\" (temperatura o atmosfera?)\n",
    "3. **Idiomi e sarcasmo**: \"Che bella giornata!\" (sotto la pioggia)\n",
    "4. **Variabilita' linguistica**: dialetti, slang, errori\n",
    "5. **Conoscenza del mondo**: richiede common sense\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nyC1TsMXm8CZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:33.707769Z",
     "iopub.status.busy": "2026-02-20T20:56:33.707555Z",
     "iopub.status.idle": "2026-02-20T20:56:37.646508Z",
     "shell.execute_reply": "2026-02-20T20:56:37.643672Z"
    },
    "executionInfo": {
     "elapsed": 31569,
     "status": "ok",
     "timestamp": 1771617166041,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "nyC1TsMXm8CZ",
    "outputId": "1f74027f-747d-4d94-f90d-06b3de5a24f2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLP librerie\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfVectorizer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "\n",
    "# Download NLTK data\n",
    "for resource in [\n",
    "    'punkt', 'stopwords', 'wordnet',\n",
    "    'punkt_tab', 'omw-1.4',\n",
    "]:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Setup completato\")\n",
    "\n",
    "import os, urllib.request, joblib\n",
    "\n",
    "# GitHub Release URL for pretrained weights (update with actual URL)\n",
    "WEIGHTS_BASE_URL = os.environ.get('WEIGHTS_URL', '')\n",
    "WEIGHTS_DIR = 'pretrained_weights'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "def load_or_train(model, train_fn, weights_filename, device='cpu'):\n",
    "    \"\"\"Load pretrained weights if available, otherwise train and save.\"\"\"\n",
    "    weights_path = os.path.join(WEIGHTS_DIR, weights_filename)\n",
    "    if os.path.exists(weights_path):\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "        print(f\"Loaded pretrained weights from {weights_path}\")\n",
    "        return None\n",
    "    elif WEIGHTS_BASE_URL:\n",
    "        try:\n",
    "            url = WEIGHTS_BASE_URL + weights_filename\n",
    "            urllib.request.urlretrieve(url, weights_path)\n",
    "            model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "            print(f\"Downloaded and loaded weights from {url}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download weights: {e}. Training from scratch...\")\n",
    "\n",
    "    history = train_fn()\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "    print(f\"Saved weights to {weights_path}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k-f4xZhIm8Ce",
   "metadata": {
    "id": "k-f4xZhIm8Ce"
   },
   "source": [
    "---\n",
    "\n",
    "# PARTE 1: NLP CLASSICO\n",
    "\n",
    "## 1. Preprocessing del Testo\n",
    "\n",
    "Il preprocessing e' fondamentale in NLP per standardizzare\n",
    "il testo.\n",
    "\n",
    "### 1.1 Operazioni Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "N-ai88Rkm8Cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:37.653587Z",
     "iopub.status.busy": "2026-02-20T20:56:37.652274Z",
     "iopub.status.idle": "2026-02-20T20:56:42.312784Z",
     "shell.execute_reply": "2026-02-20T20:56:42.310420Z"
    },
    "executionInfo": {
     "elapsed": 6695,
     "status": "ok",
     "timestamp": 1771617172741,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "N-ai88Rkm8Cf",
    "outputId": "2a803974-c71c-495a-e100-e5d15691fa85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testo originale:\n",
      "\n",
      "Natural Language Processing (NLP) e' FANTASTICO!\n",
      "Permette ai computer di comprendere il linguaggio umano.\n",
      "Nel 2023, i modelli come GPT-4 hanno rivoluzionato il campo.\n",
      "Email: info@example.com, URL: https://example.com\n",
      "\n",
      "Testo dopo preprocessing:\n",
      "natural language processing nlp fantastico permette computer comprendere linguaggio umano nel modelli come gpt hanno rivoluzionato campo email url\n",
      "\n",
      "Lunghezza originale: 28 parole\n",
      "Lunghezza processata: 19 parole\n"
     ]
    }
   ],
   "source": [
    "# Testo di esempio\n",
    "testo_esempio = \"\"\"\n",
    "Natural Language Processing (NLP) e' FANTASTICO!\n",
    "Permette ai computer di comprendere il linguaggio umano.\n",
    "Nel 2023, i modelli come GPT-4 hanno rivoluzionato il campo.\n",
    "Email: info@example.com, URL: https://example.com\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testo originale:\")\n",
    "print(testo_esempio)\n",
    "\n",
    "\n",
    "def preprocess_text(\n",
    "    text,\n",
    "    remove_stopwords=True,\n",
    "    apply_stemming=False,\n",
    "    apply_lemmatization=True,\n",
    "):\n",
    "    \"\"\"Pipeline completa di preprocessing.\"\"\"\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Rimozione URL\n",
    "    text = re.sub(\n",
    "        r'http\\S+|www\\S+|https\\S+', '',\n",
    "        text, flags=re.MULTILINE,\n",
    "    )\n",
    "\n",
    "    # 3. Rimozione email\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # 4. Rimozione menzioni e hashtag (social media)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "\n",
    "    # 5. Rimozione numeri\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # 6. Rimozione punteggiatura\n",
    "    text = text.translate(\n",
    "        str.maketrans('', '', string.punctuation)\n",
    "    )\n",
    "\n",
    "    # 7. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 8. Rimozione stopwords\n",
    "    if remove_stopwords:\n",
    "        # NB: using English stopwords - this pipeline is designed for English text\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [\n",
    "            w for w in tokens if w not in stop_words\n",
    "        ]\n",
    "\n",
    "    # 9. Stemming o Lemmatization\n",
    "    if apply_stemming:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(w) for w in tokens]\n",
    "    elif apply_lemmatization:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "    # 10. Rimozione token troppo corti\n",
    "    tokens = [w for w in tokens if len(w) > 2]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Test\n",
    "testo_processato = preprocess_text(testo_esempio)\n",
    "print(\"Testo dopo preprocessing:\")\n",
    "print(testo_processato)\n",
    "\n",
    "originale_len = len(testo_esempio.split())\n",
    "processato_len = len(testo_processato.split())\n",
    "print(f\"\\nLunghezza originale: {originale_len} parole\")\n",
    "print(f\"Lunghezza processata: {processato_len} parole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CgYTXf_Om8Cg",
   "metadata": {
    "id": "CgYTXf_Om8Cg"
   },
   "source": [
    "**Differenza Stemming vs Lemmatization:**\n",
    "\n",
    "- **Stemming**: taglia suffissi (veloce ma meno preciso)\n",
    "  - \"running\" -> \"run\"\n",
    "  - \"better\" -> \"better\" (non riconosce \"good\")\n",
    "- **Lemmatization**: trova la forma base dizionariale\n",
    "  (lento ma preciso, con il POS tag corretto)\n",
    "  - \"running\" -> \"run\"\n",
    "  - \"better\" -> \"good\"\n",
    "  - \"was\" -> \"be\"\n",
    "\n",
    "> **Nota**: WordNetLemmatizer richiede il POS tag corretto per\n",
    "> risultati accurati (default: noun). Senza il POS tag appropriato,\n",
    "> \"better\" non verra' lemmatizzato a \"good\".\n",
    "\n",
    "### 1.2 Dataset: IMDB Movie Reviews\n",
    "\n",
    "Useremo recensioni di film per sentiment analysis\n",
    "(positivo/negativo). Questo dataset sara' usato in tutto\n",
    "il notebook, sia nel tutorial che negli esercizi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gIG_GlxMm8Cg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:42.322816Z",
     "iopub.status.busy": "2026-02-20T20:56:42.322473Z",
     "iopub.status.idle": "2026-02-20T20:56:47.954038Z",
     "shell.execute_reply": "2026-02-20T20:56:47.953448Z"
    },
    "executionInfo": {
     "elapsed": 16106,
     "status": "ok",
     "timestamp": 1771617188853,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "gIG_GlxMm8Cg",
    "outputId": "0d8aaaab-e6f2-4ce2-dd40-cbc48b50b477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 25000\n",
      "Test samples: 25000\n",
      "\n",
      "Review 1 (Positiva):\n",
      "I dug out from my garage some old musicals and this is another one of my favorites. It was written by Jay Alan Lerner and directed by Vincent Minelli. It won two Academy Awards for Best Picture of 1951 and Best Screenplay. The story of an American painter in Paris who tries to make it big. Nina Foch is a sophisticated lady of means and is very interested in helping him, but soon finds she loves the guy. Meanwhile Gene Kelly falls for lovely damsel, Leslie Caron. His main dancing partner, and I m\n",
      "\n",
      "Sentiment: Positivo\n",
      "\n",
      "============================================================\n",
      "\n",
      "Review 2 (Negativa):\n",
      "Dumb is as dumb does, in this thoroughly uninteresting, supposed black comedy. Essentially what starts out as Chris Klein trying to maintain a low profile, eventually morphs into an uninspired version of \"The Three Amigos\", only without any laughs. In order for black comedy to work, it must be outrageous, which \"Play Dead\" is not. In order for black comedy to work, it cannot be mean spirited, which \"Play Dead\" is. What \"Play Dead\" really is, is a town full of nut jobs. Fred Dunst does however do\n",
      "\n",
      "Sentiment: Negativo\n",
      "\n",
      "Dataset: 25000 train, 25000 test\n",
      "Esempio: Dumb is as dumb does, in this thoroughly uninteresting, supposed black comedy. Essentially what starts out as Chris Klein trying to maintain a low profile, eventually morphs into an uninspired version...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset IMDB\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Carica IMDB da Hugging Face datasets\n",
    "imdb_dataset = load_dataset('imdb')\n",
    "\n",
    "X_train_text = np.array(imdb_dataset['train']['text'])\n",
    "y_train_imdb = np.array(imdb_dataset['train']['label'])\n",
    "X_test_text = np.array(imdb_dataset['test']['text'])\n",
    "y_test_imdb = np.array(imdb_dataset['test']['label'])\n",
    "\n",
    "# Shuffle training e test set (il dataset HuggingFace\n",
    "# e' ordinato per label, la versione Keras era shuffled)\n",
    "rng = np.random.RandomState(42)\n",
    "train_shuffle = rng.permutation(len(X_train_text))\n",
    "X_train_text = X_train_text[train_shuffle]\n",
    "y_train_imdb = y_train_imdb[train_shuffle]\n",
    "\n",
    "test_shuffle = rng.permutation(len(X_test_text))\n",
    "X_test_text = X_test_text[test_shuffle]\n",
    "y_test_imdb = y_test_imdb[test_shuffle]\n",
    "\n",
    "print(f\"Training samples: {len(X_train_text)}\")\n",
    "print(f\"Test samples: {len(X_test_text)}\")\n",
    "\n",
    "# Visualizza esempi\n",
    "print(\"\\nReview 1 (Positiva):\")\n",
    "pos_idx = np.where(y_train_imdb == 1)[0][0]\n",
    "print(X_train_text[pos_idx][:500])\n",
    "print(\n",
    "    f\"\\nSentiment: \"\n",
    "    f\"{'Positivo' if y_train_imdb[pos_idx] == 1 else 'Negativo'}\"\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Trova una review negativa\n",
    "neg_idx = np.where(y_train_imdb == 0)[0][0]\n",
    "print(\"Review 2 (Negativa):\")\n",
    "print(X_train_text[neg_idx][:500])\n",
    "print(\n",
    "    f\"\\nSentiment: \"\n",
    "    f\"{'Positivo' if y_train_imdb[neg_idx] == 1 else 'Negativo'}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset: {len(X_train_text)} train, \"\n",
    "      f\"{len(X_test_text)} test\")\n",
    "print(f\"Esempio: {X_train_text[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G5OHi8i-m8Ch",
   "metadata": {
    "id": "G5OHi8i-m8Ch"
   },
   "source": [
    "## Esercizio 1\n",
    "\n",
    "**Task**: Implementare una pipeline di preprocessing\n",
    "e confrontare stemming vs lemmatization su review IMDB reali.\n",
    "Analizzare l'impatto del preprocessing sul vocabolario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "RMlLUZrbm8Ch",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:47.958973Z",
     "iopub.status.busy": "2026-02-20T20:56:47.958588Z",
     "iopub.status.idle": "2026-02-20T20:56:48.858735Z",
     "shell.execute_reply": "2026-02-20T20:56:48.857089Z"
    },
    "executionInfo": {
     "elapsed": 2973,
     "status": "ok",
     "timestamp": 1771617191833,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "RMlLUZrbm8Ch",
    "outputId": "59c21bf8-dcc1-4f4c-edea-6bdb8b65be2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esercizio 1 - Dataset: 200 review\n",
      "Distribuzione: pos=95, neg=105\n",
      "\n",
      "============================================================\n",
      "CONFRONTO METODI DI PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "RAW:\n",
      "  Vocabolario: 7280 parole uniche\n",
      "  Token totali: 22429\n",
      "  Esempio: dumb dumb thoroughly uninteresting supposed black comedy essentially starts chri...\n",
      "\n",
      "STEM:\n",
      "  Vocabolario: 5625 parole uniche\n",
      "  Token totali: 22429\n",
      "  Esempio: dumb dumb thoroughli uninterest suppos black comedi essenti start chri klein tri...\n",
      "\n",
      "LEMMA:\n",
      "  Vocabolario: 6689 parole uniche\n",
      "  Token totali: 22429\n",
      "  Esempio: dumb dumb thoroughly uninteresting supposed black comedy essentially start chris...\n",
      "\n",
      "============================================================\n",
      "CONFRONTO SU STESSA REVIEW\n",
      "============================================================\n",
      "\n",
      "Originale: Dumb is as dumb does, in this thoroughly uninteresting, supposed black comedy. Essentially what starts out as Chris Klein trying to maintain a low profile, eventually morphs into an uninspired version...\n",
      "RAW: dumb dumb thoroughly uninteresting supposed black comedy essentially starts chri...\n",
      "STEM: dumb dumb thoroughli uninterest suppos black comedi essenti start chri klein tri...\n",
      "LEMMA: dumb dumb thoroughly uninteresting supposed black comedy essentially start chris...\n",
      "\n",
      "============================================================\n",
      "RIDUZIONE VOCABOLARIO\n",
      "============================================================\n",
      "STEM: 5625 parole (-22.7% vs raw)\n",
      "LEMMA: 6689 parole (-8.1% vs raw)\n",
      "\n",
      "Esercizio 1 completato\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ESERCIZIO 1: Pipeline di Preprocessing\n",
    "# =========================================================\n",
    "# Variabili con prefisso ex1_ per evitare conflitti\n",
    "\n",
    "# Subset di 200 review IMDB per analisi preprocessing\n",
    "ex1_reviews = X_train_text[:200].copy()\n",
    "ex1_labels = y_train_imdb[:200].copy()\n",
    "\n",
    "print(f\"Esercizio 1 - Dataset: {len(ex1_reviews)} review\")\n",
    "print(f\"Distribuzione: \"\n",
    "      f\"pos={sum(ex1_labels==1)}, \"\n",
    "      f\"neg={sum(ex1_labels==0)}\")\n",
    "\n",
    "# Step 1: Funzioni di preprocessing specializzate\n",
    "ex1_stemmer = PorterStemmer()\n",
    "ex1_lemmatizer = WordNetLemmatizer()\n",
    "ex1_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def ex1_preprocess(text, method='lemma'):\n",
    "    \"\"\"\n",
    "    Preprocessing con scelta stemming/lemmatization.\n",
    "    method: 'raw', 'stem', 'lemma'\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(\n",
    "        str.maketrans('', '', string.punctuation)\n",
    "    )\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [\n",
    "        w for w in tokens\n",
    "        if w not in ex1_stop_words and len(w) > 2\n",
    "    ]\n",
    "\n",
    "    if method == 'stem':\n",
    "        tokens = [ex1_stemmer.stem(w) for w in tokens]\n",
    "    elif method == 'lemma':\n",
    "        tokens = [ex1_lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Step 2: Applica i 3 metodi e confronta\n",
    "ex1_methods = ['raw', 'stem', 'lemma']\n",
    "ex1_processed = {}\n",
    "\n",
    "for method in ex1_methods:\n",
    "    ex1_processed[method] = [\n",
    "        ex1_preprocess(r, method=method)\n",
    "        for r in ex1_reviews\n",
    "    ]\n",
    "\n",
    "# Step 3: Analisi vocabolario\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO METODI DI PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for method in ex1_methods:\n",
    "    all_words = ' '.join(ex1_processed[method]).split()\n",
    "    vocab = set(all_words)\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    print(f\"  Vocabolario: {len(vocab)} parole uniche\")\n",
    "    print(f\"  Token totali: {len(all_words)}\")\n",
    "    print(f\"  Esempio: {ex1_processed[method][0][:80]}...\")\n",
    "\n",
    "# Step 4: Confronto su stessa frase\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO SU STESSA REVIEW\")\n",
    "print(\"=\" * 60)\n",
    "ex1_sample = X_train_text[0][:200]\n",
    "print(f\"\\nOriginale: {ex1_sample}...\")\n",
    "for method in ex1_methods:\n",
    "    result = ex1_preprocess(ex1_sample, method=method)\n",
    "    print(f\"{method.upper()}: {result[:80]}...\")\n",
    "\n",
    "# Step 5: Riduzione vocabolario\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RIDUZIONE VOCABOLARIO\")\n",
    "print(\"=\" * 60)\n",
    "ex1_raw_vocab = len(\n",
    "    set(' '.join(ex1_processed['raw']).split())\n",
    ")\n",
    "for method in ['stem', 'lemma']:\n",
    "    method_vocab = len(\n",
    "        set(' '.join(ex1_processed[method]).split())\n",
    "    )\n",
    "    reduction = (\n",
    "        (ex1_raw_vocab - method_vocab) / ex1_raw_vocab * 100\n",
    "    )\n",
    "    print(\n",
    "        f\"{method.upper()}: {method_vocab} parole \"\n",
    "        f\"(-{reduction:.1f}% vs raw)\"\n",
    "    )\n",
    "\n",
    "print(\"\\nEsercizio 1 completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VwhQuV3Om8Ci",
   "metadata": {
    "id": "VwhQuV3Om8Ci"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Feature Extraction Classica\n",
    "\n",
    "### 2.1 Bag of Words (BOW)\n",
    "\n",
    "Rappresenta il testo come vettore di frequenze delle parole,\n",
    "ignorando ordine e grammatica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "YeBSlG5sm8Ci",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:48.861434Z",
     "iopub.status.busy": "2026-02-20T20:56:48.861204Z",
     "iopub.status.idle": "2026-02-20T20:56:48.874156Z",
     "shell.execute_reply": "2026-02-20T20:56:48.873495Z"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1771617191913,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "YeBSlG5sm8Ci",
    "outputId": "2d317ced-6596-4e88-ca28-605b74f7e98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Matrix:\n",
      "   great  hate  is  love  movie  this                 text\n",
      "0      0     0   0     1      1     1    I love this movie\n",
      "1      1     0   1     0      1     1  This movie is great\n",
      "2      0     1   0     0      1     1    I hate this movie\n"
     ]
    }
   ],
   "source": [
    "# Esempio semplice di BOW\n",
    "testi_esempio = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I hate this movie\",\n",
    "]\n",
    "\n",
    "# CountVectorizer per BOW\n",
    "vectorizer_bow = CountVectorizer()\n",
    "bow_matrix = vectorizer_bow.fit_transform(testi_esempio)\n",
    "\n",
    "# Visualizzazione\n",
    "vocab = vectorizer_bow.get_feature_names_out()\n",
    "bow_df = pd.DataFrame(\n",
    "    bow_matrix.toarray(), columns=vocab\n",
    ")\n",
    "bow_df['text'] = testi_esempio\n",
    "\n",
    "print(\"Bag of Words Matrix:\")\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1R4KfcgAm8Ci",
   "metadata": {
    "id": "1R4KfcgAm8Ci"
   },
   "source": [
    "### 2.2 TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "Pesa le parole in base a:\n",
    "\n",
    "- **TF**: frequenza nel documento\n",
    "- **IDF**: rarita' nel corpus\n",
    "\n",
    "Formula: $\\text{TF-IDF}(t, d) = TF(t, d) \\times IDF(t)$\n",
    "\n",
    "Dove: $IDF(t) = \\log\\frac{N}{df(t)}$\n",
    "\n",
    "> **Nota**: sklearn usa una variante smoothed:\n",
    "> $IDF(t) = \\log\\frac{1 + N}{1 + df(t)} + 1$\n",
    "\n",
    "Parole comuni (\"the\", \"is\") hanno IDF basso,\n",
    "parole rare hanno IDF alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "h_jJTJ-Vm8Ci",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:48.877547Z",
     "iopub.status.busy": "2026-02-20T20:56:48.877195Z",
     "iopub.status.idle": "2026-02-20T20:56:48.890749Z",
     "shell.execute_reply": "2026-02-20T20:56:48.889476Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1771617191956,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "h_jJTJ-Vm8Ci",
    "outputId": "bc908f47-5610-4086-f86a-26f0fcc621b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "      great      hate        is      love     movie      this  \\\n",
      "0  0.000000  0.000000  0.000000  0.767495  0.453295  0.453295   \n",
      "1  0.608845  0.000000  0.608845  0.000000  0.359594  0.359594   \n",
      "2  0.000000  0.767495  0.000000  0.000000  0.453295  0.453295   \n",
      "\n",
      "                  text  \n",
      "0    I love this movie  \n",
      "1  This movie is great  \n",
      "2    I hate this movie  \n",
      "\n",
      "Nota: parole comuni ('this', 'movie') hanno score piu' basso\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF sullo stesso esempio\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(testi_esempio)\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), columns=vectorizer_tfidf.get_feature_names_out()\n",
    ")\n",
    "tfidf_df['text'] = testi_esempio\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_df)\n",
    "\n",
    "print(\n",
    "    \"\\nNota: parole comuni ('this', 'movie') \"\n",
    "    \"hanno score piu' basso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UlC-tQ8fm8Cj",
   "metadata": {
    "id": "UlC-tQ8fm8Cj"
   },
   "source": [
    "### 2.3 Feature Extraction su IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oA4_UUOtm8Cj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:48.897666Z",
     "iopub.status.busy": "2026-02-20T20:56:48.897323Z",
     "iopub.status.idle": "2026-02-20T20:56:52.317151Z",
     "shell.execute_reply": "2026-02-20T20:56:52.316547Z"
    },
    "executionInfo": {
     "elapsed": 7506,
     "status": "ok",
     "timestamp": 1771617199464,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "oA4_UUOtm8Cj",
    "outputId": "9dbeee2b-918c-4f26-be79-3ab614b18ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrazione TF-IDF features...\n",
      "Shape training: (5000, 5000)\n",
      "Shape test: (1000, 5000)\n",
      "Numero features: 5000\n"
     ]
    }
   ],
   "source": [
    "# Usiamo subset per velocita'\n",
    "n_train_tfidf = 5000\n",
    "n_test_tfidf = 1000\n",
    "\n",
    "X_train_sub = X_train_text[:n_train_tfidf]\n",
    "y_train_sub = y_train_imdb[:n_train_tfidf]\n",
    "X_test_sub = X_test_text[:n_test_tfidf]\n",
    "y_test_sub = y_test_imdb[:n_test_tfidf]\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),   # Unigrams e bigrams\n",
    "    min_df=5,             # Min 5 documenti\n",
    "    max_df=0.8,           # Max 80% dei documenti\n",
    ")\n",
    "\n",
    "print(\"Estrazione TF-IDF features...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_sub)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_sub)\n",
    "\n",
    "print(f\"Shape training: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape test: {X_test_tfidf.shape}\")\n",
    "n_feats = len(tfidf_vectorizer.get_feature_names_out())\n",
    "print(f\"Numero features: {n_feats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJguF_Rvm8Cm",
   "metadata": {
    "id": "QJguF_Rvm8Cm"
   },
   "source": [
    "## Esercizio 2\n",
    "\n",
    "**Task**: Estrarre features con BOW e TF-IDF su review IMDB,\n",
    "confrontare le rappresentazioni e analizzare i termini\n",
    "piu' discriminativi per classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Ut21X3jCm8Cm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:52.319701Z",
     "iopub.status.busy": "2026-02-20T20:56:52.319416Z",
     "iopub.status.idle": "2026-02-20T20:56:54.722844Z",
     "shell.execute_reply": "2026-02-20T20:56:54.722151Z"
    },
    "executionInfo": {
     "elapsed": 3845,
     "status": "ok",
     "timestamp": 1771617203311,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "Ut21X3jCm8Cm",
    "outputId": "b8a5e4bb-9d3e-46d9-8eda-9f35ee602e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esercizio 2 - Train: 1600, Test: 400\n",
      "BOW shape: (1600, 3000)\n",
      "TF-IDF shape: (1600, 3000)\n",
      "\n",
      "Naive Bayes + BOW accuracy:    0.8250\n",
      "Naive Bayes + TF-IDF accuracy: 0.8325\n",
      "\n",
      "============================================================\n",
      "TOP 10 TERMINI PER CLASSE (TF-IDF + NB)\n",
      "============================================================\n",
      "\n",
      "NEGATIVO: the, and, br, of, to, it, is, this, in, that\n",
      "\n",
      "POSITIVO: the, and, of, br, to, is, it, in, this, that\n",
      "\n",
      "============================================================\n",
      "CONFRONTO DENSITA'\n",
      "============================================================\n",
      "BOW density:    4.85%\n",
      "TF-IDF density: 4.85%\n",
      "\n",
      "Esercizio 2 completato\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ESERCIZIO 2: Confronto BOW vs TF-IDF\n",
    "# =========================================================\n",
    "\n",
    "# Subset dedicato per l'esercizio\n",
    "ex2_n = 2000\n",
    "ex2_X_train, ex2_X_test, ex2_y_train, ex2_y_test = \\\n",
    "    train_test_split(\n",
    "        X_train_text[:ex2_n],\n",
    "        y_train_imdb[:ex2_n],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train_imdb[:ex2_n],\n",
    "    )\n",
    "\n",
    "print(f\"Esercizio 2 - Train: {len(ex2_X_train)}, \"\n",
    "      f\"Test: {len(ex2_X_test)}\")\n",
    "\n",
    "# Step 1: BOW features\n",
    "ex2_bow_vec = CountVectorizer(\n",
    "    max_features=3000, ngram_range=(1, 2),\n",
    ")\n",
    "ex2_X_train_bow = ex2_bow_vec.fit_transform(ex2_X_train)\n",
    "ex2_X_test_bow = ex2_bow_vec.transform(ex2_X_test)\n",
    "\n",
    "# Step 2: TF-IDF features\n",
    "ex2_tfidf_vec = TfidfVectorizer(\n",
    "    max_features=3000, ngram_range=(1, 2),\n",
    ")\n",
    "ex2_X_train_tfidf = ex2_tfidf_vec.fit_transform(ex2_X_train)\n",
    "ex2_X_test_tfidf = ex2_tfidf_vec.transform(ex2_X_test)\n",
    "\n",
    "print(f\"BOW shape: {ex2_X_train_bow.shape}\")\n",
    "print(f\"TF-IDF shape: {ex2_X_train_tfidf.shape}\")\n",
    "\n",
    "# Step 3: Train Naive Bayes con entrambi\n",
    "ex2_nb_bow = MultinomialNB()\n",
    "ex2_nb_bow.fit(ex2_X_train_bow, ex2_y_train)\n",
    "ex2_acc_bow = accuracy_score(\n",
    "    ex2_y_test,\n",
    "    ex2_nb_bow.predict(ex2_X_test_bow),\n",
    ")\n",
    "\n",
    "ex2_nb_tfidf = MultinomialNB()\n",
    "ex2_nb_tfidf.fit(ex2_X_train_tfidf, ex2_y_train)\n",
    "ex2_acc_tfidf = accuracy_score(\n",
    "    ex2_y_test,\n",
    "    ex2_nb_tfidf.predict(ex2_X_test_tfidf),\n",
    ")\n",
    "\n",
    "print(f\"\\nNaive Bayes + BOW accuracy:    {ex2_acc_bow:.4f}\")\n",
    "print(f\"Naive Bayes + TF-IDF accuracy: {ex2_acc_tfidf:.4f}\")\n",
    "\n",
    "# Step 4: Top features per classe (TF-IDF)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 10 TERMINI PER CLASSE (TF-IDF + NB)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ex2_feature_names = ex2_tfidf_vec.get_feature_names_out()\n",
    "ex2_log_prob = ex2_nb_tfidf.feature_log_prob_\n",
    "\n",
    "for cls, label in [(0, \"NEGATIVO\"), (1, \"POSITIVO\")]:\n",
    "    top_idx = np.argsort(ex2_log_prob[cls])[-10:][::-1]\n",
    "    top_words = [ex2_feature_names[i] for i in top_idx]\n",
    "    print(f\"\\n{label}: {', '.join(top_words)}\")\n",
    "\n",
    "# Step 5: Sparsity\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO DENSITA'\")\n",
    "print(\"=\" * 60)\n",
    "bow_dens = (\n",
    "    ex2_X_train_bow.nnz\n",
    "    / np.prod(ex2_X_train_bow.shape)\n",
    "    * 100\n",
    ")\n",
    "tfidf_dens = (\n",
    "    ex2_X_train_tfidf.nnz\n",
    "    / np.prod(ex2_X_train_tfidf.shape)\n",
    "    * 100\n",
    ")\n",
    "print(f\"BOW density:    {bow_dens:.2f}%\")\n",
    "print(f\"TF-IDF density: {tfidf_dens:.2f}%\")\n",
    "\n",
    "print(\"\\nEsercizio 2 completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KW1H5RMVm8Cm",
   "metadata": {
    "id": "KW1H5RMVm8Cm"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Classificazione con ML Classico\n",
    "\n",
    "### 3.1 Naive Bayes\n",
    "\n",
    "Algoritmo probabilistico basato sul teorema di Bayes,\n",
    "molto efficace per text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "-GvcUZFSm8Cm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:54.727543Z",
     "iopub.status.busy": "2026-02-20T20:56:54.727015Z",
     "iopub.status.idle": "2026-02-20T20:56:54.746356Z",
     "shell.execute_reply": "2026-02-20T20:56:54.745649Z"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1771617203339,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "-GvcUZFSm8Cm",
    "outputId": "8dac9bb0-8b0d-4c97-d70f-013597ba4a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8490\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.84      0.84       476\n",
      "    Positive       0.86      0.85      0.86       524\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes (sul dataset tutorial: 5000 train, 1000 test)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train_sub)\n",
    "\n",
    "y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "acc_nb = accuracy_score(y_test_sub, y_pred_nb)\n",
    "print(f\"Naive Bayes Accuracy: {acc_nb:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_sub, y_pred_nb,\n",
    "    target_names=['Negative', 'Positive'],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ok5bKHWsm8Cn",
   "metadata": {
    "id": "ok5bKHWsm8Cn"
   },
   "source": [
    "### 3.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Wq6mFUXXm8Cn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:54.751672Z",
     "iopub.status.busy": "2026-02-20T20:56:54.751405Z",
     "iopub.status.idle": "2026-02-20T20:56:54.827435Z",
     "shell.execute_reply": "2026-02-20T20:56:54.826759Z"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1771617203497,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "Wq6mFUXXm8Cn",
    "outputId": "b0f1bbb6-b340-4cf1-a84f-45a10e7100ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8600\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.83      0.85       476\n",
      "    Positive       0.85      0.88      0.87       524\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(\n",
    "    max_iter=1000, random_state=42,\n",
    ")\n",
    "lr_classifier.fit(X_train_tfidf, y_train_sub)\n",
    "\n",
    "y_pred_lr = lr_classifier.predict(X_test_tfidf)\n",
    "acc_lr = accuracy_score(y_test_sub, y_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_sub, y_pred_lr,\n",
    "    target_names=['Negative', 'Positive'],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tnCY2FiWm8Cn",
   "metadata": {
    "id": "tnCY2FiWm8Cn"
   },
   "source": [
    "### 3.3 Parole piu' importanti per sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3iHW7J7sm8Cn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:54.830416Z",
     "iopub.status.busy": "2026-02-20T20:56:54.830115Z",
     "iopub.status.idle": "2026-02-20T20:56:54.841630Z",
     "shell.execute_reply": "2026-02-20T20:56:54.841028Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1771617203522,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "3iHW7J7sm8Cn",
    "outputId": "7735fd96-dbaa-4025-ad67-3e44d6c583e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 parole POSITIVE:\n",
      "  great: 4.059\n",
      "  excellent: 2.910\n",
      "  best: 2.356\n",
      "  wonderful: 2.334\n",
      "  love: 2.287\n",
      "  fun: 2.261\n",
      "  today: 2.175\n",
      "  the best: 1.938\n",
      "  it is: 1.906\n",
      "  enjoyed: 1.863\n",
      "  amazing: 1.857\n",
      "  loved: 1.850\n",
      "  perfect: 1.727\n",
      "  also: 1.670\n",
      "  fantastic: 1.623\n",
      "\n",
      "Top 15 parole NEGATIVE:\n",
      "  bad: -4.991\n",
      "  worst: -4.263\n",
      "  the worst: -3.397\n",
      "  terrible: -2.656\n",
      "  nothing: -2.646\n",
      "  awful: -2.604\n",
      "  no: -2.576\n",
      "  poor: -2.475\n",
      "  waste: -2.465\n",
      "  boring: -2.462\n",
      "  even: -2.314\n",
      "  script: -2.239\n",
      "  worse: -2.142\n",
      "  stupid: -2.045\n",
      "  dull: -2.005\n"
     ]
    }
   ],
   "source": [
    "# Feature importance da Logistic Regression\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "coefficients = lr_classifier.coef_[0]\n",
    "\n",
    "# Top parole positive e negative\n",
    "top_positive_idx = np.argsort(coefficients)[-15:]\n",
    "top_negative_idx = np.argsort(coefficients)[:15]\n",
    "\n",
    "print(\"Top 15 parole POSITIVE:\")\n",
    "for idx in reversed(top_positive_idx):\n",
    "    print(\n",
    "        f\"  {feature_names[idx]}: \"\n",
    "        f\"{coefficients[idx]:.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTop 15 parole NEGATIVE:\")\n",
    "for idx in top_negative_idx:\n",
    "    print(\n",
    "        f\"  {feature_names[idx]}: \"\n",
    "        f\"{coefficients[idx]:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mWMmma54m8Co",
   "metadata": {
    "id": "mWMmma54m8Co"
   },
   "source": [
    "### 3.4 Test su nuove review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "E8u9KOscm8Cp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:54.844635Z",
     "iopub.status.busy": "2026-02-20T20:56:54.844397Z",
     "iopub.status.idle": "2026-02-20T20:56:54.853662Z",
     "shell.execute_reply": "2026-02-20T20:56:54.851192Z"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1771617203588,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "E8u9KOscm8Cp",
    "outputId": "9357da4d-3cca-4d20-944f-5699f483caf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni su nuove review:\n",
      "\n",
      "Review: This movie was absolutely fantastic! I loved every minute of...\n",
      "Sentiment: Positive (confidence: 0.728)\n",
      "\n",
      "Review: Terrible waste of time. The plot made no sense and acting wa...\n",
      "Sentiment: Negative (confidence: 0.978)\n",
      "\n",
      "Review: An okay movie, nothing special but not terrible either....\n",
      "Sentiment: Negative (confidence: 0.900)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_classical(\n",
    "    text, vectorizer, classifier\n",
    "):\n",
    "    \"\"\"Predice sentiment usando modello classico.\"\"\"\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    prediction = classifier.predict(text_vectorized)[0]\n",
    "    probability = classifier.predict_proba(\n",
    "        text_vectorized\n",
    "    )[0]\n",
    "    return {\n",
    "        'sentiment': (\n",
    "            'Positive' if prediction == 1 else 'Negative'\n",
    "        ),\n",
    "        'confidence': probability[prediction],\n",
    "    }\n",
    "\n",
    "\n",
    "test_reviews = [\n",
    "    (\n",
    "        \"This movie was absolutely fantastic! \"\n",
    "        \"I loved every minute of it.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Terrible waste of time. The plot made \"\n",
    "        \"no sense and acting was awful.\"\n",
    "    ),\n",
    "    (\n",
    "        \"An okay movie, nothing special \"\n",
    "        \"but not terrible either.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Predizioni su nuove review:\\n\")\n",
    "for review in test_reviews:\n",
    "    result = predict_sentiment_classical(\n",
    "        review, tfidf_vectorizer, lr_classifier,\n",
    "    )\n",
    "    print(f\"Review: {review[:60]}...\")\n",
    "    print(\n",
    "        f\"Sentiment: {result['sentiment']} \"\n",
    "        f\"(confidence: {result['confidence']:.3f})\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdPelAlDm8Cp",
   "metadata": {
    "id": "fdPelAlDm8Cp"
   },
   "source": [
    "## Esercizio 3\n",
    "\n",
    "**Task**: Trainare e confrontare 4 modelli ML classici\n",
    "(Naive Bayes, Logistic Regression, SVM, Random Forest)\n",
    "su review IMDB con TF-IDF features. Usare cross-validation\n",
    "per una valutazione robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ApfZTs2Sm8Cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:56:54.860455Z",
     "iopub.status.busy": "2026-02-20T20:56:54.860202Z",
     "iopub.status.idle": "2026-02-20T20:57:13.163299Z",
     "shell.execute_reply": "2026-02-20T20:57:13.162654Z"
    },
    "executionInfo": {
     "elapsed": 19769,
     "status": "ok",
     "timestamp": 1771617223352,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "ApfZTs2Sm8Cq",
    "outputId": "8fcb8149-719d-463d-e8b8-54bbd51b825c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esercizio 3 - Train: (2400, 5000), Test: (600, 5000)\n",
      "\n",
      "============================================================\n",
      "CONFRONTO MODELLI\n",
      "============================================================\n",
      "              model  test_accuracy  cv_mean   cv_std\n",
      "        Naive Bayes       0.848333 0.837917 0.013070\n",
      "         Linear SVM       0.840000 0.830833 0.017099\n",
      "Logistic Regression       0.830000 0.838750 0.018708\n",
      "      Random Forest       0.796667 0.797500 0.019158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT - Naive Bayes\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.87      0.86       311\n",
      "    Positive       0.86      0.82      0.84       289\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.85      0.85      0.85       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "Esercizio 3 completato\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ESERCIZIO 3: Confronto Modelli ML Classici\n",
    "# =========================================================\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Subset dedicato (3000 campioni per avere risultati\n",
    "# realistici ma non troppo lento)\n",
    "ex3_n = 3000\n",
    "ex3_X = X_train_text[:ex3_n]\n",
    "ex3_y = y_train_imdb[:ex3_n]\n",
    "\n",
    "# Split train/test\n",
    "ex3_X_train, ex3_X_test, ex3_y_train, ex3_y_test = \\\n",
    "    train_test_split(\n",
    "        ex3_X, ex3_y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=ex3_y,\n",
    "    )\n",
    "\n",
    "# TF-IDF features\n",
    "ex3_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, ngram_range=(1, 2),\n",
    "    min_df=3, max_df=0.85,\n",
    ")\n",
    "ex3_X_train_tfidf = ex3_vectorizer.fit_transform(\n",
    "    ex3_X_train\n",
    ")\n",
    "ex3_X_test_tfidf = ex3_vectorizer.transform(ex3_X_test)\n",
    "\n",
    "print(f\"Esercizio 3 - Train: {ex3_X_train_tfidf.shape}, \"\n",
    "      f\"Test: {ex3_X_test_tfidf.shape}\")\n",
    "\n",
    "# Step 1: Definizione modelli\n",
    "ex3_models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000, random_state=42,\n",
    "    ),\n",
    "    'Linear SVM': LinearSVC(\n",
    "        random_state=42, max_iter=2000,\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Step 2: Training e valutazione\n",
    "ex3_results = []\n",
    "for name, model in ex3_models.items():\n",
    "    # Train\n",
    "    model.fit(ex3_X_train_tfidf, ex3_y_train)\n",
    "\n",
    "    # Test accuracy\n",
    "    y_pred = model.predict(ex3_X_test_tfidf)\n",
    "    test_acc = accuracy_score(ex3_y_test, y_pred)\n",
    "\n",
    "    # Cross-validation (5-fold)\n",
    "    cv_scores = cross_val_score(\n",
    "        model, ex3_X_train_tfidf, ex3_y_train, cv=5,\n",
    "    )\n",
    "\n",
    "    ex3_results.append({\n",
    "        'model': name,\n",
    "        'test_accuracy': test_acc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "    })\n",
    "\n",
    "# Step 3: Risultati\n",
    "ex3_results_df = pd.DataFrame(ex3_results).sort_values(\n",
    "    'test_accuracy', ascending=False,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO MODELLI\")\n",
    "print(\"=\" * 60)\n",
    "print(ex3_results_df.to_string(index=False))\n",
    "\n",
    "# Step 4: Confusion matrix del miglior modello\n",
    "ex3_best_name = ex3_results_df.iloc[0]['model']\n",
    "ex3_best_model = ex3_models[ex3_best_name]\n",
    "ex3_y_pred_best = ex3_best_model.predict(ex3_X_test_tfidf)\n",
    "\n",
    "ex3_cm = confusion_matrix(ex3_y_test, ex3_y_pred_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    ex3_cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Negative', 'Positive'],\n",
    "    yticklabels=['Negative', 'Positive'],\n",
    ")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(f'Confusion Matrix - {ex3_best_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Report dettagliato\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"CLASSIFICATION REPORT - {ex3_best_name}\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(\n",
    "    ex3_y_test, ex3_y_pred_best,\n",
    "    target_names=['Negative', 'Positive'],\n",
    "))\n",
    "\n",
    "print(\"Esercizio 3 completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JOECEFtim8Cq",
   "metadata": {
    "id": "JOECEFtim8Cq"
   },
   "source": [
    "---\n",
    "\n",
    "# PARTE 2: NLP CON DEEP LEARNING\n",
    "\n",
    "## 4. Word Embeddings\n",
    "\n",
    "Gli **embeddings** rappresentano parole come vettori densi\n",
    "in uno spazio continuo, catturando semantica.\n",
    "\n",
    "### Proprieta':\n",
    "\n",
    "- Parole simili hanno vettori vicini\n",
    "- Operazioni vettoriali:\n",
    "  \"king\" - \"man\" + \"woman\" ~ \"queen\"\n",
    "- Dimensionalita' ridotta (50-300) vs one-hot\n",
    "\n",
    "### 4.1 Preparazione dati per Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Jz0_2n_Dm8Cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:13.170715Z",
     "iopub.status.busy": "2026-02-20T20:57:13.170188Z",
     "iopub.status.idle": "2026-02-20T20:57:16.281340Z",
     "shell.execute_reply": "2026-02-20T20:57:16.279930Z"
    },
    "executionInfo": {
     "elapsed": 6625,
     "status": "ok",
     "timestamp": 1771617229978,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "Jz0_2n_Dm8Cq",
    "outputId": "b60d8f58-1748-4b5b-a60c-56f8b2d43956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training padded: (5000, 200)\n",
      "Shape test padded: (1000, 200)\n",
      "Labels train: 5000\n",
      "Labels test: 1000\n",
      "Vocabolario: 9999 parole\n",
      "\n",
      "Esempio sequenza (prime 20):\n",
      "[   0    6   14 1244 3727    7   10 1501    0  369  426 1349    0   50\n",
      "  466   44   14 1472    0  247]\n"
     ]
    }
   ],
   "source": [
    "# Parametri Deep Learning\n",
    "DL_VOCAB_SIZE = 10000\n",
    "DL_MAX_LENGTH = 200\n",
    "DL_EMBEDDING_DIM = 100\n",
    "\n",
    "# Subset per Deep Learning\n",
    "DL_N_TRAIN = 5000\n",
    "DL_N_TEST = 1000\n",
    "\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    \"\"\"Tokenizer semplice che costruisce un vocabolario.\"\"\"\n",
    "\n",
    "    def __init__(self, num_words=10000):\n",
    "        self.num_words = num_words\n",
    "        self.word_index = {}\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(text.split())\n",
    "        most_common = counter.most_common(\n",
    "            self.num_words - 1\n",
    "        )\n",
    "        # Indice 0 riservato per padding\n",
    "        self.word_index = {\n",
    "            word: i + 1\n",
    "            for i, (word, _) in enumerate(most_common)\n",
    "        }\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        return [\n",
    "            [\n",
    "                self.word_index.get(w, 0)\n",
    "                for w in text.split()\n",
    "            ]\n",
    "            for text in texts\n",
    "        ]\n",
    "\n",
    "\n",
    "def pad_sequences_manual(sequences, maxlen, padding_value=0):\n",
    "    \"\"\"Padding manuale delle sequenze.\"\"\"\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        seq = seq[:maxlen]  # Truncate\n",
    "        seq = seq + [padding_value] * (maxlen - len(seq))  # Pad\n",
    "        padded.append(seq)\n",
    "    return np.array(padded)\n",
    "\n",
    "\n",
    "# Tokenizer (fit su tutto il training set)\n",
    "dl_tokenizer = SimpleTokenizer(\n",
    "    num_words=DL_VOCAB_SIZE,\n",
    ")\n",
    "dl_tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "# Converti in sequenze\n",
    "X_train_seq = dl_tokenizer.texts_to_sequences(\n",
    "    X_train_text[:DL_N_TRAIN]\n",
    ")\n",
    "X_test_seq = dl_tokenizer.texts_to_sequences(\n",
    "    X_test_text[:DL_N_TEST]\n",
    ")\n",
    "\n",
    "# Padding\n",
    "X_train_pad = pad_sequences_manual(\n",
    "    X_train_seq, maxlen=DL_MAX_LENGTH,\n",
    ")\n",
    "X_test_pad = pad_sequences_manual(\n",
    "    X_test_seq, maxlen=DL_MAX_LENGTH,\n",
    ")\n",
    "\n",
    "y_train_dl = y_train_imdb[:DL_N_TRAIN]\n",
    "y_test_dl = y_test_imdb[:DL_N_TEST]\n",
    "\n",
    "print(f\"Shape training padded: {X_train_pad.shape}\")\n",
    "print(f\"Shape test padded: {X_test_pad.shape}\")\n",
    "print(f\"Labels train: {len(y_train_dl)}\")\n",
    "print(f\"Labels test: {len(y_test_dl)}\")\n",
    "print(f\"Vocabolario: {len(dl_tokenizer.word_index)} parole\")\n",
    "print(f\"\\nEsempio sequenza (prime 20):\")\n",
    "print(X_train_pad[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o-iV6Ih-m8Cq",
   "metadata": {
    "id": "o-iV6Ih-m8Cq"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Recurrent Neural Networks (RNN)\n",
    "\n",
    "Le **RNN** processano sequenze mantenendo uno \"stato interno\"\n",
    "(memoria).\n",
    "\n",
    "### Architettura RNN:\n",
    "\n",
    "```\n",
    "Input: x1, x2, ..., xt\n",
    "       |   |        |\n",
    "     [RNN] -> [RNN] -> ... -> [RNN]\n",
    "       |       |               |\n",
    "      h1      h2              ht\n",
    "```\n",
    "\n",
    "Ogni cell riceve input corrente $x_t$ e stato precedente\n",
    "$h_{t-1}$, producendo $h_t = f(Wx_t + Uh_{t-1} + b)$.\n",
    "\n",
    "### Problema: Vanishing Gradient\n",
    "\n",
    "RNN semplici faticano con sequenze lunghe. **LSTM** e **GRU**\n",
    "risolvono questo problema.\n",
    "\n",
    "### 5.1 LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_AxjnfXvm8Cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:16.286005Z",
     "iopub.status.busy": "2026-02-20T20:57:16.285386Z",
     "iopub.status.idle": "2026-02-20T20:57:19.855758Z",
     "shell.execute_reply": "2026-02-20T20:57:19.855155Z"
    },
    "executionInfo": {
     "elapsed": 114115,
     "status": "ok",
     "timestamp": 1771617344092,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "_AxjnfXvm8Cq",
    "outputId": "2355061e-43ac-4cae-a23a-5982a4869852"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Modello LSTM per sentiment analysis.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_dim,\n",
    "        output_dim=1, dropout=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, epochs,\n",
    "    lr=0.001, patience=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Training loop PyTorch con early stopping.\n",
    "    Ritorna un dizionario history compatibile.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        'loss': [], 'val_loss': [],\n",
    "        'accuracy': [], 'val_accuracy': [],\n",
    "    }\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch).squeeze(-1)\n",
    "            loss = criterion(output, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            predicted = (torch.sigmoid(output) > 0.5).long()\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        train_loss /= total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                output = model(X_batch).squeeze(-1)\n",
    "                loss = criterion(\n",
    "                    output, y_batch.float(),\n",
    "                )\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "                predicted = (\n",
    "                    torch.sigmoid(output) > 0.5\n",
    "                ).long()\n",
    "                val_correct += (\n",
    "                    predicted == y_batch\n",
    "                ).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} - \"\n",
    "            f\"loss: {train_loss:.4f} - \"\n",
    "            f\"accuracy: {train_acc:.4f} - \"\n",
    "            f\"val_loss: {val_loss:.4f} - \"\n",
    "            f\"val_accuracy: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = {\n",
    "                k: v.cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\n",
    "                    f\"Early stopping at epoch {epoch+1}\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    # Restore best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        model.to(device)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Valuta accuracy su test set.\"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output = model(X_batch).squeeze(-1)\n",
    "            predicted = (\n",
    "                torch.sigmoid(output) > 0.5\n",
    "            ).long()\n",
    "            correct += (\n",
    "                predicted == y_batch\n",
    "            ).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def make_loaders(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    batch_size=128, val_split=0.2,\n",
    "):\n",
    "    \"\"\"Crea DataLoader per train, val e test.\"\"\"\n",
    "    n_val = int(len(X_train) * val_split)\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    val_idx = indices[:n_val]\n",
    "    train_idx = indices[n_val:]\n",
    "\n",
    "    X_tr = torch.LongTensor(X_train[train_idx])\n",
    "    y_tr = torch.LongTensor(y_train[train_idx])\n",
    "    X_val = torch.LongTensor(X_train[val_idx])\n",
    "    y_val = torch.LongTensor(y_train[val_idx])\n",
    "    X_te = torch.LongTensor(X_test)\n",
    "    y_te = torch.LongTensor(y_test)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_tr, y_tr),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        TensorDataset(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(X_te, y_te),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Creazione DataLoaders\n",
    "dl_train_loader, dl_val_loader, dl_test_loader = \\\n",
    "    make_loaders(\n",
    "        X_train_pad, y_train_dl,\n",
    "        X_test_pad, y_test_dl,\n",
    "        batch_size=128,\n",
    "    )\n",
    "\n",
    "# Creazione modello LSTM\n",
    "model_lstm = LSTMClassifier(\n",
    "    DL_VOCAB_SIZE, DL_EMBEDDING_DIM,\n",
    "    hidden_dim=64,\n",
    ").to(device)\n",
    "\n",
    "print(\"Modello LSTM:\")\n",
    "print(model_lstm)\n",
    "n_params = sum(\n",
    "    p.numel() for p in model_lstm.parameters()\n",
    ")\n",
    "print(f\"Parametri totali: {n_params:,}\")\n",
    "\n",
    "# Training (with pretrained weight support)\n",
    "print(f\"\\nTraining LSTM su {len(y_train_dl)} campioni...\")\n",
    "\n",
    "history_lstm = load_or_train(\n",
    "    model_lstm,\n",
    "    lambda: train_model(\n",
    "        model_lstm, dl_train_loader, dl_val_loader,\n",
    "        epochs=10, patience=2,\n",
    "    ),\n",
    "    'nb06_lstm.pt',\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Valutazione\n",
    "lstm_acc = evaluate_model(model_lstm, dl_test_loader)\n",
    "print(f\"\\nLSTM Test Accuracy: {lstm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kU_H5iOom8Cq",
   "metadata": {
    "id": "kU_H5iOom8Cq"
   },
   "source": [
    "### 5.2 Bidirectional LSTM\n",
    "\n",
    "Processa la sequenza in entrambe le direzioni\n",
    "(forward e backward) per catturare contesto completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9MDzA5Lnm8Cr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:19.860998Z",
     "iopub.status.busy": "2026-02-20T20:57:19.860632Z",
     "iopub.status.idle": "2026-02-20T20:57:21.568942Z",
     "shell.execute_reply": "2026-02-20T20:57:21.568337Z"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "error",
     "timestamp": 1771617344206,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "9MDzA5Lnm8Cr",
    "outputId": "0c34f7fd-c1c3-45e1-da4c-7f653635475e"
   },
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    \"\"\"LSTM bidirezionale per migliore contesto.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim,\n",
    "        hidden_dim1=64, hidden_dim2=32,\n",
    "        output_dim=1, dropout=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0,\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            embedding_dim, hidden_dim1,\n",
    "            batch_first=True, bidirectional=True,\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            hidden_dim1 * 2, hidden_dim2,\n",
    "            batch_first=True, bidirectional=True,\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim2 * 2, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm1_out, _ = self.lstm1(embedded)\n",
    "        _, (hidden, _) = self.lstm2(lstm1_out)\n",
    "        # Concatena forward e backward hidden states\n",
    "        hidden = torch.cat(\n",
    "            (hidden[-2], hidden[-1]), dim=1,\n",
    "        )\n",
    "        hidden = self.dropout1(hidden)\n",
    "        hidden = self.relu(self.fc1(hidden))\n",
    "        hidden = self.dropout2(hidden)\n",
    "        return self.fc2(hidden)\n",
    "\n",
    "\n",
    "model_bilstm = BiLSTMClassifier(\n",
    "    DL_VOCAB_SIZE, DL_EMBEDDING_DIM,\n",
    ").to(device)\n",
    "\n",
    "n_params_bilstm = sum(\n",
    "    p.numel() for p in model_bilstm.parameters()\n",
    ")\n",
    "n_params_lstm = sum(\n",
    "    p.numel() for p in model_lstm.parameters()\n",
    ")\n",
    "print(\n",
    "    f\"Parametri BiLSTM: {n_params_bilstm:,}\"\n",
    ")\n",
    "print(\n",
    "    f\"Parametri LSTM:   {n_params_lstm:,}\"\n",
    ")\n",
    "\n",
    "# Training (with pretrained weight support)\n",
    "print(f\"\\nTraining BiLSTM...\")\n",
    "\n",
    "history_bilstm = load_or_train(\n",
    "    model_bilstm,\n",
    "    lambda: train_model(\n",
    "        model_bilstm, dl_train_loader, dl_val_loader,\n",
    "        epochs=10, patience=2,\n",
    "    ),\n",
    "    'nb06_bilstm.pt',\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "bilstm_acc = evaluate_model(\n",
    "    model_bilstm, dl_test_loader,\n",
    ")\n",
    "print(f\"\\nBiLSTM Test Accuracy: {bilstm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oKJnXZaBm8Cr",
   "metadata": {
    "id": "oKJnXZaBm8Cr"
   },
   "source": [
    "### 5.3 GRU (Gated Recurrent Unit)\n",
    "\n",
    "Variante piu' semplice di LSTM, spesso con performance\n",
    "comparabili ma meno parametri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "IDWmnRs7m8Cr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:21.573700Z",
     "iopub.status.busy": "2026-02-20T20:57:21.573445Z",
     "iopub.status.idle": "2026-02-20T20:57:21.592229Z",
     "shell.execute_reply": "2026-02-20T20:57:21.591634Z"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "aborted",
     "timestamp": 1771617344272,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "IDWmnRs7m8Cr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri GRU:    1,041,313\n",
      "Parametri LSTM:   1,042,561\n",
      "Parametri BiLSTM: 1,130,689\n",
      "\n",
      "Confronto accuracy tutorial:\n",
      "  Logistic Regression: 0.8600\n",
      "  LSTM:                0.5160\n",
      "  BiLSTM:              0.5960\n"
     ]
    }
   ],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    \"\"\"GRU model - piu' leggero di LSTM.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim,\n",
    "        hidden_dim1=64, hidden_dim2=32,\n",
    "        output_dim=1, dropout=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0,\n",
    "        )\n",
    "        self.gru1 = nn.GRU(\n",
    "            embedding_dim, hidden_dim1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.gru2 = nn.GRU(\n",
    "            hidden_dim1, hidden_dim2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        gru1_out, _ = self.gru1(embedded)\n",
    "        _, hidden = self.gru2(gru1_out)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "\n",
    "model_gru = GRUClassifier(\n",
    "    DL_VOCAB_SIZE, DL_EMBEDDING_DIM,\n",
    ").to(device)\n",
    "\n",
    "n_params_gru = sum(\n",
    "    p.numel() for p in model_gru.parameters()\n",
    ")\n",
    "print(f\"Parametri GRU:    {n_params_gru:,}\")\n",
    "print(f\"Parametri LSTM:   {n_params_lstm:,}\")\n",
    "print(f\"Parametri BiLSTM: {n_params_bilstm:,}\")\n",
    "\n",
    "# Confronto tutorial\n",
    "print(f\"\\nConfronto accuracy tutorial:\")\n",
    "print(f\"  Logistic Regression: {acc_lr:.4f}\")\n",
    "print(f\"  LSTM:                {lstm_acc:.4f}\")\n",
    "print(f\"  BiLSTM:              {bilstm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C78kqNl9m8Cr",
   "metadata": {
    "id": "C78kqNl9m8Cr"
   },
   "source": [
    "## Esercizio 4\n",
    "\n",
    "**Task**: Costruire e confrontare LSTM, Bidirectional LSTM\n",
    "e GRU su review IMDB. Visualizzare training curves e\n",
    "analizzare le differenze tra architetture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RWjhROwHm8Cr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:21.595973Z",
     "iopub.status.busy": "2026-02-20T20:57:21.595507Z",
     "iopub.status.idle": "2026-02-20T20:57:30.240488Z",
     "shell.execute_reply": "2026-02-20T20:57:30.239580Z"
    },
    "executionInfo": {
     "elapsed": 209910,
     "status": "aborted",
     "timestamp": 1771617344274,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "RWjhROwHm8Cr"
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ESERCIZIO 4: Confronto Architetture Deep Learning\n",
    "# =========================================================\n",
    "\n",
    "# Subset dedicato (diverso dal tutorial)\n",
    "ex4_n_train = 5000\n",
    "ex4_n_test = 1000\n",
    "\n",
    "# Usiamo la seconda meta' del training set per evitare\n",
    "# overlap col tutorial\n",
    "ex4_start = 5000\n",
    "ex4_X_train_text = X_train_text[\n",
    "    ex4_start:ex4_start + ex4_n_train\n",
    "]\n",
    "ex4_y_train = y_train_imdb[\n",
    "    ex4_start:ex4_start + ex4_n_train\n",
    "]\n",
    "ex4_X_test_text = X_test_text[:ex4_n_test]\n",
    "ex4_y_test = y_test_imdb[:ex4_n_test]\n",
    "\n",
    "# Tokenizzazione dedicata\n",
    "ex4_vocab_size = 10000\n",
    "ex4_max_length = 150\n",
    "ex4_embedding_dim = 64\n",
    "\n",
    "ex4_tokenizer = SimpleTokenizer(\n",
    "    num_words=ex4_vocab_size,\n",
    ")\n",
    "ex4_tokenizer.fit_on_texts(ex4_X_train_text)\n",
    "\n",
    "ex4_X_train = pad_sequences_manual(\n",
    "    ex4_tokenizer.texts_to_sequences(ex4_X_train_text),\n",
    "    maxlen=ex4_max_length,\n",
    ")\n",
    "ex4_X_test = pad_sequences_manual(\n",
    "    ex4_tokenizer.texts_to_sequences(ex4_X_test_text),\n",
    "    maxlen=ex4_max_length,\n",
    ")\n",
    "\n",
    "print(f\"Esercizio 4 - Train: {ex4_X_train.shape}, \"\n",
    "      f\"Test: {ex4_X_test.shape}\")\n",
    "print(f\"Labels train: pos={sum(ex4_y_train==1)}, \"\n",
    "      f\"neg={sum(ex4_y_train==0)}\")\n",
    "\n",
    "\n",
    "# Step 1: Definizione architetture\n",
    "class Ex4LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            ex4_vocab_size, ex4_embedding_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            ex4_embedding_dim, 64, batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        return self.fc(self.dropout(hidden[-1]))\n",
    "\n",
    "\n",
    "class Ex4BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            ex4_vocab_size, ex4_embedding_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            ex4_embedding_dim, 64,\n",
    "            batch_first=True, bidirectional=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden = torch.cat(\n",
    "            (hidden[-2], hidden[-1]), dim=1,\n",
    "        )\n",
    "        return self.fc(self.dropout(hidden))\n",
    "\n",
    "\n",
    "class Ex4GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            ex4_vocab_size, ex4_embedding_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        self.gru = nn.GRU(\n",
    "            ex4_embedding_dim, 64, batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, hidden = self.gru(embedded)\n",
    "        return self.fc(self.dropout(hidden[-1]))\n",
    "\n",
    "\n",
    "ex4_models = {\n",
    "    'LSTM': Ex4LSTM().to(device),\n",
    "    'BiLSTM': Ex4BiLSTM().to(device),\n",
    "    'GRU': Ex4GRU().to(device),\n",
    "}\n",
    "\n",
    "for name, model in ex4_models.items():\n",
    "    n_p = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{name}: {n_p:,} parametri\")\n",
    "\n",
    "# DataLoaders per esercizio 4\n",
    "ex4_train_loader, ex4_val_loader, ex4_test_loader = \\\n",
    "    make_loaders(\n",
    "        ex4_X_train, ex4_y_train,\n",
    "        ex4_X_test, ex4_y_test,\n",
    "        batch_size=64,\n",
    "    )\n",
    "\n",
    "# Step 2: Training (with pretrained weight support)\n",
    "ex4_histories = {}\n",
    "ex4_results = []\n",
    "\n",
    "ex4_weight_names = {\n",
    "    'LSTM': 'nb06_ex4_lstm.pt',\n",
    "    'BiLSTM': 'nb06_ex4_bilstm.pt',\n",
    "    'GRU': 'nb06_ex4_gru.pt',\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING MODELLI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in ex4_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    history = load_or_train(\n",
    "        model,\n",
    "        lambda m=model: train_model(\n",
    "            m, ex4_train_loader, ex4_val_loader,\n",
    "            epochs=10, patience=3,\n",
    "        ),\n",
    "        ex4_weight_names[name],\n",
    "        device=device,\n",
    "    )\n",
    "    ex4_histories[name] = history\n",
    "\n",
    "    test_acc = evaluate_model(\n",
    "        model, ex4_test_loader,\n",
    "    )\n",
    "    train_acc = evaluate_model(\n",
    "        model, ex4_train_loader,\n",
    "    )\n",
    "\n",
    "    n_epochs = len(history['loss']) if history is not None else 0\n",
    "    ex4_results.append({\n",
    "        'model': name,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'test_loss': history['val_loss'][-1] if history is not None else 0.0,\n",
    "        'epochs': n_epochs,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"{name} - Test: {test_acc:.4f}, \"\n",
    "        f\"Epochs: {n_epochs}\"\n",
    "    )\n",
    "\n",
    "# Step 3: Risultati\n",
    "ex4_results_df = pd.DataFrame(ex4_results).sort_values(\n",
    "    'test_acc', ascending=False,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RISULTATI FINALI\")\n",
    "print(\"=\" * 60)\n",
    "print(ex4_results_df.to_string(index=False))\n",
    "\n",
    "# Step 4: Training curves\n",
    "if any(h is not None for h in ex4_histories.values()):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    for idx, (name, hist) in enumerate(\n",
    "        ex4_histories.items()\n",
    "    ):\n",
    "        ax = axes[idx]\n",
    "        if hist is not None:\n",
    "            ax.plot(hist['loss'], label='Train Loss')\n",
    "            ax.plot(hist['val_loss'], label='Val Loss')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'Pretrained\\n(no curves)',\n",
    "                    ha='center', va='center',\n",
    "                    transform=ax.transAxes, fontsize=12)\n",
    "        ax.set_title(name)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Training Curves', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Using pretrained weights - training curves not available\")\n",
    "\n",
    "# Step 5: Confronto con approccio classico\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO DL vs ML CLASSICO (tutorial)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Logistic Regression (TF-IDF): {acc_lr:.4f}\")\n",
    "for r in ex4_results:\n",
    "    print(f\"{r['model']:25s}: {r['test_acc']:.4f}\")\n",
    "\n",
    "print(\"\\nEsercizio 4 completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6QrNtjXzm8Cr",
   "metadata": {
    "id": "6QrNtjXzm8Cr"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Foundation Models per NLP\n",
    "\n",
    "I **foundation models** sono modelli pre-trained su enormi\n",
    "corpus di testo.\n",
    "\n",
    "### Transformers e Attention\n",
    "\n",
    "Il meccanismo di **Attention** permette al modello di\n",
    "\"focalizzarsi\" su parti rilevanti dell'input.\n",
    "\n",
    "### Modelli principali:\n",
    "\n",
    "- **BERT** (Google, 2018): Bidirectional Encoder\n",
    "- **GPT** (OpenAI): Generative Pre-trained Transformer\n",
    "- **T5** (Google): Text-to-Text Transfer Transformer\n",
    "- **RoBERTa**: BERT ottimizzato\n",
    "- **DistilBERT**: BERT piu' piccolo e veloce\n",
    "\n",
    "### 6.1 Uso di modelli pre-trained con Hugging Face\n",
    "\n",
    "**Hugging Face** e' la libreria standard per foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Fq8PVM44m8Cr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:30.244967Z",
     "iopub.status.busy": "2026-02-20T20:57:30.244721Z",
     "iopub.status.idle": "2026-02-20T20:57:33.511135Z",
     "shell.execute_reply": "2026-02-20T20:57:33.509698Z"
    },
    "executionInfo": {
     "elapsed": 209911,
     "status": "aborted",
     "timestamp": 1771617344276,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "Fq8PVM44m8Cr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 21:57:30.718246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers library pronta\n"
     ]
    }
   ],
   "source": [
    "# Installa transformers se necessario\n",
    "try:\n",
    "    from transformers import (\n",
    "        pipeline,\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "    )\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call(\n",
    "        ['pip', 'install', 'transformers']\n",
    "    )\n",
    "    from transformers import (\n",
    "        pipeline,\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "    )\n",
    "\n",
    "print(\"Transformers library pronta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wDOxGTITm8Cs",
   "metadata": {
    "id": "wDOxGTITm8Cs"
   },
   "source": [
    "### 6.2 Sentiment Analysis con modello pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1nL7CpyTm8Cy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:57:33.515927Z",
     "iopub.status.busy": "2026-02-20T20:57:33.514094Z",
     "iopub.status.idle": "2026-02-20T20:58:32.846172Z",
     "shell.execute_reply": "2026-02-20T20:58:32.845511Z"
    },
    "executionInfo": {
     "elapsed": 209910,
     "status": "aborted",
     "timestamp": 1771617344278,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "1nL7CpyTm8Cy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuele/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab57fd3cc6f04f1a90c48e0ca7447ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b1f2d73ac34035a6a4ce6eacda9200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1fe942d7fa4421ad1cda17d65bb748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni con DistilBERT pre-trained:\n",
      "\n",
      "Text: This movie is absolutely amazing!\n",
      "Label: POSITIVE, Score: 0.9999\n",
      "\n",
      "Text: Worst film I've ever seen. Terrible.\n",
      "Label: NEGATIVE, Score: 0.9998\n",
      "\n",
      "Text: It was okay, nothing special.\n",
      "Label: NEGATIVE, Score: 0.9821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline per sentiment analysis\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=(\n",
    "        \"distilbert-base-uncased-\"\n",
    "        \"finetuned-sst-2-english\"\n",
    "    ),\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "# Test\n",
    "test_texts = [\n",
    "    \"This movie is absolutely amazing!\",\n",
    "    \"Worst film I've ever seen. Terrible.\",\n",
    "    \"It was okay, nothing special.\",\n",
    "]\n",
    "\n",
    "print(\"Predizioni con DistilBERT pre-trained:\\n\")\n",
    "for text in test_texts:\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\n",
    "        f\"Label: {result['label']}, \"\n",
    "        f\"Score: {result['score']:.4f}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43xb_h9Sm8Cz",
   "metadata": {
    "id": "43xb_h9Sm8Cz"
   },
   "source": [
    "### 6.3 Fine-tuning di BERT\n",
    "\n",
    "Adattiamo un modello pre-trained al nostro task specifico.\n",
    "\n",
    "> **Nota**: Il fine-tuning su CPU richiede tempo significativo\n",
    "> (~25 min per 3 epoch con 1000 campioni).\n",
    "> Su Google Colab, attivare il runtime GPU:\n",
    "> Runtime -> Cambia tipo di runtime -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mu5zH8ztm8Cz",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:58:32.849385Z",
     "iopub.status.busy": "2026-02-20T20:58:32.849116Z",
     "iopub.status.idle": "2026-02-20T20:59:53.134721Z",
     "shell.execute_reply": "2026-02-20T20:59:53.134023Z"
    },
    "executionInfo": {
     "elapsed": 209911,
     "status": "aborted",
     "timestamp": 1771617344279,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "Mu5zH8ztm8Cz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Caricamento modello e tokenizer\n",
    "bert_model_name = \"distilbert-base-uncased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    bert_model_name,\n",
    ")\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    bert_model_name, num_labels=2,\n",
    ")\n",
    "bert_model.to(device)\n",
    "\n",
    "print(f\"Modello: {bert_model_name}\")\n",
    "print(f\"Parametri: {bert_model.num_parameters():,}\")\n",
    "\n",
    "\n",
    "# Tokenization helper\n",
    "def tokenize_for_bert(texts, tokenizer, max_length=128):\n",
    "    \"\"\"Tokenizza testi per BERT.\"\"\"\n",
    "    if hasattr(texts, 'tolist'):\n",
    "        texts = texts.tolist()\n",
    "    else:\n",
    "        texts = list(texts)\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "\n",
    "# IMPORTANTE: usiamo IMDB text + IMDB labels (matched!)\n",
    "bert_n_train = 1000\n",
    "bert_n_test = 200\n",
    "\n",
    "bert_train_texts = X_train_text[:bert_n_train]\n",
    "bert_train_labels = y_train_imdb[:bert_n_train]\n",
    "bert_test_texts = X_test_text[:bert_n_test]\n",
    "bert_test_labels = y_test_imdb[:bert_n_test]\n",
    "\n",
    "print(\n",
    "    f\"Fine-tuning su {bert_n_train} campioni, \"\n",
    "    f\"test su {bert_n_test}\"\n",
    ")\n",
    "\n",
    "# Tokenize\n",
    "bert_train_enc = tokenize_for_bert(\n",
    "    bert_train_texts, bert_tokenizer,\n",
    ")\n",
    "bert_test_enc = tokenize_for_bert(\n",
    "    bert_test_texts, bert_tokenizer,\n",
    ")\n",
    "\n",
    "# Labels come tensori\n",
    "bert_y_train = torch.tensor(\n",
    "    bert_train_labels.tolist()\n",
    "    if hasattr(bert_train_labels, 'tolist')\n",
    "    else list(bert_train_labels)\n",
    ").long()\n",
    "bert_y_test = torch.tensor(\n",
    "    bert_test_labels.tolist()\n",
    "    if hasattr(bert_test_labels, 'tolist')\n",
    "    else list(bert_test_labels)\n",
    ").long()\n",
    "\n",
    "print(\n",
    "    f\"Input shape: {bert_train_enc['input_ids'].shape}\"\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "bert_train_dataset = TensorDataset(\n",
    "    bert_train_enc['input_ids'],\n",
    "    bert_train_enc['attention_mask'],\n",
    "    bert_y_train,\n",
    ")\n",
    "bert_test_dataset = TensorDataset(\n",
    "    bert_test_enc['input_ids'],\n",
    "    bert_test_enc['attention_mask'],\n",
    "    bert_y_test,\n",
    ")\n",
    "\n",
    "bert_train_loader = DataLoader(\n",
    "    bert_train_dataset, batch_size=16, shuffle=True,\n",
    ")\n",
    "bert_test_loader = DataLoader(\n",
    "    bert_test_dataset, batch_size=16,\n",
    ")\n",
    "\n",
    "# Check for pretrained weights\n",
    "bert_weights_path = os.path.join(WEIGHTS_DIR, 'nb06_distilbert.pt')\n",
    "_bert_loaded = False\n",
    "\n",
    "if os.path.exists(bert_weights_path):\n",
    "    bert_model.load_state_dict(\n",
    "        torch.load(bert_weights_path, map_location=device, weights_only=True)\n",
    "    )\n",
    "    print(f\"Loaded pretrained DistilBERT weights from {bert_weights_path}\")\n",
    "    _bert_loaded = True\n",
    "elif WEIGHTS_BASE_URL:\n",
    "    try:\n",
    "        url = WEIGHTS_BASE_URL + 'nb06_distilbert.pt'\n",
    "        urllib.request.urlretrieve(url, bert_weights_path)\n",
    "        bert_model.load_state_dict(\n",
    "            torch.load(bert_weights_path, map_location=device, weights_only=True)\n",
    "        )\n",
    "        print(f\"Downloaded and loaded DistilBERT weights from {url}\")\n",
    "        _bert_loaded = True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download weights: {e}. Fine-tuning from scratch...\")\n",
    "\n",
    "if not _bert_loaded:\n",
    "    # Optimizer\n",
    "    bert_optimizer = torch.optim.Adam(\n",
    "        bert_model.parameters(), lr=2e-5,\n",
    "    )\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    bert_epochs = 3\n",
    "    bert_model.train()\n",
    "\n",
    "    for epoch in range(bert_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        progress = tqdm(\n",
    "            bert_train_loader,\n",
    "            desc=f'Epoch {epoch + 1}/{bert_epochs}',\n",
    "        )\n",
    "        for batch in progress:\n",
    "            input_ids, attention_mask, labels = [\n",
    "                b.to(device) for b in batch\n",
    "            ]\n",
    "\n",
    "            bert_optimizer.zero_grad()\n",
    "\n",
    "            outputs = bert_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            bert_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress.set_postfix({\n",
    "                'loss': f'{loss.item():.3f}',\n",
    "                'acc': f'{correct/total:.3f}',\n",
    "            })\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} - \"\n",
    "            f\"Loss: {total_loss / len(bert_train_loader):.4f}, \"\n",
    "            f\"Accuracy: {correct / total:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nFine-tuning completato\")\n",
    "\n",
    "    # Save weights\n",
    "    torch.save(bert_model.state_dict(), bert_weights_path)\n",
    "    print(f\"Saved DistilBERT weights to {bert_weights_path}\")\n",
    "\n",
    "# Valutazione\n",
    "bert_model.eval()\n",
    "bert_correct = 0\n",
    "bert_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in bert_test_loader:\n",
    "        input_ids, attention_mask, labels = [\n",
    "            b.to(device) for b in batch\n",
    "        ]\n",
    "        outputs = bert_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        bert_correct += (preds == labels).sum().item()\n",
    "        bert_total += labels.size(0)\n",
    "\n",
    "bert_acc = bert_correct / bert_total\n",
    "print(f\"BERT Fine-tuned Accuracy: {bert_acc:.4f}\")\n",
    "\n",
    "# Confronto finale\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO FINALE (stesso test set IMDB):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Logistic Regression (TF-IDF): {acc_lr:.4f}\")\n",
    "print(f\"LSTM:                         {lstm_acc:.4f}\")\n",
    "print(f\"BiLSTM:                       {bilstm_acc:.4f}\" if 'bilstm_acc' in dir() else \"BiLSTM:                       N/A\")\n",
    "print(f\"BERT fine-tuned:              {bert_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fp2QrUPJm8Cz",
   "metadata": {
    "id": "fp2QrUPJm8Cz"
   },
   "source": [
    "---\n",
    "\n",
    "## 7. Utilizzo API per NLP\n",
    "\n",
    "### 7.1 Simulazione API Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "kOMIlqcQm8Cz",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:59:53.137995Z",
     "iopub.status.busy": "2026-02-20T20:59:53.137546Z",
     "iopub.status.idle": "2026-02-20T20:59:54.003673Z",
     "shell.execute_reply": "2026-02-20T20:59:54.002801Z"
    },
    "executionInfo": {
     "elapsed": 209910,
     "status": "aborted",
     "timestamp": 1771617344281,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "kOMIlqcQm8Cz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisi Sentiment via API:\n",
      "\n",
      "Text: The cinematography was breathtaking and the acting was ...\n",
      "  -> POSITIVE (1.000)\n",
      "\n",
      "Text: Complete waste of money. Plot was confusing and boring....\n",
      "  -> NEGATIVE (1.000)\n",
      "\n",
      "Text: Decent movie, had some good moments but overall forgett...\n",
      "  -> NEGATIVE (0.998)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NLPAPISimulator:\n",
    "    \"\"\"\n",
    "    Simulazione API per NLP tasks.\n",
    "    In produzione useresti chiamate HTTP a:\n",
    "    - Hugging Face Inference API\n",
    "    - OpenAI API\n",
    "    - Anthropic Claude API\n",
    "    - Google Cloud Natural Language API\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentiment_model = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=(\n",
    "                \"distilbert-base-uncased-\"\n",
    "                \"finetuned-sst-2-english\"\n",
    "            ),\n",
    "            framework=\"pt\",\n",
    "        )\n",
    "\n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"Analizza sentiment del testo.\"\"\"\n",
    "        result = self.sentiment_model(text)[0]\n",
    "        return {\n",
    "            'text': text,\n",
    "            'sentiment': result['label'],\n",
    "            'confidence': result['score'],\n",
    "        }\n",
    "\n",
    "    def batch_process(self, texts):\n",
    "        \"\"\"Processa batch di testi.\"\"\"\n",
    "        return [\n",
    "            self.analyze_sentiment(t) for t in texts\n",
    "        ]\n",
    "\n",
    "\n",
    "# Test\n",
    "nlp_api = NLPAPISimulator()\n",
    "\n",
    "api_test_texts = [\n",
    "    (\n",
    "        \"The cinematography was breathtaking \"\n",
    "        \"and the acting was superb.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Complete waste of money. \"\n",
    "        \"Plot was confusing and boring.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Decent movie, had some good moments \"\n",
    "        \"but overall forgettable.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Analisi Sentiment via API:\\n\")\n",
    "for result in nlp_api.batch_process(api_test_texts):\n",
    "    print(f\"Text: {result['text'][:55]}...\")\n",
    "    print(\n",
    "        f\"  -> {result['sentiment']} \"\n",
    "        f\"({result['confidence']:.3f})\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0ocCO6zm8Cz",
   "metadata": {
    "id": "s0ocCO6zm8Cz"
   },
   "source": [
    "### 7.2 Esempio chiamata reale API (struttura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "vwyXrcTrm8C0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:59:54.009939Z",
     "iopub.status.busy": "2026-02-20T20:59:54.009582Z",
     "iopub.status.idle": "2026-02-20T20:59:54.017468Z",
     "shell.execute_reply": "2026-02-20T20:59:54.016831Z"
    },
    "executionInfo": {
     "elapsed": 209911,
     "status": "aborted",
     "timestamp": 1771617344283,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "vwyXrcTrm8C0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struttura per API calls in produzione\n",
      "(vedi cella per esempi di codice)\n"
     ]
    }
   ],
   "source": [
    "# Codice illustrativo per chiamate API reali\n",
    "api_example = \"\"\"\n",
    "# Hugging Face Inference API\n",
    "import requests\n",
    "\n",
    "API_URL = (\n",
    "    \"https://api-inference.huggingface.co/models/\"\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "headers = {\"Authorization\": f\"Bearer {YOUR_API_KEY}\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(\n",
    "        API_URL, headers=headers, json=payload,\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "output = query({\"inputs\": \"I love this product!\"})\n",
    "\n",
    "# OpenAI API\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=YOUR_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a sentiment analyzer.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Analyze: This movie is great!\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Struttura per API calls in produzione\")\n",
    "print(\"(vedi cella per esempi di codice)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wofIGzGSm8C0",
   "metadata": {
    "id": "wofIGzGSm8C0"
   },
   "source": [
    "---\n",
    "\n",
    "## 8. Sistema NLP Completo\n",
    "\n",
    "Classe end-to-end che supporta approccio classico e LSTM,\n",
    "dimostrando come incapsulare la pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T85_74Bmm8C0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T20:59:54.021511Z",
     "iopub.status.busy": "2026-02-20T20:59:54.020940Z",
     "iopub.status.idle": "2026-02-20T20:59:58.120375Z",
     "shell.execute_reply": "2026-02-20T20:59:58.119240Z"
    },
    "executionInfo": {
     "elapsed": 209912,
     "status": "aborted",
     "timestamp": 1771617344285,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     },
     "user_tz": -60
    },
    "id": "T85_74Bmm8C0"
   },
   "outputs": [],
   "source": [
    "class SistemaNLPCompleto:\n",
    "    \"\"\"\n",
    "    Sistema end-to-end per NLP.\n",
    "    Supporta approccio 'classico' (TF-IDF + LR)\n",
    "    e 'lstm' (embedding + LSTM).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, approccio='classico'):\n",
    "        self.approccio = approccio\n",
    "        self.model = None\n",
    "        self.vectorizer = None\n",
    "        self.tokenizer = None\n",
    "        self.history = None\n",
    "        self.max_length = 200\n",
    "        self.vocab_size = 10000\n",
    "\n",
    "    def _preprocess_classical(self, texts, fit=False):\n",
    "        if fit:\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=5000,\n",
    "                ngram_range=(1, 2),\n",
    "            )\n",
    "            return self.vectorizer.fit_transform(texts)\n",
    "        return self.vectorizer.transform(texts)\n",
    "\n",
    "    def _preprocess_dl(self, texts, fit=False):\n",
    "        if fit:\n",
    "            self.tokenizer = SimpleTokenizer(\n",
    "                num_words=self.vocab_size,\n",
    "            )\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "        seqs = self.tokenizer.texts_to_sequences(texts)\n",
    "        return pad_sequences_manual(\n",
    "            seqs, maxlen=self.max_length,\n",
    "        )\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Costruisce il modello.\"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            self.model = LogisticRegression(\n",
    "                max_iter=1000, random_state=42,\n",
    "            )\n",
    "        elif self.approccio == 'lstm':\n",
    "            self.model = LSTMClassifier(\n",
    "                self.vocab_size, 100,\n",
    "                hidden_dim=64,\n",
    "            ).to(device)\n",
    "\n",
    "    def train(self, X, y, epochs=5):\n",
    "        \"\"\"Addestra il modello.\"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            X_proc = self._preprocess_classical(\n",
    "                X, fit=True,\n",
    "            )\n",
    "            self.model.fit(X_proc, y)\n",
    "        elif self.approccio == 'lstm':\n",
    "            X_proc = self._preprocess_dl(X, fit=True)\n",
    "            # Split train/val\n",
    "            n_val = int(len(X_proc) * 0.2)\n",
    "            indices = np.random.permutation(len(X_proc))\n",
    "            val_idx = indices[:n_val]\n",
    "            train_idx = indices[n_val:]\n",
    "\n",
    "            X_tr = torch.LongTensor(X_proc[train_idx])\n",
    "            y_tr = torch.LongTensor(y[train_idx])\n",
    "            X_val = torch.LongTensor(X_proc[val_idx])\n",
    "            y_val = torch.LongTensor(y[val_idx])\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                TensorDataset(X_tr, y_tr),\n",
    "                batch_size=128, shuffle=True,\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                TensorDataset(X_val, y_val),\n",
    "                batch_size=128,\n",
    "            )\n",
    "\n",
    "            self.history = load_or_train(\n",
    "                self.model,\n",
    "                lambda: train_model(\n",
    "                    self.model, train_loader, val_loader,\n",
    "                    epochs=epochs, patience=2,\n",
    "                ),\n",
    "                'nb06_sistema_lstm.pt',\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Valuta il modello e ritorna accuracy.\"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            X_proc = self._preprocess_classical(X)\n",
    "            y_pred = self.model.predict(X_proc)\n",
    "        elif self.approccio == 'lstm':\n",
    "            X_proc = self._preprocess_dl(X)\n",
    "            X_tensor = torch.LongTensor(X_proc)\n",
    "            test_loader = DataLoader(\n",
    "                TensorDataset(\n",
    "                    X_tensor,\n",
    "                    torch.LongTensor(y),\n",
    "                ),\n",
    "                batch_size=128,\n",
    "            )\n",
    "            return evaluate_model(\n",
    "                self.model, test_loader,\n",
    "            )\n",
    "\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        return acc\n",
    "\n",
    "    def predict_text(self, text):\n",
    "        \"\"\"Predice sentiment di un singolo testo.\"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            X_proc = self._preprocess_classical([text])\n",
    "            pred = self.model.predict(X_proc)[0]\n",
    "            prob = self.model.predict_proba(X_proc)[0]\n",
    "            return {\n",
    "                'sentiment': (\n",
    "                    'Positive' if pred == 1\n",
    "                    else 'Negative'\n",
    "                ),\n",
    "                'confidence': float(prob[pred]),\n",
    "            }\n",
    "        elif self.approccio == 'lstm':\n",
    "            X_proc = self._preprocess_dl([text])\n",
    "            X_tensor = torch.LongTensor(\n",
    "                X_proc\n",
    "            ).to(device)\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = self.model(\n",
    "                    X_tensor\n",
    "                ).squeeze(-1)\n",
    "                pred_val = torch.sigmoid(\n",
    "                    output\n",
    "                ).item()\n",
    "            pred_class = 1 if pred_val > 0.5 else 0\n",
    "            return {\n",
    "                'sentiment': (\n",
    "                    'Positive' if pred_class == 1\n",
    "                    else 'Negative'\n",
    "                ),\n",
    "                'confidence': (\n",
    "                    pred_val if pred_class == 1\n",
    "                    else 1 - pred_val\n",
    "                ),\n",
    "            }\n",
    "\n",
    "\n",
    "# ---- Test del sistema ----\n",
    "\n",
    "# Dati IMDB consistenti\n",
    "sys_n_train = 3000\n",
    "sys_n_test = 500\n",
    "sys_X_train = X_train_text[:sys_n_train]\n",
    "sys_y_train = y_train_imdb[:sys_n_train]\n",
    "sys_X_test = X_test_text[:sys_n_test]\n",
    "sys_y_test = y_test_imdb[:sys_n_test]\n",
    "\n",
    "print(\"Test Sistema NLP Completo:\")\n",
    "print(\n",
    "    f\"Train: {sys_n_train}, \"\n",
    "    f\"Test: {sys_n_test}\\n\"\n",
    ")\n",
    "\n",
    "# Test classico\n",
    "print(\"--- Approccio Classico ---\")\n",
    "sistema_classico = SistemaNLPCompleto('classico')\n",
    "sistema_classico.build_model()\n",
    "sistema_classico.train(sys_X_train, sys_y_train)\n",
    "acc_classico = sistema_classico.evaluate(\n",
    "    sys_X_test, sys_y_test,\n",
    ")\n",
    "print(f\"Accuracy: {acc_classico:.4f}\\n\")\n",
    "\n",
    "# Test LSTM\n",
    "print(\"--- Approccio LSTM ---\")\n",
    "sistema_lstm = SistemaNLPCompleto('lstm')\n",
    "sistema_lstm.build_model()\n",
    "sistema_lstm.train(\n",
    "    sys_X_train, sys_y_train, epochs=5,\n",
    ")\n",
    "acc_lstm_sys = sistema_lstm.evaluate(\n",
    "    sys_X_test, sys_y_test,\n",
    ")\n",
    "print(f\"Accuracy: {acc_lstm_sys:.4f}\\n\")\n",
    "\n",
    "# Confronto\n",
    "print(\"=\" * 40)\n",
    "print(\"RISULTATI:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Classico (TF-IDF + LR): {acc_classico:.4f}\")\n",
    "print(f\"LSTM:                   {acc_lstm_sys:.4f}\")\n",
    "\n",
    "# Test su testo singolo\n",
    "print(\"\\n--- Predizione singola ---\")\n",
    "test_text = \"This movie was really great and fun!\"\n",
    "for name, sistema in [\n",
    "    ('Classico', sistema_classico),\n",
    "    ('LSTM', sistema_lstm),\n",
    "]:\n",
    "    result = sistema.predict_text(test_text)\n",
    "    print(\n",
    "        f\"{name}: {result['sentiment']} \"\n",
    "        f\"({result['confidence']:.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t2XFtgY1m8C0",
   "metadata": {
    "id": "t2XFtgY1m8C0"
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusioni\n",
    "\n",
    "### Approccio Classico:\n",
    "\n",
    "- Preprocessing: tokenization, stopwords,\n",
    "  stemming/lemmatization\n",
    "- Feature extraction: BOW, TF-IDF\n",
    "- Classificatori: Naive Bayes, Logistic Regression,\n",
    "  SVM, Random Forest\n",
    "- Analisi feature importance\n",
    "\n",
    "### Deep Learning:\n",
    "\n",
    "- Word Embeddings: rappresentazioni dense\n",
    "- RNN/LSTM/GRU: architetture per sequenze\n",
    "- Bidirectional LSTM: contesto completo\n",
    "- Foundation Models: BERT, DistilBERT\n",
    "- Fine-tuning: adattamento task-specific\n",
    "- API: deployment e usage\n",
    "\n",
    "### Concetti Chiave\n",
    "\n",
    "1. **Preprocessing e' fondamentale**: la qualita'\n",
    "   del preprocessing determina il successo\n",
    "2. **TF-IDF > BOW**: per la maggior parte dei task\n",
    "3. **LSTM/GRU per sequenze**: gestiscono dipendenze\n",
    "   a lungo termine\n",
    "4. **Foundation models sono il futuro**: transfer\n",
    "   learning e' standard\n",
    "5. **Fine-tuning > training da zero**: specialmente\n",
    "   con dati limitati\n",
    "6. **Context matters**: modelli bidirezionali catturano\n",
    "   meglio il significato\n",
    "\n",
    "### Workflow Consigliato\n",
    "\n",
    "1. **Baseline veloce**: TF-IDF + Logistic Regression\n",
    "2. **Se serve piu' accuracy**: prova LSTM/GRU\n",
    "3. **Per performance SOTA**: fine-tune BERT/DistilBERT\n",
    "4. **In produzione**: valuta costo/beneficio di ogni\n",
    "   approccio"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02b68b5f739540ac8fba995ed06b9110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02e75c683add43b987c546de9a0ab58d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0350e934f13543d4990779327cbbfb35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0776397e005e463098a3ce0b4c5c969a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9a3fab7a4a4746398f971d9e0d65b8c5",
       "placeholder": "",
       "style": "IPY_MODEL_78dc11ba44a0401aae08baaec9cacd28",
       "tabbable": null,
       "tooltip": null,
       "value": "48.0/48.0[00:00&lt;00:00,3.99kB/s]"
      }
     },
     "0855cfc04b9146349231c4e6c0fe1343": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ec0b4f02b934180af44a43bd98a9a4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3e100fb203e94dfa89df1b797b462cda",
       "max": 483.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b72ce3f70b054560a4b7f142cfba69cf",
       "tabbable": null,
       "tooltip": null,
       "value": 483.0
      }
     },
     "0f25a282f0ab48e2a552f45d5f41e807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6553095c4bb0475998ddce34e8f66861",
        "IPY_MODEL_0ec0b4f02b934180af44a43bd98a9a4e",
        "IPY_MODEL_dc19f7f788c24770a251ff5edc3ae562"
       ],
       "layout": "IPY_MODEL_401589c0a6ce41f998062d8c491e759d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0f3018917326499a82f562e1897de71b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc7e0c9290e04d509066f656543d26bb",
       "placeholder": "",
       "style": "IPY_MODEL_f6c685ee6a1d44b6aae1c991efc8d5bd",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:100%"
      }
     },
     "0f3aeb6536bd477ebc1f7abb69229e6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0fd89db2bb474fbea4fcc2bb6c58b35e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4aac2cee6ce24862933b0f22d5438c13",
       "max": 267832558.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98a60b66bf034b68842dc09bcda0a53b",
       "tabbable": null,
       "tooltip": null,
       "value": 267832558.0
      }
     },
     "13a241e884ab4f578c7dec4477c72cc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13a65ac9db1045a899e4ba6fad7d66cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "158efcec8ae3471381955cca64b8f8d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_97f1e1121ab34f29808871bc1dc959e6",
       "placeholder": "",
       "style": "IPY_MODEL_5acefe782acc4ba187bfad6b897ecbf9",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "1a2a18126c80443abdbf7395b6100035": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_289052ab5edc4adb936e02a7e80e0595",
       "placeholder": "",
       "style": "IPY_MODEL_0f3aeb6536bd477ebc1f7abb69229e6a",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "1f1fe942d7fa4421ad1cda17d65bb748": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_158efcec8ae3471381955cca64b8f8d2",
        "IPY_MODEL_36eb783dfd6e4e2ebc6a0bd1053d1441",
        "IPY_MODEL_e6eb86952fb445528bfb9185bb014f68"
       ],
       "layout": "IPY_MODEL_9447c24ee86c4f5f918beeb116d1e1ee",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2158f25226be45e79988b0db06df004a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22849e55f3134a4596d770972925607e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_254e7904e563430799cefaa5da0b5e73",
       "placeholder": "",
       "style": "IPY_MODEL_de2191c008604c0c9b3c869dcddf1ff5",
       "tabbable": null,
       "tooltip": null,
       "value": "48.0/48.0[00:00&lt;00:00,2.31kB/s]"
      }
     },
     "254e7904e563430799cefaa5da0b5e73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2590dd53dff243a98db916bdbddc4ec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_beb1acd34c504d63860f91ecc3759977",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d1684aa7c8bf4e0182414a3087c3cc64",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "25b9cd61476e4ca9950212050f8bf93f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "262b5b7dcb93434c8e0bbe766555a8be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "289052ab5edc4adb936e02a7e80e0595": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c1424aaf48b42609e8f049ace80ad75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02b68b5f739540ac8fba995ed06b9110",
       "placeholder": "",
       "style": "IPY_MODEL_dfdfcc9a53a04b538b6c28bd348686f6",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "335f7715bc3d4db0ae89c44fca29745b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "36eb783dfd6e4e2ebc6a0bd1053d1441": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89fffd2e739d409ab36a658de836cba1",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d3107c176cc94d3a8211cb8e9bf6d784",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "380ce7d6b6aa43018fdf326b99ecd491": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bba4ffc8fb47464186bf3d4a1ca00820",
       "placeholder": "",
       "style": "IPY_MODEL_335f7715bc3d4db0ae89c44fca29745b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "38f268a9106042d296ef41644ef301e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13a241e884ab4f578c7dec4477c72cc4",
       "placeholder": "",
       "style": "IPY_MODEL_67a4a4d7541749599d979a6ce72422cf",
       "tabbable": null,
       "tooltip": null,
       "value": "232k/232k[00:00&lt;00:00,1.18MB/s]"
      }
     },
     "3d60023483b8414a8c9196d468d0ff50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0350e934f13543d4990779327cbbfb35",
       "placeholder": "",
       "style": "IPY_MODEL_13a65ac9db1045a899e4ba6fad7d66cb",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "3e100fb203e94dfa89df1b797b462cda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "401589c0a6ce41f998062d8c491e759d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "476856b2c49a402e95eb62cd94912e23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c1424aaf48b42609e8f049ace80ad75",
        "IPY_MODEL_480cec1ff0b54e91b980d524f3dbab60",
        "IPY_MODEL_38f268a9106042d296ef41644ef301e7"
       ],
       "layout": "IPY_MODEL_b04466f101a446a99ac6788f397da1aa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "480cec1ff0b54e91b980d524f3dbab60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0855cfc04b9146349231c4e6c0fe1343",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b488f1e3cc654a438ecafdc5686ad97f",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "4aac2cee6ce24862933b0f22d5438c13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "508904c725324eb8bc0753f7c36fa21f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5329eb36edd24bf6af08295f940e9433": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "544628f8c93647069d8b4b84862bf11f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d60023483b8414a8c9196d468d0ff50",
        "IPY_MODEL_c4d8b307106a41b9861505e43b830dd3",
        "IPY_MODEL_0776397e005e463098a3ce0b4c5c969a"
       ],
       "layout": "IPY_MODEL_25b9cd61476e4ca9950212050f8bf93f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "58f8194a580d4216b480b5a4b8c3d454": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5acefe782acc4ba187bfad6b897ecbf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ec37b7522cb4ad797fb15fbc5d25ce1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ff290b5c5c9422b82e75df525054529": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6553095c4bb0475998ddce34e8f66861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_caae4f231e194babb464b4bcd4d23b31",
       "placeholder": "",
       "style": "IPY_MODEL_79267c9278de4d3abcdde55cfaaca990",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "67a4a4d7541749599d979a6ce72422cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d3365a36dde449280243d7dd3ee23e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ebd50459bef48c08a635be72205c8f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74fa154c417f4e11b81858725c22ad05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f3018917326499a82f562e1897de71b",
        "IPY_MODEL_a1f8cb08de294f4ea8cfd659131421d7",
        "IPY_MODEL_98a3b8c07b9f4f87bccc8ad781042b1a"
       ],
       "layout": "IPY_MODEL_9b30ea82ba6e476f8d45b22d0a45ee69",
       "tabbable": null,
       "tooltip": null
      }
     },
     "78dc11ba44a0401aae08baaec9cacd28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "79267c9278de4d3abcdde55cfaaca990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d5e2937013543f0968e91aee8485465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d3365a36dde449280243d7dd3ee23e4",
       "max": 267954768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bbbed0e12adf4ff48c6d52af698dd3d2",
       "tabbable": null,
       "tooltip": null,
       "value": 267954768.0
      }
     },
     "89fffd2e739d409ab36a658de836cba1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cc44467850f4a508193a7cd5cd4376a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d0db41397d6443582baa3bc0c169c2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93ab2b95806f4338b565dbb7fd48fdfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9447c24ee86c4f5f918beeb116d1e1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97f1e1121ab34f29808871bc1dc959e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98a3b8c07b9f4f87bccc8ad781042b1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6ebd50459bef48c08a635be72205c8f3",
       "placeholder": "",
       "style": "IPY_MODEL_5ec37b7522cb4ad797fb15fbc5d25ce1",
       "tabbable": null,
       "tooltip": null,
       "value": "466k/466k[00:00&lt;00:00,1.63MB/s]"
      }
     },
     "98a60b66bf034b68842dc09bcda0a53b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a3fab7a4a4746398f971d9e0d65b8c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b30ea82ba6e476f8d45b22d0a45ee69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d0a3313b80148dabc28d82cb749342a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f497f8215f542088dcc919e6f6585bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a1f8cb08de294f4ea8cfd659131421d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5329eb36edd24bf6af08295f940e9433",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9f497f8215f542088dcc919e6f6585bb",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "a6996ae638f94af2b841309f454d2260": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_380ce7d6b6aa43018fdf326b99ecd491",
        "IPY_MODEL_7d5e2937013543f0968e91aee8485465",
        "IPY_MODEL_d7284520571c45a091ed43b45f22fa77"
       ],
       "layout": "IPY_MODEL_9d0a3313b80148dabc28d82cb749342a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ab57fd3cc6f04f1a90c48e0ca7447ba4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a2a18126c80443abdbf7395b6100035",
        "IPY_MODEL_0fd89db2bb474fbea4fcc2bb6c58b35e",
        "IPY_MODEL_fb94f26c8a5e4b35830933ff55681397"
       ],
       "layout": "IPY_MODEL_93ab2b95806f4338b565dbb7fd48fdfd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afba76e93941467abbdae6e2415e246a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58f8194a580d4216b480b5a4b8c3d454",
       "placeholder": "",
       "style": "IPY_MODEL_b0eda7f808754d64b6c25baeac0ab3cc",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "b04466f101a446a99ac6788f397da1aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0eda7f808754d64b6c25baeac0ab3cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b488f1e3cc654a438ecafdc5686ad97f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b72ce3f70b054560a4b7f142cfba69cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b97340d162724432bdd857cab9c7c80a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bba4ffc8fb47464186bf3d4a1ca00820": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbbed0e12adf4ff48c6d52af698dd3d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bc7e0c9290e04d509066f656543d26bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beb1acd34c504d63860f91ecc3759977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4d8b307106a41b9861505e43b830dd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8cc44467850f4a508193a7cd5cd4376a",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_262b5b7dcb93434c8e0bbe766555a8be",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "caae4f231e194babb464b4bcd4d23b31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccac23d118f14bd6bfc6d5393402687b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d1684aa7c8bf4e0182414a3087c3cc64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d3107c176cc94d3a8211cb8e9bf6d784": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d7284520571c45a091ed43b45f22fa77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02e75c683add43b987c546de9a0ab58d",
       "placeholder": "",
       "style": "IPY_MODEL_5ff290b5c5c9422b82e75df525054529",
       "tabbable": null,
       "tooltip": null,
       "value": "268M/268M[00:53&lt;00:00,9.33MB/s]"
      }
     },
     "d8b1f2d73ac34035a6a4ce6eacda9200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afba76e93941467abbdae6e2415e246a",
        "IPY_MODEL_2590dd53dff243a98db916bdbddc4ec3",
        "IPY_MODEL_22849e55f3134a4596d770972925607e"
       ],
       "layout": "IPY_MODEL_8d0db41397d6443582baa3bc0c169c2c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dc19f7f788c24770a251ff5edc3ae562": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2158f25226be45e79988b0db06df004a",
       "placeholder": "",
       "style": "IPY_MODEL_e905450ab82b4bcf81024e5bf40be091",
       "tabbable": null,
       "tooltip": null,
       "value": "483/483[00:00&lt;00:00,43.4kB/s]"
      }
     },
     "de2191c008604c0c9b3c869dcddf1ff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dfdfcc9a53a04b538b6c28bd348686f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6eb86952fb445528bfb9185bb014f68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b97340d162724432bdd857cab9c7c80a",
       "placeholder": "",
       "style": "IPY_MODEL_ccac23d118f14bd6bfc6d5393402687b",
       "tabbable": null,
       "tooltip": null,
       "value": "232k/232k[00:00&lt;00:00,4.73MB/s]"
      }
     },
     "e905450ab82b4bcf81024e5bf40be091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f265c48045844912b9a92a4821c58dee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f6c685ee6a1d44b6aae1c991efc8d5bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fb94f26c8a5e4b35830933ff55681397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_508904c725324eb8bc0753f7c36fa21f",
       "placeholder": "",
       "style": "IPY_MODEL_f265c48045844912b9a92a4821c58dee",
       "tabbable": null,
       "tooltip": null,
       "value": "268M/268M[00:57&lt;00:00,7.49MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}