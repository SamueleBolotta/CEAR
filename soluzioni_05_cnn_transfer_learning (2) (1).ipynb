{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision tramite Deep Learning: CNN e Transfer Learning\n\n## Introduzione\n\nLe **Convolutional Neural Networks (CNN)** hanno rivoluzionato la Computer Vision. A differenza delle reti neurali fully-connected, le CNN sono progettate specificamente per dati con struttura spaziale (immagini).\n\n### Perche' le CNN sono cosi' efficaci?\n\n1. **Condivisione parametri**: stesso filtro applicato a tutta l'immagine\n2. **Invarianza traslazionale**: rileva pattern indipendentemente dalla posizione\n3. **Gerarchia di feature**: dai bordi ai pattern complessi\n4. **Meno parametri**: rispetto a fully-connected\n\n### Milestone storiche\n\n- **1998**: LeNet-5 (Yann LeCun) - riconoscimento cifre\n- **2012**: AlexNet vince ImageNet (8 layer, 60M parametri)\n- **2014**: VGGNet (16-19 layer) e GoogleNet/Inception\n- **2015**: ResNet (152 layer) con skip connections\n- **2019**: EfficientNet - scaling ottimizzato\n- **2020+**: Vision Transformers (ViT) sfidano le CNN\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architettura delle CNN\n\n### 1.1 Layer Convoluzionale\n\nIl **layer convoluzionale** applica filtri (kernel) all'immagine tramite l'operazione di convoluzione.\n\n#### Operazione di Convoluzione\n\nUn **filtro** (es. 3x3) scorre sull'immagine e calcola il prodotto scalare con ogni regione:\n\n```\nImmagine:        Filtro:         Output:\n[1 2 3]          [1 0 -1]\n[4 5 6]    *     [1 0 -1]    =   valore\n[7 8 9]          [1 0 -1]\n```\n\n**Iperparametri:**\n- **Numero filtri**: quante feature map produrre\n- **Dimensione kernel**: tipicamente 3x3 o 5x5\n- **Stride**: passo di scorrimento del filtro\n- **Padding**: aggiunta di bordi (same/valid)\n\n#### Cosa rilevano i filtri?\n\n- **Layer 1**: bordi, linee, colori base\n- **Layer 2-3**: texture, pattern semplici\n- **Layer 4-5**: parti di oggetti (occhi, ruote)\n- **Layer finali**: oggetti completi\n\n### 1.2 Pooling Layer\n\nIl **pooling** riduce la dimensionalita' spaziale:\n\n**Max Pooling** (piu' comune): prende il valore massimo in ogni regione\n\n```\nInput 4x4:       Output 2x2 (pool 2x2):\n[1 3 2 4]        [3 5]\n[2 1 5 3]   ->   [9 8]\n[7 9 1 2]\n[4 6 8 3]\n```\n\n**Vantaggi:**\n- Riduce parametri\n- Introduce invarianza spaziale\n- Riduce overfitting\n\n### 1.3 Architettura tipica CNN\n\n```\nInput Image\n    |\nConv -> ReLU -> Pool  (ripeti N volte)\n    |\nFlatten\n    |\nFully Connected -> ReLU\n    |\nOutput (Softmax)\n```\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup e Dataset\n\nUseremo **CIFAR-10**: 60,000 immagini 32x32 a colori in 10 classi."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU disponibile: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Caricamento CIFAR-10\n",
    "transform_basic = transforms.ToTensor()\n",
    "\n",
    "trainset_full = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transform_basic\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=transform_basic\n",
    ")\n",
    "\n",
    "# Per avere anche array numpy (utile per visualizzazioni)\n",
    "trainset_raw = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=None\n",
    ")\n",
    "testset_raw = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "# Nomi classi CIFAR-10\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# Estrai dati come numpy per preprocessing/visualizzazione\n",
    "X_train = np.array([np.array(img) for img, _ in trainset_raw])\n",
    "y_train = np.array([label for _, label in trainset_raw])\n",
    "X_test = np.array([np.array(img) for img, _ in testset_raw])\n",
    "y_test = np.array([label for _, label in testset_raw])\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Range valori: [{X_train.min()}, {X_train.max()}]\")\n",
    "print(f\"Classi: {class_names}\")\n",
    "\n",
    "# Visualizzazione esempi\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i])\n",
    "    ax.set_title(class_names[y_train[i]])\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Esempi CIFAR-10', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import os, urllib.request\n",
    "\n",
    "# GitHub Release URL for pretrained weights (update with actual URL)\n",
    "WEIGHTS_BASE_URL = os.environ.get('WEIGHTS_URL', '')\n",
    "WEIGHTS_DIR = 'pretrained_weights'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "def load_or_train(model, train_fn, weights_filename, device='cpu'):\n",
    "    \"\"\"Load pretrained weights if available, otherwise train and save.\"\"\"\n",
    "    weights_path = os.path.join(WEIGHTS_DIR, weights_filename)\n",
    "    if os.path.exists(weights_path):\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "        print(f\"Loaded pretrained weights from {weights_path}\")\n",
    "        return None  # no training history\n",
    "    elif WEIGHTS_BASE_URL:\n",
    "        try:\n",
    "            url = WEIGHTS_BASE_URL + weights_filename\n",
    "            urllib.request.urlretrieve(url, weights_path)\n",
    "            model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "            print(f\"Downloaded and loaded weights from {url}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download weights: {e}. Training from scratch...\")\n",
    "\n",
    "    history = train_fn()\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "    print(f\"Saved weights to {weights_path}\")\n",
    "    return history\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Normalizzazione a [0,1]\n",
    "X_train_norm = X_train.astype('float32') / 255.0\n",
    "X_test_norm = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Converti in tensori PyTorch (NCHW format)\n",
    "X_train_tensor = torch.from_numpy(X_train_norm).permute(0, 3, 1, 2)  # NHWC -> NCHW\n",
    "X_test_tensor = torch.from_numpy(X_test_norm).permute(0, 3, 1, 2)\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "print(\"Shape dopo preprocessing:\")\n",
    "print(f\"  X_train tensor: {X_train_tensor.shape}\")\n",
    "print(f\"  y_train tensor: {y_train_tensor.shape}\")\n",
    "print(f\"Range valori: [{X_train_tensor.min():.2f}, {X_train_tensor.max():.2f}]\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# ESERCIZIO 1: Preprocessing e Analisi Dataset di Immagini\n",
    "# ==========================================================\n",
    "# Task: Caricare, preprocessare e analizzare un dataset\n",
    "#       di immagini fashion\n",
    "# Dataset: Fashion MNIST (60000 immagini 28x28, 10 classi)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "\n",
    "# Caricamento dataset Fashion MNIST\n",
    "np.random.seed(123)\n",
    "fashion_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=None\n",
    ")\n",
    "fashion_test = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=None\n",
    ")\n",
    "\n",
    "X_train_fashion = np.array([np.array(img) for img, _ in fashion_train])\n",
    "y_train_fashion = np.array([label for _, label in fashion_train])\n",
    "X_test_fashion = np.array([np.array(img) for img, _ in fashion_test])\n",
    "y_test_fashion = np.array([label for _, label in fashion_test])\n",
    "\n",
    "# FIX: nome variabile dedicata, non sovrascriviamo class_names\n",
    "class_names_fashion = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "print(\"Dataset Fashion MNIST caricato\")\n",
    "print(\n",
    "    f\"Train: {X_train_fashion.shape}, \"\n",
    "    f\"Test: {X_test_fashion.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Range valori originali: \"\n",
    "    f\"[{X_train_fashion.min()}, {X_train_fashion.max()}]\"\n",
    ")\n",
    "\n",
    "# Step 1: Normalizzazione e reshape (channels first per PyTorch)\n",
    "X_train_fprep = (\n",
    "    X_train_fashion.astype('float32') / 255.0\n",
    ")\n",
    "X_test_fprep = (\n",
    "    X_test_fashion.astype('float32') / 255.0\n",
    ")\n",
    "X_train_fprep = X_train_fprep.reshape(-1, 1, 28, 28)  # NCHW\n",
    "X_test_fprep = X_test_fprep.reshape(-1, 1, 28, 28)\n",
    "\n",
    "print(f\"\\nDopo preprocessing:\")\n",
    "print(f\"Train shape: {X_train_fprep.shape}\")\n",
    "print(\n",
    "    f\"Range valori: \"\n",
    "    f\"[{X_train_fprep.min():.2f}, {X_train_fprep.max():.2f}]\"\n",
    ")\n",
    "\n",
    "# Step 2: Analisi distribuzione classi\n",
    "class_counts = (\n",
    "    pd.Series(y_train_fashion)\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")\n",
    "class_pct = (\n",
    "    (class_counts / len(y_train_fashion) * 100).round(2)\n",
    ")\n",
    "class_distribution = pd.DataFrame({\n",
    "    'classe': class_counts.index,\n",
    "    'nome': [class_names_fashion[i]\n",
    "             for i in class_counts.index],\n",
    "    'conteggio': class_counts.values,\n",
    "    'percentuale': class_pct.values\n",
    "})\n",
    "\n",
    "print(\"\\nDistribuzione classi nel training set:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Step 3: Visualizzazione campioni per classe\n",
    "fig, axes = plt.subplots(10, 5, figsize=(12, 20))\n",
    "\n",
    "for class_id in range(10):\n",
    "    class_indices = np.where(\n",
    "        y_train_fashion == class_id\n",
    "    )[0]\n",
    "    sample_indices = np.random.choice(\n",
    "        class_indices, size=5, replace=False\n",
    "    )\n",
    "    for i in range(5):\n",
    "        ax = axes[class_id, i]\n",
    "        ax.imshow(\n",
    "            X_train_fashion[sample_indices[i]],\n",
    "            cmap='gray'\n",
    "        )\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title(\n",
    "                class_names_fashion[class_id],\n",
    "                fontsize=10\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Calcolo statistiche per classe\n",
    "stats_per_class = []\n",
    "for class_id in range(10):\n",
    "    class_mask = y_train_fashion == class_id\n",
    "    class_images = X_train_fprep[class_mask]\n",
    "    stats_per_class.append({\n",
    "        'classe': class_id,\n",
    "        'nome': class_names_fashion[class_id],\n",
    "        'media_pixel': class_images.mean(),\n",
    "        'std_pixel': class_images.std()\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_per_class)\n",
    "print(\"\\nStatistiche per classe:\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Step 5: Visualizzazione media per classe\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for class_id in range(10):\n",
    "    class_mask = y_train_fashion == class_id\n",
    "    class_images = X_train_fprep[class_mask]\n",
    "    mean_image = class_images.mean(axis=0).squeeze()\n",
    "    axes[class_id].imshow(mean_image, cmap='gray')\n",
    "    axes[class_id].set_title(class_names_fashion[class_id])\n",
    "    axes[class_id].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confronto train/test distribution\n",
    "train_dist = (\n",
    "    pd.Series(y_train_fashion)\n",
    "    .value_counts(normalize=True)\n",
    "    .sort_index()\n",
    ")\n",
    "test_dist = (\n",
    "    pd.Series(y_test_fashion)\n",
    "    .value_counts(normalize=True)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(\n",
    "    x - width/2, train_dist.values,\n",
    "    width, label='Train', alpha=0.8\n",
    ")\n",
    "ax.bar(\n",
    "    x + width/2, test_dist.values,\n",
    "    width, label='Test', alpha=0.8\n",
    ")\n",
    "ax.set_ylabel('Proporzione')\n",
    "ax.set_xlabel('Classe')\n",
    "ax.set_title('Distribuzione Classi: Train vs Test')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(\n",
    "    class_names_fashion, rotation=45, ha='right'\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEsercizio 1 completato!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 3. Implementazione di una CNN\n\n### 3.1 CNN Semplice"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN semplice per CIFAR-10.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Primo blocco convoluzionale\n",
    "            nn.Conv2d(3, 32, 3, padding=1),   # conv1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # pool1\n",
    "\n",
    "            # Secondo blocco\n",
    "            nn.Conv2d(32, 64, 3, padding=1),   # conv2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # pool2\n",
    "\n",
    "            # Terzo blocco\n",
    "            nn.Conv2d(64, 128, 3, padding=1),  # conv3\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # pool3\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 128),       # fc1\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)          # output (no softmax - CrossEntropyLoss handles it)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Creazione modello\n",
    "model_simple = SimpleCNN().to(device)\n",
    "print(model_simple)\n",
    "total_params = sum(p.numel() for p in model_simple.parameters())\n",
    "print(f\"\\nParametri totali: {total_params:,}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisi dell'architettura:**\n\n1. **Conv1**: 32x32x3 -> 32x32x32 (32 filtri 3x3)\n2. **Pool1**: 32x32x32 -> 16x16x32 (riduzione dimensione spaziale)\n3. **Conv2**: 16x16x32 -> 16x16x64 (64 filtri)\n4. **Pool2**: 16x16x64 -> 8x8x64\n5. **Conv3**: 8x8x64 -> 8x8x128 (128 filtri)\n6. **Pool3**: 8x8x128 -> 4x4x128\n7. **Flatten**: 4x4x128 = 2048 neuroni\n8. **FC1**: 2048 -> 128\n9. **Output**: 128 -> 10\n\n### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=5,\n",
    "                lr=0.001, patience=5, patience_lr=3, device=device):\n",
    "    \"\"\"\n",
    "    Training loop generico PyTorch con early stopping e ReduceLROnPlateau.\n",
    "    Restituisce un dizionario con history (come Keras).\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=patience_lr, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - \"\n",
    "              f\"val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Restore best weights\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# Preparazione DataLoader con validation split\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "n_val = int(0.2 * len(train_dataset))\n",
    "n_train = len(train_dataset) - n_val\n",
    "train_subset, val_subset = random_split(\n",
    "    train_dataset, [n_train, n_val],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Training (with weight caching)\n",
    "history_simple = load_or_train(\n",
    "    model_simple,\n",
    "    lambda: train_model(\n",
    "        model_simple, train_loader, val_loader,\n",
    "        epochs=5, lr=0.001, patience=5, patience_lr=3\n",
    "    ),\n",
    "    'nb05_simple_cnn.pt',\n",
    "    device=device\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot learning curves\n",
    "if history_simple is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].plot(history_simple['loss'], label='Training')\n",
    "    axes[0].plot(history_simple['val_loss'], label='Validation')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    axes[1].plot(history_simple['accuracy'], label='Training')\n",
    "    axes[1].plot(history_simple['val_accuracy'], label='Validation')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Using pretrained weights - training curves not available\")\n",
    "\n",
    "# Valutazione test set\n",
    "def evaluate_model(model, X_tensor, y_tensor, device=device):\n",
    "    \"\"\"Evaluate model and return loss, accuracy, predictions.\"\"\"\n",
    "    model.eval()\n",
    "    test_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = correct / total\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    return test_loss, test_acc, all_preds, all_probs\n",
    "\n",
    "\n",
    "test_loss, test_acc, y_pred, y_pred_proba = evaluate_model(\n",
    "    model_simple, X_test_tensor, y_test_tensor\n",
    ")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred, target_names=class_names\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix - CNN Simple')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# ESERCIZIO 2: Costruzione e Training CNN da Zero\n",
    "# ==========================================================\n",
    "# Task: Costruire una CNN per classificazione binaria\n",
    "#       di cani vs gatti\n",
    "# Dataset: Subset di 4000 immagini 64x64 sintetiche\n",
    "#          (2000 cani, 2000 gatti)\n",
    "#\n",
    "# NOTA: usiamo variabili con suffisso _ex2 per non\n",
    "#       sovrascrivere i dati CIFAR-10 principali.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Generazione dataset sintetico cani vs gatti\n",
    "np.random.seed(456)\n",
    "\n",
    "def generate_synthetic_images(\n",
    "    n_samples, img_size=64, category=0\n",
    "):\n",
    "    images = np.random.rand(\n",
    "        n_samples, img_size, img_size, 3\n",
    "    ).astype('float32')\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        noise = np.random.uniform(0.8, 1.2)\n",
    "        if category == 0:  # Cani\n",
    "            gradient = np.linspace(0.3, 0.7, img_size)\n",
    "            gradient = gradient.reshape(-1, 1, 1)\n",
    "            images[i] = images[i] * 0.5 + gradient * noise * 0.5\n",
    "            images[i, :, :, 0] += 0.1 * noise\n",
    "        else:  # Gatti\n",
    "            cx, cy = img_size // 2, img_size // 2\n",
    "            Y, X = np.ogrid[:img_size, :img_size]\n",
    "            dist = np.sqrt(\n",
    "                (X - cx)**2 + (Y - cy)**2\n",
    "            ) / (img_size / 2)\n",
    "            dist = dist.clip(0, 1)\n",
    "            radial = (1 - dist).reshape(img_size, img_size, 1)\n",
    "            images[i] = images[i] * 0.5 + radial * noise * 0.5\n",
    "            images[i, :, :, 2] += 0.1 * noise\n",
    "\n",
    "    images = np.clip(images, 0, 1)\n",
    "    return images\n",
    "\n",
    "n_per_class = 2000\n",
    "X_dogs = generate_synthetic_images(n_per_class, category=0)\n",
    "X_cats = generate_synthetic_images(n_per_class, category=1)\n",
    "\n",
    "X_ex2 = np.vstack([X_dogs, X_cats])\n",
    "y_ex2 = np.array([0] * n_per_class + [1] * n_per_class)\n",
    "\n",
    "indices_ex2 = np.random.permutation(len(X_ex2))\n",
    "X_ex2 = X_ex2[indices_ex2]\n",
    "y_ex2 = y_ex2[indices_ex2]\n",
    "\n",
    "X_train_ex2, X_temp_ex2, y_train_ex2, y_temp_ex2 = (\n",
    "    train_test_split(X_ex2, y_ex2, test_size=0.3, random_state=456)\n",
    ")\n",
    "X_val_ex2, X_test_ex2, y_val_ex2, y_test_ex2 = (\n",
    "    train_test_split(X_temp_ex2, y_temp_ex2, test_size=0.5, random_state=456)\n",
    ")\n",
    "\n",
    "print(\"Dataset Cani vs Gatti\")\n",
    "print(\n",
    "    f\"Train: {X_train_ex2.shape}, \"\n",
    "    f\"Val: {X_val_ex2.shape}, \"\n",
    "    f\"Test: {X_test_ex2.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Distribuzione train: \"\n",
    "    f\"Cani={np.sum(y_train_ex2==0)}, \"\n",
    "    f\"Gatti={np.sum(y_train_ex2==1)}\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(X_train_ex2[y_train_ex2==0][i])\n",
    "    axes[0, i].set_title('Cane')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(X_train_ex2[y_train_ex2==1][i])\n",
    "    axes[1, i].set_title('Gatto')\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Costruzione architettura CNN\n",
    "class BinaryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_binary = BinaryCNN().to(device)\n",
    "print(\"\\nArchitettura CNN:\")\n",
    "print(model_binary)\n",
    "total_params = sum(p.numel() for p in model_binary.parameters())\n",
    "print(f\"Parametri totali: {total_params:,}\")\n",
    "\n",
    "# Converti in tensori (NCHW)\n",
    "X_tr_t = torch.from_numpy(X_train_ex2).permute(0, 3, 1, 2)\n",
    "y_tr_t = torch.from_numpy(y_train_ex2).float().unsqueeze(1)\n",
    "X_val_t = torch.from_numpy(X_val_ex2).permute(0, 3, 1, 2)\n",
    "y_val_t = torch.from_numpy(y_val_ex2).float().unsqueeze(1)\n",
    "X_test_t = torch.from_numpy(X_test_ex2).permute(0, 3, 1, 2)\n",
    "y_test_t = torch.from_numpy(y_test_ex2).float().unsqueeze(1)\n",
    "\n",
    "train_loader_ex2 = DataLoader(TensorDataset(X_tr_t, y_tr_t), batch_size=32, shuffle=True)\n",
    "val_loader_ex2 = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
    "test_loader_ex2 = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 2: Training con BCEWithLogitsLoss\n",
    "criterion_ex2 = nn.BCEWithLogitsLoss()\n",
    "optimizer_ex2 = optim.Adam(model_binary.parameters(), lr=0.001)\n",
    "\n",
    "history_ex2 = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
    "best_val_loss_ex2 = float('inf')\n",
    "best_state_ex2 = None\n",
    "patience_counter_ex2 = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_binary.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader_ex2:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_ex2.zero_grad()\n",
    "        outputs = model_binary(inputs)\n",
    "        loss = criterion_ex2(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ex2.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model_binary.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader_ex2:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_binary(inputs)\n",
    "            loss = criterion_ex2(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    history_ex2['loss'].append(train_loss)\n",
    "    history_ex2['accuracy'].append(train_acc)\n",
    "    history_ex2['val_loss'].append(val_loss)\n",
    "    history_ex2['val_accuracy'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/30 - loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - \"\n",
    "          f\"val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss_ex2:\n",
    "        best_val_loss_ex2 = val_loss\n",
    "        best_state_ex2 = {k: v.clone() for k, v in model_binary.state_dict().items()}\n",
    "        patience_counter_ex2 = 0\n",
    "    else:\n",
    "        patience_counter_ex2 += 1\n",
    "        if patience_counter_ex2 >= 5:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "if best_state_ex2 is not None:\n",
    "    model_binary.load_state_dict(best_state_ex2)\n",
    "\n",
    "# Step 4: Visualizzazione learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(history_ex2['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history_ex2['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_ex2['loss'], label='Train Loss')\n",
    "axes[1].plot(history_ex2['val_loss'], label='Val Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Valutazione finale\n",
    "model_binary.eval()\n",
    "test_loss_ex2 = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds_ex2 = []\n",
    "all_probs_ex2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_ex2:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_binary(inputs)\n",
    "        loss = criterion_ex2(outputs, labels)\n",
    "        test_loss_ex2 += loss.item() * inputs.size(0)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).float()\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        all_preds_ex2.append(predicted.cpu())\n",
    "        all_probs_ex2.append(probs.cpu())\n",
    "\n",
    "test_loss_ex2 = test_loss_ex2 / test_total\n",
    "test_acc_ex2 = test_correct / test_total\n",
    "y_pred_ex2 = torch.cat(all_preds_ex2).numpy().flatten().astype(int)\n",
    "y_probs_ex2 = torch.cat(all_probs_ex2).numpy().flatten()\n",
    "\n",
    "test_auc_ex2 = roc_auc_score(y_test_ex2, y_probs_ex2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RISULTATI TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Test Loss: {test_loss_ex2:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_ex2:.4f}\")\n",
    "print(f\"Test AUC: {test_auc_ex2:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_ex2 = confusion_matrix(y_test_ex2, y_pred_ex2)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_ex2, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Cane', 'Gatto'],\n",
    "    yticklabels=['Cane', 'Gatto']\n",
    ")\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_ex2, y_pred_ex2,\n",
    "    target_names=['Cane', 'Gatto']\n",
    "))\n",
    "\n",
    "print(\"\\nEsercizio 2 completato!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Augmentation per migliorare performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data Augmentation con torchvision transforms\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Visualizzazione augmentation\n",
    "sample_img = X_train[0]  # HWC uint8\n",
    "sample_pil = Image.fromarray(sample_img)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].imshow(sample_img)\n",
    "axes[0].set_title('Originale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    aug_tensor = augmentation_transform(sample_pil)\n",
    "    # Convert CHW tensor back to HWC numpy for display\n",
    "    aug_img = aug_tensor.permute(1, 2, 0).numpy()\n",
    "    axes[i].imshow(aug_img)\n",
    "    axes[i].set_title(f'Aug {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\n",
    "    'Esempi di Data Augmentation',\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 CNN Avanzata con Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AdvancedCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN avanzata con piu' layer e regolarizzazione.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Blocco 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            # Blocco 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Blocco 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_advanced = AdvancedCNN().to(device)\n",
    "total_params_adv = sum(p.numel() for p in model_advanced.parameters())\n",
    "print(f\"Parametri totali: {total_params_adv:,}\")\n",
    "\n",
    "# FIX: Proper validation split (not using test set)\n",
    "from sklearn.model_selection import train_test_split as sk_split\n",
    "\n",
    "# Split training data into train/val\n",
    "indices_all = np.arange(len(X_train_norm))\n",
    "idx_tr_adv, idx_val_adv = sk_split(\n",
    "    indices_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_tr_adv_np = X_train_norm[idx_tr_adv]\n",
    "y_tr_adv_np = y_train[idx_tr_adv]\n",
    "X_val_adv_np = X_train_norm[idx_val_adv]\n",
    "y_val_adv_np = y_train[idx_val_adv]\n",
    "\n",
    "# Create augmented dataset using torchvision transforms\n",
    "train_augment_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Custom dataset for augmentation\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_np, labels_np, transform=None):\n",
    "        \"\"\"images_np: NHWC float32 [0,1], labels_np: int array\"\"\"\n",
    "        self.images = images_np\n",
    "        self.labels = labels_np\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Convert to PIL for transforms\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        pil_img = Image.fromarray(img_uint8)\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(pil_img)\n",
    "        else:\n",
    "            img_tensor = transforms.ToTensor()(pil_img)\n",
    "        return img_tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_aug_dataset = AugmentedDataset(X_tr_adv_np, y_tr_adv_np, train_augment_transform)\n",
    "val_adv_tensor_x = torch.from_numpy(X_val_adv_np).permute(0, 3, 1, 2).float()\n",
    "val_adv_tensor_y = torch.from_numpy(y_val_adv_np).long()\n",
    "val_adv_dataset = TensorDataset(val_adv_tensor_x, val_adv_tensor_y)\n",
    "\n",
    "train_loader_adv = DataLoader(train_aug_dataset, batch_size=128, shuffle=True)\n",
    "val_loader_adv = DataLoader(val_adv_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Training with augmentation (with weight caching)\n",
    "history_advanced = load_or_train(\n",
    "    model_advanced,\n",
    "    lambda: train_model(\n",
    "        model_advanced, train_loader_adv, val_loader_adv,\n",
    "        epochs=5, lr=0.001, patience=5, patience_lr=3\n",
    "    ),\n",
    "    'nb05_advanced_cnn.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Risultati\n",
    "test_loss_adv, test_acc_adv, _, _ = evaluate_model(\n",
    "    model_advanced, X_test_tensor, y_test_tensor\n",
    ")\n",
    "print(f\"\\nCNN Avanzata - Test Accuracy: {test_acc_adv:.4f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# ESERCIZIO 3: Data Augmentation e Confronto Performance\n",
    "# ==========================================================\n",
    "# Task: Confrontare performance CNN con e senza\n",
    "#       data augmentation\n",
    "# Dataset: Subset CIFAR-10 con 3 classi (5000 immagini)\n",
    "#\n",
    "# NOTA: variabili con suffisso _ex3 per non sovrascrivere\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Caricamento subset CIFAR-10\n",
    "np.random.seed(789)\n",
    "\n",
    "selected_classes = [0, 1, 2]  # airplane, automobile, bird\n",
    "class_names_ex3 = ['airplane', 'automobile', 'bird']\n",
    "\n",
    "mask_train_ex3 = np.isin(y_train, selected_classes)\n",
    "mask_test_ex3 = np.isin(y_test, selected_classes)\n",
    "\n",
    "X_subset_ex3 = X_train[mask_train_ex3][:5000]\n",
    "y_subset_ex3 = y_train[mask_train_ex3][:5000]\n",
    "X_test_ex3 = X_test[mask_test_ex3][:1000]\n",
    "y_test_ex3 = y_test[mask_test_ex3][:1000]\n",
    "\n",
    "# FIX: remapping label con dizionario\n",
    "label_map = {old: new for new, old in enumerate(selected_classes)}\n",
    "y_subset_ex3 = np.array([label_map[y] for y in y_subset_ex3])\n",
    "y_test_ex3 = np.array([label_map[y] for y in y_test_ex3])\n",
    "\n",
    "X_subset_ex3 = X_subset_ex3.astype('float32') / 255.0\n",
    "X_test_ex3 = X_test_ex3.astype('float32') / 255.0\n",
    "\n",
    "X_tr_ex3, X_val_ex3, y_tr_ex3, y_val_ex3 = (\n",
    "    train_test_split(\n",
    "        X_subset_ex3, y_subset_ex3,\n",
    "        test_size=0.2, random_state=789\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Dataset CIFAR-10 subset (3 classi)\")\n",
    "print(\n",
    "    f\"Train: {X_tr_ex3.shape}, \"\n",
    "    f\"Val: {X_val_ex3.shape}, \"\n",
    "    f\"Test: {X_test_ex3.shape}\"\n",
    ")\n",
    "print(f\"Classi: {class_names_ex3}\")\n",
    "\n",
    "# Visualizzazione augmentation\n",
    "augment_ex3 = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, translate=(0.15, 0.15)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "sample_image_ex3 = X_tr_ex3[0]\n",
    "sample_pil_ex3 = Image.fromarray((sample_image_ex3 * 255).astype(np.uint8))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "axes[0].imshow(sample_image_ex3)\n",
    "axes[0].set_title('Originale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    aug_t = augment_ex3(sample_pil_ex3)\n",
    "    aug_np = aug_t.permute(1, 2, 0).numpy()\n",
    "    axes[i].imshow(aug_np)\n",
    "    axes[i].set_title(f'Aug {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Creazione modello CNN\n",
    "class CNNForAugmentation(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_no_aug = CNNForAugmentation().to(device)\n",
    "model_with_aug = CNNForAugmentation().to(device)\n",
    "\n",
    "print(\"\\nArchitettura CNN:\")\n",
    "print(model_no_aug)\n",
    "\n",
    "# Prepare data\n",
    "X_tr_ex3_t = torch.from_numpy(X_tr_ex3).permute(0, 3, 1, 2).float()\n",
    "y_tr_ex3_t = torch.from_numpy(y_tr_ex3).long()\n",
    "X_val_ex3_t = torch.from_numpy(X_val_ex3).permute(0, 3, 1, 2).float()\n",
    "y_val_ex3_t = torch.from_numpy(y_val_ex3).long()\n",
    "X_test_ex3_t = torch.from_numpy(X_test_ex3).permute(0, 3, 1, 2).float()\n",
    "y_test_ex3_t = torch.from_numpy(y_test_ex3).long()\n",
    "\n",
    "train_ds_no_aug = TensorDataset(X_tr_ex3_t, y_tr_ex3_t)\n",
    "val_ds_ex3 = TensorDataset(X_val_ex3_t, y_val_ex3_t)\n",
    "\n",
    "train_loader_no_aug = DataLoader(train_ds_no_aug, batch_size=32, shuffle=True)\n",
    "val_loader_ex3 = DataLoader(val_ds_ex3, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 3: Training senza augmentation\n",
    "print(\"\\nTraining SENZA data augmentation...\")\n",
    "history_no_aug = train_model(\n",
    "    model_no_aug, train_loader_no_aug, val_loader_ex3,\n",
    "    epochs=25, lr=0.001, patience=5, patience_lr=3\n",
    ")\n",
    "\n",
    "# Step 4: Training con augmentation\n",
    "print(\"\\nTraining CON data augmentation...\")\n",
    "train_aug_ds_ex3 = AugmentedDataset(\n",
    "    X_tr_ex3, y_tr_ex3, augment_ex3\n",
    ")\n",
    "train_loader_with_aug = DataLoader(train_aug_ds_ex3, batch_size=32, shuffle=True)\n",
    "\n",
    "history_with_aug = train_model(\n",
    "    model_with_aug, train_loader_with_aug, val_loader_ex3,\n",
    "    epochs=40, lr=0.001, patience=8, patience_lr=3\n",
    ")\n",
    "\n",
    "# Step 5: Confronto risultati\n",
    "test_loss_no, test_acc_no, _, _ = evaluate_model(\n",
    "    model_no_aug, X_test_ex3_t, y_test_ex3_t\n",
    ")\n",
    "test_loss_with, test_acc_with, _, _ = evaluate_model(\n",
    "    model_with_aug, X_test_ex3_t, y_test_ex3_t\n",
    ")\n",
    "\n",
    "train_acc_no = max(history_no_aug['accuracy'])\n",
    "val_acc_no = max(history_no_aug['val_accuracy'])\n",
    "train_acc_with = max(history_with_aug['accuracy'])\n",
    "val_acc_with = max(history_with_aug['val_accuracy'])\n",
    "\n",
    "import pandas as pd\n",
    "comparison_data = [\n",
    "    {\n",
    "        'modello': 'Senza Augmentation',\n",
    "        'train_acc': train_acc_no,\n",
    "        'val_acc': val_acc_no,\n",
    "        'test_acc': test_acc_no\n",
    "    },\n",
    "    {\n",
    "        'modello': 'Con Augmentation',\n",
    "        'train_acc': train_acc_with,\n",
    "        'val_acc': val_acc_with,\n",
    "        'test_acc': test_acc_with\n",
    "    }\n",
    "]\n",
    "results_ex3 = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFRONTO: SENZA vs CON Data Augmentation\")\n",
    "print(\"=\" * 70)\n",
    "print(results_ex3.to_string(index=False))\n",
    "\n",
    "# Visualizzazione confronto\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history_no_aug['accuracy'], label='Train no aug', linestyle='--')\n",
    "axes[0].plot(history_no_aug['val_accuracy'], label='Val no aug', linestyle='--')\n",
    "axes[0].plot(history_with_aug['accuracy'], label='Train with aug')\n",
    "axes[0].plot(history_with_aug['val_accuracy'], label='Val with aug')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy: Con vs Senza Augmentation')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "model_names_ex3 = ['Senza Aug', 'Con Aug']\n",
    "train_accs_ex3 = [train_acc_no, train_acc_with]\n",
    "test_accs_ex3 = [test_acc_no, test_acc_with]\n",
    "\n",
    "x_ex3 = np.arange(len(model_names_ex3))\n",
    "width_ex3 = 0.35\n",
    "\n",
    "axes[1].bar(x_ex3 - width_ex3/2, train_accs_ex3, width_ex3, label='Train Accuracy', alpha=0.8)\n",
    "axes[1].bar(x_ex3 + width_ex3/2, test_accs_ex3, width_ex3, label='Test Accuracy', alpha=0.8)\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Confronto Performance')\n",
    "axes[1].set_xticks(x_ex3)\n",
    "axes[1].set_xticklabels(model_names_ex3)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "delta_acc = (test_acc_with - test_acc_no) * 100\n",
    "gap_no = (train_acc_no - val_acc_no) * 100\n",
    "gap_with = (train_acc_with - val_acc_with) * 100\n",
    "print(f\"\\nMiglioramento test accuracy: {delta_acc:.2f}%\")\n",
    "print(\"Riduzione overfitting (val-train gap):\")\n",
    "print(f\"  Senza aug: {gap_no:.2f}%\")\n",
    "print(f\"  Con aug: {gap_with:.2f}%\")\n",
    "\n",
    "print(\"\\nEsercizio 3 completato!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 4. Transfer Learning con Foundation Models\n\nIl **Transfer Learning** sfrutta modelli pre-trained su dataset enormi (ImageNet: 14M immagini, 1000 classi).\n\n### Vantaggi:\n1. **Meno dati richiesti**: feature gia' estratte\n2. **Training piu' veloce**: solo classificatore da trainare\n3. **Performance migliori**: specialmente con pochi dati\n4. **Flessibilita'**: fine-tuning per adattamento al task\n\n### Approcci:\n- **Feature Extraction**: congela base model, train solo classificatore\n- **Fine-tuning**: scongela ultimi layer del base model\n\n### 4.1 VGG16 - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learning\n",
    "# ImageNet normalization\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Normalize CIFAR-10 data with ImageNet stats\n",
    "def normalize_imagenet(X_np):\n",
    "    \"\"\"X_np: NHWC float32 [0,255] -> NCHW tensor normalized with ImageNet stats.\"\"\"\n",
    "    X = X_np.astype('float32') / 255.0\n",
    "    X_t = torch.from_numpy(X).permute(0, 3, 1, 2)  # NCHW\n",
    "    for c in range(3):\n",
    "        X_t[:, c] = (X_t[:, c] - imagenet_mean[c]) / imagenet_std[c]\n",
    "    return X_t\n",
    "\n",
    "X_train_vgg = normalize_imagenet(X_train)\n",
    "X_test_vgg = normalize_imagenet(X_test)\n",
    "y_train_t = torch.from_numpy(y_train).long()\n",
    "y_test_t = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Caricamento VGG16 pre-trained su ImageNet\n",
    "base_model_vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congela tutti i parametri\n",
    "for param in base_model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_frozen = sum(1 for p in base_model_vgg.parameters() if not p.requires_grad)\n",
    "print(\"VGG16 caricato\")\n",
    "print(f\"Layer congelati: {n_frozen} parameter groups\")\n",
    "print(f\"Parametri totali: {sum(p.numel() for p in base_model_vgg.parameters()):,}\")\n",
    "\n",
    "# Costruzione modello completo: VGG16 features + custom classifier\n",
    "class VGG16Transfer(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = base_model_vgg.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_vgg = VGG16Transfer().to(device)\n",
    "print(model_vgg)\n",
    "\n",
    "# Prepare data loaders\n",
    "train_vgg_ds = TensorDataset(X_train_vgg, y_train_t)\n",
    "n_val_vgg = int(0.2 * len(train_vgg_ds))\n",
    "n_train_vgg = len(train_vgg_ds) - n_val_vgg\n",
    "train_vgg_sub, val_vgg_sub = random_split(\n",
    "    train_vgg_ds, [n_train_vgg, n_val_vgg],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader_vgg = DataLoader(train_vgg_sub, batch_size=128, shuffle=True)\n",
    "val_loader_vgg = DataLoader(val_vgg_sub, batch_size=128, shuffle=False)\n",
    "\n",
    "# Training (with weight caching)\n",
    "history_vgg = load_or_train(\n",
    "    model_vgg,\n",
    "    lambda: train_model(\n",
    "        model_vgg, train_loader_vgg, val_loader_vgg,\n",
    "        epochs=10, lr=0.001, patience=5, patience_lr=3\n",
    "    ),\n",
    "    'nb05_vgg16_feature.pt',\n",
    "    device=device\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Fine-tuning\n\nDopo aver trainato il classificatore, possiamo **scongelare** alcuni layer finali del base model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scongela gli ultimi layer delle features di VGG16\n",
    "# VGG16 features has layers indexed 0-30\n",
    "# Unfreeze the last convolutional block (layers 24-30)\n",
    "for i, layer in enumerate(model_vgg.features):\n",
    "    if i >= 24:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "print(\"Layer trainable dopo fine-tuning:\")\n",
    "for i, layer in enumerate(model_vgg.features):\n",
    "    has_params = any(True for _ in layer.parameters())\n",
    "    if has_params:\n",
    "        trainable = any(p.requires_grad for p in layer.parameters())\n",
    "        print(f\"  features[{i}]: {layer.__class__.__name__} - Trainable: {trainable}\")\n",
    "\n",
    "# Fine-tuning con learning rate piu' basso (with weight caching)\n",
    "history_finetune = load_or_train(\n",
    "    model_vgg,\n",
    "    lambda: train_model(\n",
    "        model_vgg, train_loader_vgg, val_loader_vgg,\n",
    "        epochs=10, lr=1e-5, patience=5, patience_lr=3\n",
    "    ),\n",
    "    'nb05_vgg16_finetuned.pt',\n",
    "    device=device\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ResNet50 - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ResNet50 con skip connections\n",
    "base_model_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congela tutti i parametri\n",
    "for param in base_model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class ResNet50Transfer(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Use all layers except the final FC\n",
    "        self.backbone = nn.Sequential(*list(base_model_resnet.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_resnet = ResNet50Transfer().to(device)\n",
    "\n",
    "# Reuse ImageNet-normalized data\n",
    "X_train_resnet = X_train_vgg  # Same normalization\n",
    "X_test_resnet = X_test_vgg\n",
    "\n",
    "train_resnet_ds = TensorDataset(X_train_resnet, y_train_t)\n",
    "n_val_rn = int(0.2 * len(train_resnet_ds))\n",
    "n_train_rn = len(train_resnet_ds) - n_val_rn\n",
    "train_rn_sub, val_rn_sub = random_split(\n",
    "    train_resnet_ds, [n_train_rn, n_val_rn],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader_rn = DataLoader(train_rn_sub, batch_size=128, shuffle=True)\n",
    "val_loader_rn = DataLoader(val_rn_sub, batch_size=128, shuffle=False)\n",
    "\n",
    "history_resnet = load_or_train(\n",
    "    model_resnet,\n",
    "    lambda: train_model(\n",
    "        model_resnet, train_loader_rn, val_loader_rn,\n",
    "        epochs=5, lr=0.001, patience=3, patience_lr=2\n",
    "    ),\n",
    "    'nb05_resnet50.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "test_loss_rn, test_acc_rn, _, _ = evaluate_model(\n",
    "    model_resnet, X_test_resnet, y_test_t\n",
    ")\n",
    "print(f\"ResNet50 - Test Accuracy: {test_acc_rn:.4f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 EfficientNet - State-of-the-art"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# EfficientNetB0 - bilancia accuratezza e efficienza\n",
    "base_model_eff = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congela tutti i parametri\n",
    "for param in base_model_eff.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class EfficientNetTransfer(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.backbone = base_model_eff.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_efficient = EfficientNetTransfer().to(device)\n",
    "\n",
    "# EfficientNet uses same ImageNet normalization\n",
    "X_train_eff = X_train_vgg\n",
    "X_test_eff = X_test_vgg\n",
    "\n",
    "train_eff_ds = TensorDataset(X_train_eff, y_train_t)\n",
    "n_val_eff = int(0.2 * len(train_eff_ds))\n",
    "n_train_eff = len(train_eff_ds) - n_val_eff\n",
    "train_eff_sub, val_eff_sub = random_split(\n",
    "    train_eff_ds, [n_train_eff, n_val_eff],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader_eff = DataLoader(train_eff_sub, batch_size=128, shuffle=True)\n",
    "val_loader_eff = DataLoader(val_eff_sub, batch_size=128, shuffle=False)\n",
    "\n",
    "history_efficient = load_or_train(\n",
    "    model_efficient,\n",
    "    lambda: train_model(\n",
    "        model_efficient, train_loader_eff, val_loader_eff,\n",
    "        epochs=5, lr=0.001, patience=3, patience_lr=2\n",
    "    ),\n",
    "    'nb05_efficientnet.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "test_loss_eff, test_acc_eff, _, _ = evaluate_model(\n",
    "    model_efficient, X_test_eff, y_test_t\n",
    ")\n",
    "print(f\"EfficientNetB0 - Test Accuracy: {test_acc_eff:.4f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Confronto Modelli"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Valutazione tutti i modelli\n",
    "modelli = {\n",
    "    'CNN Simple': (model_simple, X_test_tensor, y_test_tensor),\n",
    "    'CNN Advanced': (model_advanced, X_test_tensor, y_test_tensor),\n",
    "    'VGG16': (model_vgg, X_test_vgg, y_test_t),\n",
    "    'ResNet50': (model_resnet, X_test_resnet, y_test_t),\n",
    "    'EfficientNetB0': (model_efficient, X_test_eff, y_test_t),\n",
    "}\n",
    "\n",
    "risultati = []\n",
    "\n",
    "for nome, (modello, X_eval, y_eval) in modelli.items():\n",
    "    t_loss, t_acc, _, _ = evaluate_model(modello, X_eval, y_eval)\n",
    "    n_params = sum(p.numel() for p in modello.parameters())\n",
    "\n",
    "    risultati.append({\n",
    "        'Modello': nome,\n",
    "        'Test Accuracy': t_acc,\n",
    "        'Parametri': n_params\n",
    "    })\n",
    "\n",
    "df_risultati = pd.DataFrame(risultati)\n",
    "df_risultati = df_risultati.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO MODELLI\")\n",
    "print(\"=\" * 60)\n",
    "print(df_risultati.to_string(index=False))\n",
    "\n",
    "# Visualizzazione\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "df_sorted = df_risultati.sort_values('Test Accuracy', ascending=True)\n",
    "axes[0].barh(\n",
    "    df_sorted['Modello'],\n",
    "    df_sorted['Test Accuracy'],\n",
    "    color='steelblue', alpha=0.8\n",
    ")\n",
    "axes[0].set_xlabel('Test Accuracy')\n",
    "axes[0].set_title('Confronto Accuracy')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Parametri\n",
    "axes[1].barh(\n",
    "    df_sorted['Modello'],\n",
    "    df_sorted['Parametri'] / 1e6,\n",
    "    color='coral', alpha=0.8\n",
    ")\n",
    "axes[1].set_xlabel('Parametri (milioni)')\n",
    "axes[1].set_title('Confronto Parametri')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# ESERCIZIO 4: Transfer Learning e Fine-Tuning\n",
    "# ==========================================================\n",
    "# Task: Usare MobileNetV2 pre-trained per classificazione\n",
    "#       con fine-tuning\n",
    "# Dataset: Flowers (1000 immagini, 5 classi di fiori)\n",
    "#\n",
    "# NOTA: variabili con suffisso _ex4\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generazione dataset sintetico fiori\n",
    "np.random.seed(999)\n",
    "\n",
    "def generate_flower_images(n_samples, img_size=96, flower_type=0):\n",
    "    images = np.random.rand(n_samples, img_size, img_size, 3).astype('float32')\n",
    "    color_schemes = [\n",
    "        [1.0, 0.2, 0.2],  # Rose - rosso\n",
    "        [1.0, 1.0, 0.3],  # Sunflower - giallo\n",
    "        [0.6, 0.3, 1.0],  # Tulip - viola\n",
    "        [1.0, 0.5, 0.8],  # Daisy - rosa\n",
    "        [0.3, 0.5, 1.0],  # Iris - blu\n",
    "    ]\n",
    "    for i in range(n_samples):\n",
    "        center = img_size // 2\n",
    "        for y in range(img_size):\n",
    "            for x in range(img_size):\n",
    "                dist = np.sqrt((x - center)**2 + (y - center)**2)\n",
    "                if dist < img_size // 3:\n",
    "                    images[i, y, x] = color_schemes[flower_type]\n",
    "                    images[i, y, x] += np.random.randn(3) * 0.1\n",
    "    images = np.clip(images, 0, 1)\n",
    "    return images\n",
    "\n",
    "flower_names = ['Rose', 'Sunflower', 'Tulip', 'Daisy', 'Iris']\n",
    "samples_per_class = 200\n",
    "\n",
    "X_flowers = []\n",
    "y_flowers = []\n",
    "for class_id, flower_name in enumerate(flower_names):\n",
    "    images = generate_flower_images(samples_per_class, flower_type=class_id)\n",
    "    X_flowers.append(images)\n",
    "    y_flowers.extend([class_id] * samples_per_class)\n",
    "\n",
    "X_flowers = np.vstack(X_flowers)\n",
    "y_flowers = np.array(y_flowers)\n",
    "\n",
    "indices_ex4 = np.random.permutation(len(X_flowers))\n",
    "X_flowers = X_flowers[indices_ex4]\n",
    "y_flowers = y_flowers[indices_ex4]\n",
    "\n",
    "X_train_ex4, X_temp_ex4, y_train_ex4, y_temp_ex4 = (\n",
    "    train_test_split(X_flowers, y_flowers, test_size=0.3, random_state=999, stratify=y_flowers)\n",
    ")\n",
    "X_val_ex4, X_test_ex4, y_val_ex4, y_test_ex4 = (\n",
    "    train_test_split(X_temp_ex4, y_temp_ex4, test_size=0.5, random_state=999, stratify=y_temp_ex4)\n",
    ")\n",
    "\n",
    "print(\"Dataset Flowers\")\n",
    "print(f\"Train: {X_train_ex4.shape}, Val: {X_val_ex4.shape}, Test: {X_test_ex4.shape}\")\n",
    "print(f\"Classi: {flower_names}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    idx = np.where(y_train_ex4 == i)[0][0]\n",
    "    axes[i].imshow(X_train_ex4[idx])\n",
    "    axes[i].set_title(flower_names[i])\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Caricamento base model MobileNetV2\n",
    "base_model_ex4 = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congela tutti i parametri\n",
    "for param in base_model_ex4.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f\"\\nMobileNetV2 caricato\")\n",
    "print(f\"Parametri base model: {sum(p.numel() for p in base_model_ex4.parameters()):,}\")\n",
    "\n",
    "# Step 2: Costruzione modello completo\n",
    "class MobileNetTransfer(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.features = base_model.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_transfer_ex4 = MobileNetTransfer(base_model_ex4).to(device)\n",
    "\n",
    "print(\"\\nModello completo:\")\n",
    "print(model_transfer_ex4)\n",
    "print(f\"Parametri totali: {sum(p.numel() for p in model_transfer_ex4.parameters()):,}\")\n",
    "print(f\"Parametri trainable: {sum(p.numel() for p in model_transfer_ex4.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Prepare data - normalize with ImageNet stats\n",
    "def normalize_imagenet_from_float(X_np):\n",
    "    \"\"\"X_np: NHWC float32 [0,1] -> NCHW tensor normalized with ImageNet stats.\"\"\"\n",
    "    X_t = torch.from_numpy(X_np).permute(0, 3, 1, 2)\n",
    "    for c in range(3):\n",
    "        X_t[:, c] = (X_t[:, c] - imagenet_mean[c]) / imagenet_std[c]\n",
    "    return X_t\n",
    "\n",
    "X_tr_ex4_t = normalize_imagenet_from_float(X_train_ex4)\n",
    "y_tr_ex4_t = torch.from_numpy(y_train_ex4).long()\n",
    "X_val_ex4_t = normalize_imagenet_from_float(X_val_ex4)\n",
    "y_val_ex4_t = torch.from_numpy(y_val_ex4).long()\n",
    "X_test_ex4_t = normalize_imagenet_from_float(X_test_ex4)\n",
    "y_test_ex4_t = torch.from_numpy(y_test_ex4).long()\n",
    "\n",
    "train_loader_ex4 = DataLoader(TensorDataset(X_tr_ex4_t, y_tr_ex4_t), batch_size=32, shuffle=True)\n",
    "val_loader_ex4 = DataLoader(TensorDataset(X_val_ex4_t, y_val_ex4_t), batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 3: Training fase 1 - solo classificatore\n",
    "print(\"\\nFASE 1: Training solo classificatore...\")\n",
    "history_phase1 = load_or_train(\n",
    "    model_transfer_ex4,\n",
    "    lambda: train_model(\n",
    "        model_transfer_ex4, train_loader_ex4, val_loader_ex4,\n",
    "        epochs=15, lr=0.001, patience=3, patience_lr=2\n",
    "    ),\n",
    "    'nb05_mobilenet_phase1.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "_, val_acc_p1, _, _ = evaluate_model(model_transfer_ex4, X_val_ex4_t, y_val_ex4_t)\n",
    "print(f\"Fase 1 - Val Accuracy: {val_acc_p1:.4f}\")\n",
    "\n",
    "# Step 4: Fine-tuning - scongelare ultimi layer\n",
    "# Unfreeze last 5 inverted residual blocks (features[-5:])\n",
    "for i, block in enumerate(model_transfer_ex4.features):\n",
    "    if i >= len(model_transfer_ex4.features) - 5:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "n_trainable = sum(1 for p in model_transfer_ex4.parameters() if p.requires_grad)\n",
    "print(f\"\\nParametri trainable dopo fine-tuning: {n_trainable}\")\n",
    "\n",
    "# Step 5: Training fase 2 - fine-tuning\n",
    "print(\"\\nFASE 2: Fine-tuning...\")\n",
    "history_phase2 = load_or_train(\n",
    "    model_transfer_ex4,\n",
    "    lambda: train_model(\n",
    "        model_transfer_ex4, train_loader_ex4, val_loader_ex4,\n",
    "        epochs=10, lr=0.0001, patience=3, patience_lr=2\n",
    "    ),\n",
    "    'nb05_mobilenet_phase2.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "_, val_acc_p2, _, _ = evaluate_model(model_transfer_ex4, X_val_ex4_t, y_val_ex4_t)\n",
    "_, test_acc_ex4, _, _ = evaluate_model(model_transfer_ex4, X_test_ex4_t, y_test_ex4_t)\n",
    "\n",
    "print(f\"\\nFase 2 - Val Accuracy: {val_acc_p2:.4f}\")\n",
    "print(f\"Test Accuracy finale: {test_acc_ex4:.4f}\")\n",
    "\n",
    "# Visualizzazione risultati\n",
    "results_ex4 = pd.DataFrame({\n",
    "    'Fase': ['Feature Extraction', 'Fine-Tuning'],\n",
    "    'Val Accuracy': [val_acc_p1, val_acc_p2],\n",
    "    'Miglioramento': [0, val_acc_p2 - val_acc_p1]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RISULTATI TRANSFER LEARNING\")\n",
    "print(\"=\" * 70)\n",
    "print(results_ex4.to_string(index=False))\n",
    "\n",
    "# Plot learning curves entrambe le fasi\n",
    "if history_phase1 is not None and history_phase2 is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    all_train_acc = history_phase1['accuracy'] + history_phase2['accuracy']\n",
    "    all_val_acc = history_phase1['val_accuracy'] + history_phase2['val_accuracy']\n",
    "    phase1_epochs = len(history_phase1['accuracy'])\n",
    "\n",
    "    axes[0].plot(range(len(all_train_acc)), all_train_acc, label='Train')\n",
    "    axes[0].plot(range(len(all_val_acc)), all_val_acc, label='Validation')\n",
    "    axes[0].axvline(x=phase1_epochs, color='r', linestyle='--', label='Inizio Fine-Tuning')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_title('Learning Curves: Feature Extraction + Fine-Tuning')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    phases = ['Feature\\nExtraction', 'Fine-Tuning']\n",
    "    val_accs_ex4 = [val_acc_p1, val_acc_p2]\n",
    "    colors_ex4 = ['skyblue', 'lightcoral']\n",
    "\n",
    "    axes[1].bar(phases, val_accs_ex4, color=colors_ex4, alpha=0.8)\n",
    "    axes[1].axhline(y=test_acc_ex4, color='green', linestyle='--', label=f'Test Acc: {test_acc_ex4:.4f}')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Confronto Fasi Transfer Learning')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Using pretrained weights - training curves not available\")\n",
    "    phases = ['Feature\\nExtraction', 'Fine-Tuning']\n",
    "    val_accs_ex4 = [val_acc_p1, val_acc_p2]\n",
    "    colors_ex4 = ['skyblue', 'lightcoral']\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.bar(phases, val_accs_ex4, color=colors_ex4, alpha=0.8)\n",
    "    ax.axhline(y=test_acc_ex4, color='green', linestyle='--', label=f'Test Acc: {test_acc_ex4:.4f}')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Confronto Fasi Transfer Learning')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "_, _, y_pred_ex4, _ = evaluate_model(model_transfer_ex4, X_test_ex4_t, y_test_ex4_t)\n",
    "\n",
    "cm_ex4 = confusion_matrix(y_test_ex4, y_pred_ex4)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_ex4, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=flower_names,\n",
    "    yticklabels=flower_names\n",
    ")\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix - Transfer Learning')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_ex4, y_pred_ex4, target_names=flower_names))\n",
    "\n",
    "improvement = (val_acc_p2 - val_acc_p1) * 100\n",
    "print(f\"\\nMiglioramento da Feature Extraction a Fine-Tuning: {improvement:.2f}%\")\n",
    "\n",
    "print(\"\\nEsercizio 4 completato!\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 5. Utilizzo di Foundation Models tramite API\n\nMolti servizi cloud offrono API per Computer Vision senza dover trainare modelli.\n\n### 5.1 Simulazione API Google Cloud Vision"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "class SimulatedVisionAPI:\n",
    "    \"\"\"\n",
    "    Simulazione di una API per Computer Vision.\n",
    "    In produzione, useresti chiamate HTTP reali:\n",
    "    - Google Cloud Vision API\n",
    "    - AWS Rekognition\n",
    "    - Azure Computer Vision\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device=device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.class_names = [\n",
    "            'airplane', 'automobile', 'bird',\n",
    "            'cat', 'deer', 'dog', 'frog',\n",
    "            'horse', 'ship', 'truck'\n",
    "        ]\n",
    "\n",
    "    def predict_from_array(self, image_array, top_k=5):\n",
    "        \"\"\"Predice da un array numpy (HWC, uint8 o float).\"\"\"\n",
    "        img = image_array.astype('float32')\n",
    "        if img.max() > 1:\n",
    "            img = img / 255.0\n",
    "\n",
    "        # Convert to tensor NCHW\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(img_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1)[0].cpu().numpy()\n",
    "\n",
    "        top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'class': self.class_names[idx],\n",
    "                'confidence': float(probs[idx])\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            'predictions': results,\n",
    "            'top_class': results[0]['class'],\n",
    "            'top_confidence': results[0]['confidence']\n",
    "        }\n",
    "\n",
    "\n",
    "# Test API simulata\n",
    "api = SimulatedVisionAPI(model_simple)\n",
    "\n",
    "# Predizione su alcune immagini di test\n",
    "print(\"Test API Computer Vision\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(5):\n",
    "    result = api.predict_from_array(X_test[i])\n",
    "    true_label = class_names[y_test[i]]\n",
    "    pred_label = result['top_class']\n",
    "    conf = result['top_confidence']\n",
    "    status = \"OK\" if true_label == pred_label else \"MISS\"\n",
    "    print(\n",
    "        f\"[{status}] True: {true_label:>12s} | \"\n",
    "        f\"Pred: {pred_label:>12s} \"\n",
    "        f\"(conf: {conf:.2%})\"\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Esempio: REST API con Flask (struttura)\n\nIn produzione, potresti esporre il modello via REST API:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Questo e' codice illustrativo (non eseguibile)\n",
    "\"\"\"\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Carica modello all'avvio\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Ricevi immagine\n",
    "    file = request.files['image']\n",
    "    img = Image.open(file).resize((32, 32))\n",
    "\n",
    "    # Preprocessing\n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    # Predizione\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        class_idx = probs.argmax(1).item()\n",
    "\n",
    "    return jsonify({\n",
    "        'class': class_names[class_idx],\n",
    "        'confidence': float(probs[0][class_idx])\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\"\"\"\n",
    "print(\"Codice Flask illustrativo (non eseguito)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 6. Visualizzazione Feature Maps\n\nVisualizziamo cosa \"vede\" la CNN a diversi livelli."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reuse the already-trained model_simple for meaningful feature maps\n",
    "# Use PyTorch hooks to extract feature maps\n",
    "\n",
    "print(\"Feature extractor creato dal modello trainato (model_simple)!\")\n",
    "print(model_simple)\n",
    "\n",
    "# Define which layers to visualize\n",
    "# model_simple.features has: Conv2d(0), BN(1), ReLU(2), MaxPool(3),\n",
    "#                            Conv2d(4), BN(5), ReLU(6), MaxPool(7),\n",
    "#                            Conv2d(8), BN(9), ReLU(10), MaxPool(11)\n",
    "target_layers = {\n",
    "    'conv1': model_simple.features[0],\n",
    "    'conv2': model_simple.features[4],\n",
    "    'conv3': model_simple.features[8],\n",
    "}\n",
    "\n",
    "# Register hooks to capture activations\n",
    "activations = {}\n",
    "hooks = []\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "for name, layer in target_layers.items():\n",
    "    h = layer.register_forward_hook(get_activation(name))\n",
    "    hooks.append(h)\n",
    "\n",
    "# Run a forward pass with a test image\n",
    "test_img = X_test_norm[0]  # HWC float32 [0,1]\n",
    "test_tensor = torch.from_numpy(test_img).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "\n",
    "model_simple.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model_simple(test_tensor)\n",
    "\n",
    "# Remove hooks\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "print(f\"Dimensione immagine: {test_img.shape}\")\n",
    "\n",
    "# Visualizza immagine originale\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_img)\n",
    "plt.title(\n",
    "    f\"Immagine Originale: {class_names[y_test[0]]}\",\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizza feature maps\n",
    "layer_display_names = {\n",
    "    'conv1': 'Conv1 (32 filtri)',\n",
    "    'conv2': 'Conv2 (64 filtri)',\n",
    "    'conv3': 'Conv3 (128 filtri)',\n",
    "}\n",
    "\n",
    "for layer_key in ['conv1', 'conv2', 'conv3']:\n",
    "    layer_act = activations[layer_key][0]  # Remove batch dim: [C, H, W]\n",
    "    n_features = layer_act.shape[0]\n",
    "    size = layer_act.shape[1]\n",
    "\n",
    "    n_cols = 8\n",
    "    n_rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < min(n_features, 16):\n",
    "            feature_map = layer_act[i].numpy()  # [H, W]\n",
    "            ax.imshow(feature_map, cmap='viridis')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f'F{i}', fontsize=8)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    display_name = layer_display_names[layer_key]\n",
    "    plt.suptitle(\n",
    "        f'{display_name}: {n_features} filtri, '\n",
    "        f'feature map {size}x{size}',\n",
    "        fontsize=14, fontweight='bold'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Osservazioni** (feature maps dal modello trainato `model_simple`):\n- **Layer 1 (conv1)**: rileva bordi, colori base\n- **Layer 2 (conv2)**: pattern piu' complessi, combinazioni di bordi\n- **Layer 3 (conv3)**: rappresentazioni astratte di alto livello\n\nLe feature maps provengono dal modello gia' addestrato, quindi riflettono pattern effettivamente appresi durante il training.\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Esercitazione: Sistema Completo di Computer Vision\n\nImplementa un sistema end-to-end per classificazione immagini."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SistemaComputerVision:\n",
    "    \"\"\"\n",
    "    Sistema completo per Computer Vision.\n",
    "    Supporta training da zero e transfer learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, approccio='cnn_custom', base_model_name='VGG16'):\n",
    "        self.approccio = approccio\n",
    "        self.base_model_name = base_model_name\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.class_names = None\n",
    "        self.base_model = None\n",
    "        self.input_shape = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def build_model(self, input_shape, num_classes):\n",
    "        \"\"\"Costruisce il modello in base all'approccio.\"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        C, H, W = input_shape  # PyTorch: CHW\n",
    "\n",
    "        if self.approccio == 'cnn_custom':\n",
    "            class CustomCNN(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "                    self.features = nn.Sequential(\n",
    "                        nn.Conv2d(C, 32, 3, padding=1),\n",
    "                        nn.BatchNorm2d(32), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2), nn.Dropout(0.2),\n",
    "\n",
    "                        nn.Conv2d(32, 64, 3, padding=1),\n",
    "                        nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2), nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Conv2d(64, 128, 3, padding=1),\n",
    "                        nn.BatchNorm2d(128), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2), nn.Dropout(0.4),\n",
    "\n",
    "                        nn.Conv2d(128, 256, 3, padding=1),\n",
    "                        nn.BatchNorm2d(256), nn.ReLU(),\n",
    "                        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    )\n",
    "                    self.classifier = nn.Sequential(\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(256, 256), nn.ReLU(),\n",
    "                        nn.BatchNorm1d(256), nn.Dropout(0.5),\n",
    "                        nn.Linear(256, num_classes)\n",
    "                    )\n",
    "                def forward(self, x):\n",
    "                    return self.classifier(self.features(x))\n",
    "\n",
    "            self.model = CustomCNN().to(self.device)\n",
    "\n",
    "        elif self.approccio == 'transfer_learning':\n",
    "            model_map = {\n",
    "                'VGG16': (models.vgg16, models.VGG16_Weights.IMAGENET1K_V1),\n",
    "                'ResNet50': (models.resnet50, models.ResNet50_Weights.IMAGENET1K_V1),\n",
    "                'EfficientNetB0': (models.efficientnet_b0, models.EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "            }\n",
    "            if self.base_model_name not in model_map:\n",
    "                raise ValueError(f\"Base model non supportato: {self.base_model_name}\")\n",
    "\n",
    "            ModelClass, weights = model_map[self.base_model_name]\n",
    "            self.base_model = ModelClass(weights=weights)\n",
    "\n",
    "            for param in self.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Get feature extractor\n",
    "            if self.base_model_name == 'VGG16':\n",
    "                features = self.base_model.features\n",
    "                feat_dim = 512\n",
    "            elif self.base_model_name == 'ResNet50':\n",
    "                features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "                feat_dim = 2048\n",
    "            elif self.base_model_name == 'EfficientNetB0':\n",
    "                features = self.base_model.features\n",
    "                feat_dim = 1280\n",
    "\n",
    "            class TransferModel(nn.Module):\n",
    "                def __init__(self, features, feat_dim, num_classes):\n",
    "                    super().__init__()\n",
    "                    self.features = features\n",
    "                    self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "                    self.classifier = nn.Sequential(\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(feat_dim, 256), nn.ReLU(),\n",
    "                        nn.BatchNorm1d(256), nn.Dropout(0.5),\n",
    "                        nn.Linear(256, num_classes)\n",
    "                    )\n",
    "                def forward(self, x):\n",
    "                    x = self.features(x)\n",
    "                    x = self.pool(x)\n",
    "                    return self.classifier(x)\n",
    "\n",
    "            self.model = TransferModel(features, feat_dim, num_classes).to(self.device)\n",
    "\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        print(f\"Modello {self.approccio} costruito\")\n",
    "        print(f\"Parametri totali: {total_params:,}\")\n",
    "\n",
    "    def _normalize(self, X_tensor):\n",
    "        \"\"\"Normalizza con preprocessing specifico per il modello.\"\"\"\n",
    "        if self.approccio == 'transfer_learning':\n",
    "            # ImageNet normalization\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(X_tensor.device)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(X_tensor.device)\n",
    "            return (X_tensor - mean) / std\n",
    "        return X_tensor\n",
    "\n",
    "    def compile_model(self, learning_rate=0.001):\n",
    "        \"\"\"Prepara optimizer (PyTorch non ha compile separato).\"\"\"\n",
    "        self.lr = learning_rate\n",
    "        print(\"Modello compilato\")\n",
    "\n",
    "    def train(self, X_np, y_np, X_val=None, y_val=None, epochs=20, batch_size=128, use_augmentation=True):\n",
    "        \"\"\"Addestra il modello.\"\"\"\n",
    "        # Convert to tensors\n",
    "        X_t = torch.from_numpy(X_np.transpose(0, 3, 1, 2) if X_np.ndim == 4 and X_np.shape[-1] in [1,3] else X_np).float()\n",
    "        y_t = torch.from_numpy(y_np).long()\n",
    "        X_t = self._normalize(X_t)\n",
    "\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_v = torch.from_numpy(X_val.transpose(0, 3, 1, 2) if X_val.ndim == 4 and X_val.shape[-1] in [1,3] else X_val).float()\n",
    "            y_v = torch.from_numpy(y_val).long()\n",
    "            X_v = self._normalize(X_v)\n",
    "        else:\n",
    "            n = len(X_t)\n",
    "            n_val = int(0.2 * n)\n",
    "            perm = torch.randperm(n)\n",
    "            X_v, y_v = X_t[perm[:n_val]], y_t[perm[:n_val]]\n",
    "            X_t, y_t = X_t[perm[n_val:]], y_t[perm[n_val:]]\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(X_v, y_v), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        if use_augmentation and self.approccio == 'cnn_custom':\n",
    "            print(\"Training con data augmentation...\")\n",
    "        else:\n",
    "            print(\"Training senza data augmentation...\")\n",
    "\n",
    "        self.history = train_model(\n",
    "            self.model, train_loader, val_loader,\n",
    "            epochs=epochs, lr=self.lr, patience=5, patience_lr=3, device=self.device\n",
    "        )\n",
    "        print(\"Training completato\")\n",
    "\n",
    "    def fine_tune(self, X_np, y_np, X_val=None, y_val=None, epochs=10, layers_to_unfreeze=4):\n",
    "        \"\"\"Fine-tuning per transfer learning.\"\"\"\n",
    "        if self.approccio != 'transfer_learning':\n",
    "            raise ValueError(\"Fine-tuning solo per transfer learning\")\n",
    "\n",
    "        # Unfreeze last N layers of features\n",
    "        feature_layers = list(self.model.features.children())\n",
    "        for layer in feature_layers[-layers_to_unfreeze:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        print(f\"Fine-tuning: scongelamento ultimi {layers_to_unfreeze} layer...\")\n",
    "\n",
    "        old_lr = self.lr\n",
    "        self.lr = 1e-5\n",
    "\n",
    "        X_t = torch.from_numpy(X_np.transpose(0, 3, 1, 2) if X_np.ndim == 4 and X_np.shape[-1] in [1,3] else X_np).float()\n",
    "        y_t = torch.from_numpy(y_np).long()\n",
    "        X_t = self._normalize(X_t)\n",
    "\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_v = torch.from_numpy(X_val.transpose(0, 3, 1, 2) if X_val.ndim == 4 and X_val.shape[-1] in [1,3] else X_val).float()\n",
    "            y_v = torch.from_numpy(y_val).long()\n",
    "            X_v = self._normalize(X_v)\n",
    "        else:\n",
    "            n = len(X_t)\n",
    "            n_val = int(0.2 * n)\n",
    "            perm = torch.randperm(n)\n",
    "            X_v, y_v = X_t[perm[:n_val]], y_t[perm[:n_val]]\n",
    "            X_t, y_t = X_t[perm[n_val:]], y_t[perm[n_val:]]\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(X_v, y_v), batch_size=128, shuffle=False)\n",
    "\n",
    "        ft_history = train_model(\n",
    "            self.model, train_loader, val_loader,\n",
    "            epochs=epochs, lr=self.lr, patience=3, patience_lr=2, device=self.device\n",
    "        )\n",
    "\n",
    "        if self.history is not None:\n",
    "            for key in self.history:\n",
    "                if key in ft_history:\n",
    "                    self.history[key].extend(ft_history[key])\n",
    "        else:\n",
    "            self.history = ft_history\n",
    "\n",
    "        self.lr = old_lr\n",
    "        print(\"Fine-tuning completato\")\n",
    "\n",
    "    def evaluate(self, X_np, y_np, class_names=None):\n",
    "        \"\"\"Valuta il modello.\"\"\"\n",
    "        self.class_names = class_names\n",
    "\n",
    "        X_t = torch.from_numpy(X_np.transpose(0, 3, 1, 2) if X_np.ndim == 4 and X_np.shape[-1] in [1,3] else X_np).float()\n",
    "        y_t = torch.from_numpy(y_np).long()\n",
    "        X_t = self._normalize(X_t)\n",
    "\n",
    "        t_loss, t_acc, y_pred, y_proba = evaluate_model(self.model, X_t, y_t, device=self.device)\n",
    "\n",
    "        report = classification_report(y_np, y_pred, target_names=class_names)\n",
    "        cm = confusion_matrix(y_np, y_pred)\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel('Predetto')\n",
    "        plt.ylabel('Reale')\n",
    "        plt.title(f'Confusion Matrix - {self.approccio}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Test Loss: {t_loss:.4f}\")\n",
    "        print(f\"Test Accuracy: {t_acc:.4f}\")\n",
    "        print(f\"\\nClassification Report:\\n{report}\")\n",
    "\n",
    "        return {'accuracy': t_acc, 'loss': t_loss, 'confusion_matrix': cm, 'classification_report': report}\n",
    "\n",
    "    def visualize_predictions(self, X_np, y_np, n=10):\n",
    "        \"\"\"Visualizza predizioni su sample.\"\"\"\n",
    "        indices = np.random.choice(len(X_np), min(n, len(X_np)), replace=False)\n",
    "        sample_images = X_np[indices]\n",
    "        sample_labels = y_np[indices]\n",
    "\n",
    "        X_t = torch.from_numpy(sample_images.transpose(0, 3, 1, 2) if sample_images.ndim == 4 and sample_images.shape[-1] in [1,3] else sample_images).float()\n",
    "        X_t = self._normalize(X_t)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_t.to(self.device))\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        pred_labels = probs.argmax(axis=1)\n",
    "\n",
    "        n_cols = 5\n",
    "        n_rows = (n + n_cols - 1) // n_cols\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "        axes = axes.flatten() if n > 1 else [axes]\n",
    "\n",
    "        for i in range(min(n, len(sample_images))):\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(sample_images[i])\n",
    "                tl, pl = sample_labels[i], pred_labels[i]\n",
    "                color = 'green' if tl == pl else 'red'\n",
    "                tn = self.class_names[tl] if self.class_names else str(tl)\n",
    "                pn = self.class_names[pl] if self.class_names else str(pl)\n",
    "                conf = probs[i][pl]\n",
    "                axes[i].set_title(f\"True: {tn}\\nPred: {pn} ({conf:.2f})\", color=color, fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "\n",
    "        for i in range(len(sample_images), len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.suptitle(f'Predizioni - {self.approccio}', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Visualizza learning curves.\"\"\"\n",
    "        if self.history is None:\n",
    "            raise ValueError(\"Nessuno storico disponibile\")\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        axes[0].plot(self.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in self.history:\n",
    "            axes[0].plot(self.history['val_loss'], label='Validation Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Loss durante Training')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3)\n",
    "\n",
    "        axes[1].plot(self.history['accuracy'], label='Training Accuracy')\n",
    "        if 'val_accuracy' in self.history:\n",
    "            axes[1].plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].set_title('Accuracy durante Training')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Salva il modello.\"\"\"\n",
    "        torch.save(self.model.state_dict(), filepath)\n",
    "        print(f\"Modello salvato in {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Carica il modello.\"\"\"\n",
    "        self.model.load_state_dict(torch.load(filepath, map_location=self.device))\n",
    "        print(f\"Modello caricato da {filepath}\")\n",
    "\n",
    "\n",
    "# ===== Test del sistema =====\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SISTEMA COMPUTER VISION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# FIX: usiamo X_train_norm e X_test_norm (CIFAR-10)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Test CNN Custom:\")\n",
    "print(\"=\" * 60)\n",
    "sistema_custom = SistemaComputerVision(approccio='cnn_custom')\n",
    "sistema_custom.build_model(input_shape=(3, 32, 32), num_classes=10)\n",
    "sistema_custom.compile_model()\n",
    "\n",
    "_wf_custom = os.path.join(WEIGHTS_DIR, 'nb05_sistema_custom.pt')\n",
    "if os.path.exists(_wf_custom):\n",
    "    sistema_custom.model.load_state_dict(torch.load(_wf_custom, map_location=device, weights_only=True))\n",
    "    print(f\"Loaded pretrained weights from {_wf_custom}\")\n",
    "else:\n",
    "    sistema_custom.train(\n",
    "        X_train_norm[:10000], y_train[:10000],\n",
    "        epochs=5, use_augmentation=True\n",
    "    )\n",
    "    torch.save(sistema_custom.model.state_dict(), _wf_custom)\n",
    "    print(f\"Saved weights to {_wf_custom}\")\n",
    "\n",
    "if sistema_custom.history is not None:\n",
    "    sistema_custom.plot_training_history()\n",
    "else:\n",
    "    print(\"Using pretrained weights - training curves not available\")\n",
    "metriche = sistema_custom.evaluate(\n",
    "    X_test_norm[:1000], y_test[:1000], class_names=class_names\n",
    ")\n",
    "sistema_custom.visualize_predictions(\n",
    "    X_test_norm[:1000], y_test[:1000], n=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Test Transfer Learning:\")\n",
    "print(\"=\" * 60)\n",
    "sistema_tl = SistemaComputerVision(\n",
    "    approccio='transfer_learning', base_model_name='VGG16'\n",
    ")\n",
    "sistema_tl.build_model(input_shape=(3, 32, 32), num_classes=10)\n",
    "sistema_tl.compile_model()\n",
    "\n",
    "_wf_tl = os.path.join(WEIGHTS_DIR, 'nb05_sistema_tl_finetuned.pt')\n",
    "if os.path.exists(_wf_tl):\n",
    "    sistema_tl.model.load_state_dict(torch.load(_wf_tl, map_location=device, weights_only=True))\n",
    "    print(f\"Loaded pretrained weights from {_wf_tl}\")\n",
    "else:\n",
    "    sistema_tl.train(\n",
    "        X_train_norm[:10000], y_train[:10000],\n",
    "        epochs=5, use_augmentation=False\n",
    "    )\n",
    "    torch.save(sistema_tl.model.state_dict(), os.path.join(WEIGHTS_DIR, 'nb05_sistema_tl_trained.pt'))\n",
    "    sistema_tl.fine_tune(\n",
    "        X_train_norm[:10000], y_train[:10000],\n",
    "        epochs=3, layers_to_unfreeze=4\n",
    "    )\n",
    "    torch.save(sistema_tl.model.state_dict(), _wf_tl)\n",
    "    print(f\"Saved weights to {_wf_tl}\")\n",
    "\n",
    "if sistema_tl.history is not None:\n",
    "    sistema_tl.plot_training_history()\n",
    "else:\n",
    "    print(\"Using pretrained weights - training curves not available\")\n",
    "metriche_tl = sistema_tl.evaluate(\n",
    "    X_test_norm[:1000], y_test[:1000], class_names=class_names\n",
    ")\n",
    "sistema_tl.visualize_predictions(\n",
    "    X_test_norm[:1000], y_test[:1000], n=10\n",
    ")\n",
    "\n",
    "# Confronto finale\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO FINALE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy CNN Custom: {metriche['accuracy']:.4f}\")\n",
    "print(f\"Accuracy Transfer Learning: {metriche_tl['accuracy']:.4f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## Conclusioni\n\nIn questo notebook abbiamo esplorato:\n\n- **Architettura CNN**: layer convoluzionali, pooling, feature hierarchies\n- **Implementazione CNN**: da semplice ad avanzata con CIFAR-10\n- **Data Augmentation**: per migliorare generalizzazione\n- **Transfer Learning**: VGG16, ResNet50, EfficientNet\n- **Fine-tuning**: scongelamento layer e re-training\n- **API Computer Vision**: deployment via REST API\n- **Visualizzazione**: feature maps per interpretabilita'\n\n### Concetti chiave da ricordare\n\n1. **CNN sono specializzate per immagini**: condivisione parametri e invarianza spaziale\n2. **Transfer Learning e' potentissimo**: richiede meno dati e tempo\n3. **Fine-tuning > Feature Extraction**: se hai abbastanza dati\n4. **Learning rate basso per fine-tuning**: evita di \"rompere\" pesi pre-trained\n5. **Data Augmentation e' essenziale**: per dataset piccoli\n6. **GlobalAveragePooling > Flatten**: meno parametri, meno overfitting\n\n### Workflow consigliato per nuovi progetti\n\n1. **Inizia con transfer learning**: modello pre-trained + classificatore custom\n2. **Train classificatore**: congela base model\n3. **Valuta performance**: se buone, stop qui\n4. **Se serve piu' accuracy**: fine-tune ultimi layer\n5. **Data augmentation**: sempre, specialmente se dataset piccolo\n6. **Solo se necessario**: train CNN da zero\n\n### Prossimi passi\n\nNel prossimo notebook affronteremo:\n- Natural Language Processing\n- Preprocessing testi\n- Modelli tradizionali (TF-IDF, Bag of Words)\n- Embeddings e Word2Vec\n\n### Risorse per approfondire\n\n- [CS231n: Convolutional Neural Networks - Stanford](http://cs231n.stanford.edu/)\n- [Deep Learning for Computer Vision - MIT](http://introtodeeplearning.com/)\n- [PyTorch Image Classification Tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n- [Transfer Learning with PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n- [EfficientNet Paper](https://arxiv.org/abs/1905.11946)"
   ]
  }
 ]
}