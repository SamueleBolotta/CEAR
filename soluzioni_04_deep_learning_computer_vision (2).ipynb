{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yFMbDb942Mz"
   },
   "source": [
    "# Deep Learning e Computer Vision - VERSIONE DOCENTE\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "Il **Deep Learning** è un sottoinsieme del Machine Learning basato su reti neurali artificiali con molteplici livelli (\"deep\" = profondo). Negli ultimi anni ha rivoluzionato campi come:\n",
    "- Computer Vision (riconoscimento immagini)\n",
    "- Natural Language Processing (traduzione, chatbot)\n",
    "- Speech Recognition (assistenti vocali)\n",
    "- Sistemi di raccomandazione\n",
    "- Guida autonoma\n",
    "\n",
    "### Perché Deep Learning?\n",
    "\n",
    "**Vantaggi rispetto al ML classico:**\n",
    "- **Apprendimento automatico delle feature**: non serve feature engineering manuale\n",
    "- **Performance su grandi dataset**: scala meglio con più dati\n",
    "- **Capacità di catturare pattern complessi**: gerarchie di rappresentazioni\n",
    "\n",
    "**Svantaggi:**\n",
    "- Richiede molti dati\n",
    "- Computazionalmente intensivo (serve GPU)\n",
    "- Meno interpretabile (\"black box\")\n",
    "- Rischio di overfitting se non gestito correttamente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXopqRz942M2"
   },
   "source": [
    "## 1. Che cos'è il Deep Learning\n",
    "\n",
    "### Dall'AI al Deep Learning\n",
    "\n",
    "```\n",
    "Intelligenza Artificiale (AI)\n",
    "    └── Machine Learning (ML)\n",
    "            └── Deep Learning (DL)\n",
    "```\n",
    "\n",
    "- **AI**: campo generale che studia macchine intelligenti\n",
    "- **ML**: subset di AI che impara dai dati senza programmazione esplicita\n",
    "- **DL**: subset di ML basato su reti neurali profonde\n",
    "\n",
    "### Evoluzione storica\n",
    "\n",
    "1. **1943**: McCulloch-Pitts, primo modello neurone artificiale\n",
    "2. **1958**: Perceptron di Rosenblatt\n",
    "3. **1986**: Backpropagation (Rumelhart, Hinton, Williams)\n",
    "4. **1998**: LeNet (Yann LeCun) per riconoscimento cifre\n",
    "5. **2006**: Renaissance del DL (Hinton)\n",
    "6. **2012**: AlexNet vince ImageNet, inizio dell'era moderna\n",
    "7. **2017+**: Transformers (BERT, GPT) rivoluzionano NLP\n",
    "\n",
    "### Fattori che hanno reso possibile il DL moderno\n",
    "\n",
    "1. **Big Data**: miliardi di immagini, testi, video disponibili\n",
    "2. **GPU**: calcolo parallelo massivo\n",
    "3. **Algoritmi migliorati**: ReLU, dropout, batch normalization\n",
    "4. **Framework**: TensorFlow, PyTorch rendono lo sviluppo accessibile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC7BtEsz42M3"
   },
   "source": [
    "## 2. Reti Neurali Artificiali\n",
    "\n",
    "### 2.1 Il Neurone Artificiale\n",
    "\n",
    "Un **neurone artificiale** (o perceptron) è l'unità base delle reti neurali.\n",
    "\n",
    "#### Componenti:\n",
    "\n",
    "1. **Input**: $x_1, x_2, ..., x_n$\n",
    "2. **Pesi**: $w_1, w_2, ..., w_n$ (parametri da apprendere)\n",
    "3. **Bias**: $b$ (parametro da apprendere)\n",
    "4. **Somma pesata**: $z = \\sum_{i=1}^{n} w_i x_i + b$\n",
    "5. **Funzione di attivazione**: $a = f(z)$\n",
    "6. **Output**: $a$\n",
    "\n",
    "#### Funzioni di attivazione comuni:\n",
    "\n",
    "**Sigmoid**: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "- Output in [0, 1]\n",
    "- Usata per probabilità\n",
    "- Problema: vanishing gradient\n",
    "\n",
    "**Tanh**: $\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$\n",
    "- Output in [-1, 1]\n",
    "- Zero-centered (meglio di sigmoid)\n",
    "\n",
    "**ReLU** (Rectified Linear Unit): $\\text{ReLU}(z) = \\max(0, z)$\n",
    "- Semplice e efficace\n",
    "- Standard per hidden layers\n",
    "- Risolve vanishing gradient\n",
    "\n",
    "**Softmax** (per output layer classificazione multi-classe):\n",
    "$$\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}$$\n",
    "\n",
    "### 2.2 Architettura di una Rete Neurale\n",
    "\n",
    "Una rete neurale è composta da **layer** (strati) di neuroni:\n",
    "\n",
    "1. **Input Layer**: riceve i dati\n",
    "2. **Hidden Layers**: uno o più strati intermedi\n",
    "3. **Output Layer**: produce le predizioni\n",
    "\n",
    "```\n",
    "Input → Hidden 1 → Hidden 2 → ... → Output\n",
    "```\n",
    "\n",
    "**Deep Neural Network**: rete con molti hidden layers (≥ 2)\n",
    "\n",
    "### 2.3 Forward Propagation\n",
    "\n",
    "Il processo di calcolare l'output dato un input:\n",
    "\n",
    "```\n",
    "Layer 1: a[1] = f(W[1] · x + b[1])\n",
    "Layer 2: a[2] = f(W[2] · a[1] + b[2])\n",
    "...\n",
    "Output:  ŷ = a[L]\n",
    "```\n",
    "\n",
    "### 2.4 Backpropagation e Training\n",
    "\n",
    "**Obiettivo**: minimizzare la loss function rispetto ai parametri\n",
    "\n",
    "1. **Forward pass**: calcola predizioni\n",
    "2. **Calcola loss**: $L(\\hat{y}, y)$\n",
    "3. **Backward pass**: calcola gradienti con chain rule\n",
    "4. **Update parametri**: $w := w - \\alpha \\frac{\\partial L}{\\partial w}$\n",
    "\n",
    "**Loss functions comuni:**\n",
    "- **Regressione**: Mean Squared Error (MSE)\n",
    "- **Classificazione binaria**: Binary Cross-Entropy\n",
    "- **Classificazione multi-classe**: Categorical Cross-Entropy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REpd4apt42M4"
   },
   "source": [
    "## 3. Setup: TensorFlow e Keras\n",
    "\n",
    "**TensorFlow** è un framework open-source di Google per deep learning.\n",
    "**Keras** è un'API ad alto livello integrata in TensorFlow per costruire reti neurali in modo semplice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_l9pfkj42M5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615463463,
     "user_tz": -60,
     "elapsed": 21363,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "30fa9b72-040d-4d76-8d3a-7a56ed2bad5d"
   },
   "outputs": [],
   "source": [
    "# Import librerie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Scikit-learn per preprocessing e metriche\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Impostazioni\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUODFAzt42M7"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Prima Rete Neurale: Classificazione con MNIST\n",
    "\n",
    "**MNIST** è un dataset classico di cifre scritte a mano (0-9):\n",
    "- 60,000 immagini di training\n",
    "- 10,000 immagini di test\n",
    "- Dimensione: 28x28 pixel in scala di grigi\n",
    "\n",
    "### 4.1 Caricamento Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "SHlAwRc-42M7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615465703,
     "user_tz": -60,
     "elapsed": 2237,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "364db6e8-4961-4a4b-a0aa-492418cfa9a4"
   },
   "outputs": [],
   "source": [
    "# Caricamento MNIST da torchvision\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "X_train = mnist_train.data.numpy()  # (60000, 28, 28)\n",
    "y_train = mnist_train.targets.numpy()\n",
    "X_test = mnist_test.data.numpy()\n",
    "y_test = mnist_test.targets.numpy()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nRange valori pixel: [{X_train.min()}, {X_train.max()}]\")\n",
    "print(f\"Classi: {np.unique(y_train)}\")\n",
    "\n",
    "# Visualizzazione esempi\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f\"Etichetta: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Esempi MNIST')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaNVXjp342M8"
   },
   "source": [
    "### 4.2 Preprocessing\n",
    "\n",
    "Per una rete neurale fully-connected:\n",
    "1. **Flatten**: trasformare immagini 28x28 in vettori 784\n",
    "2. **Normalizzazione**: scalare pixel da [0, 255] a [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9U83l7I42M8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615465972,
     "user_tz": -60,
     "elapsed": 266,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "2b30ab02-41ce-4910-bc22-3f9cef688402"
   },
   "outputs": [],
   "source": [
    "# Flatten: da (28, 28) a (784,)\n",
    "X_train_flat = X_train.reshape(-1, 28 * 28)\n",
    "X_test_flat = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(f\"Shape dopo flatten:\")\n",
    "print(f\"  Training: {X_train_flat.shape}\")\n",
    "print(f\"  Test: {X_test_flat.shape}\")\n",
    "\n",
    "# Normalizzazione\n",
    "X_train_norm = X_train_flat / 255.0\n",
    "X_test_norm = X_test_flat / 255.0\n",
    "\n",
    "print(f\"\\nRange dopo normalizzazione: [{X_train_norm.min():.2f}, {X_train_norm.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esercizio 1"
   ],
   "metadata": {
    "id": "q_PrQXZsVShq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# ESERCIZIO 1: Preprocessing e Analisi Dataset Fashion MNIST\n",
    "# ============================================================================\n",
    "# Task: Caricare, preprocessare e analizzare Fashion MNIST\n",
    "# Dataset: Fashion MNIST (70000 immagini 28x28, 10 classi di abbigliamento)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "\n",
    "# Caricamento dataset Fashion MNIST\n",
    "np.random.seed(123)\n",
    "fmnist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "fmnist_test = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "X_train_fmnist = fmnist_train.data.numpy()\n",
    "y_train_fmnist = fmnist_train.targets.numpy()\n",
    "X_test_fmnist = fmnist_test.data.numpy()\n",
    "y_test_fmnist = fmnist_test.targets.numpy()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Dataset Fashion MNIST\")\n",
    "print(f\"Train shape: {X_train_fmnist.shape}\")\n",
    "print(f\"Test shape: {X_test_fmnist.shape}\")\n",
    "print(f\"Range valori originali: [{X_train_fmnist.min()}, {X_train_fmnist.max()}]\")\n",
    "print(f\"Numero classi: {len(class_names)}\")\n",
    "\n",
    "# Visualizzazione esempi per classe\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = np.where(y_train_fmnist == i)[0][0]\n",
    "    ax.imshow(X_train_fmnist[idx], cmap='gray')\n",
    "    ax.set_title(class_names[i])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Flatten e normalizzazione\n",
    "X_train_flat_fmnist = X_train_fmnist.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test_flat_fmnist = X_test_fmnist.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "print(f\"\\nDopo preprocessing:\")\n",
    "print(f\"Train shape: {X_train_flat_fmnist.shape}, range: [{X_train_flat_fmnist.min():.2f}, {X_train_flat_fmnist.max():.2f}]\")\n",
    "print(f\"Test shape: {X_test_flat_fmnist.shape}\")\n",
    "\n",
    "# Step 2: Analisi distribuzione classi\n",
    "class_counts = pd.Series(y_train_fmnist).value_counts().sort_index()\n",
    "class_percentages = (class_counts / len(y_train_fmnist) * 100).round(2)\n",
    "distribution_df = pd.DataFrame({\n",
    "    'classe_id': class_counts.index,\n",
    "    'nome_classe': [class_names[i] for i in class_counts.index],\n",
    "    'conteggio': class_counts.values,\n",
    "    'percentuale': class_percentages.values\n",
    "})\n",
    "\n",
    "print(\"\\nDistribuzione classi:\")\n",
    "print(distribution_df)\n",
    "\n",
    "# Step 3: Analisi statistica pixel per classe\n",
    "stats_list = []\n",
    "for class_id in range(10):\n",
    "    class_images = X_train_fmnist[y_train_fmnist == class_id]\n",
    "    stats_list.append({\n",
    "        'classe_id': class_id,\n",
    "        'nome_classe': class_names[class_id],\n",
    "        'media_pixel': class_images.mean(),\n",
    "        'std_pixel': class_images.std(),\n",
    "        'min_pixel': class_images.min(),\n",
    "        'max_pixel': class_images.max()\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "print(\"\\nStatistiche pixel per classe:\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Step 4: Calcolo matrice di correlazione tra classi\n",
    "mean_images = []\n",
    "for class_id in range(10):\n",
    "    class_images_flat = X_train_flat_fmnist[y_train_fmnist == class_id]\n",
    "    mean_image = class_images_flat.mean(axis=0)\n",
    "    mean_images.append(mean_image)\n",
    "\n",
    "mean_images = np.array(mean_images)\n",
    "corr_matrix = np.corrcoef(mean_images)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlazione tra Classi (basata su immagini medie)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Visualizzazione varianza pixel\n",
    "pixel_variance = X_train_fmnist.reshape(-1, 784).var(axis=0)\n",
    "variance_heatmap = pixel_variance.reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(variance_heatmap, cmap='viridis')\n",
    "plt.colorbar(label='Varianza')\n",
    "plt.title('Varianza per Pixel (tutto il dataset)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPixel con varianza piu' alta: indice {pixel_variance.argmax()}, valore {pixel_variance.max():.2f}\")\n",
    "print(f\"Pixel con varianza piu' bassa: indice {pixel_variance.argmin()}, valore {pixel_variance.min():.2f}\")\n",
    "\n",
    "print(\"\\nEsercizio 1 completato!\")"
   ],
   "metadata": {
    "id": "QpmZJJ_wVTh0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615471270,
     "user_tz": -60,
     "elapsed": 5290,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "684e876b-ffca-41a1-fe97-57d11420d6ce"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYdFoc_J42M9"
   },
   "source": [
    "### 4.3 Costruzione del Modello\n",
    "\n",
    "Keras offre due API:\n",
    "1. **Sequential API**: per modelli lineari (layer dopo layer)\n",
    "2. **Functional API**: per architetture complesse\n",
    "\n",
    "Useremo la Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "8Ss2dkxY42M9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615472967,
     "user_tz": -60,
     "elapsed": 1692,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "48410ffc-cef8-4986-8588-d1cbe7551deb"
   },
   "outputs": [],
   "source": [
    "# Creazione modello\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "# Visualizzazione architettura\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal params: {total_params:,}\")\n",
    "print(f\"Trainable params: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjQKnSzn42M-"
   },
   "source": [
    "**Spiegazione dell'architettura:**\n",
    "\n",
    "1. **Hidden Layer 1**: 784 input → 128 neuroni con ReLU\n",
    "   - Parametri: (784 × 128) + 128 bias = 100,480\n",
    "\n",
    "2. **Hidden Layer 2**: 128 input → 64 neuroni con ReLU\n",
    "   - Parametri: (128 × 64) + 64 bias = 8,256\n",
    "\n",
    "3. **Output Layer**: 64 input → 10 neuroni con Softmax\n",
    "   - Parametri: (64 × 10) + 10 bias = 650\n",
    "   - Softmax produce probabilità per le 10 classi\n",
    "\n",
    "**Totale parametri trainabili: 109,386**\n",
    "\n",
    "### 4.4 Compilazione del Modello\n",
    "\n",
    "Prima del training, dobbiamo specificare:\n",
    "1. **Optimizer**: algoritmo di ottimizzazione (Adam è lo standard)\n",
    "2. **Loss function**: funzione da minimizzare\n",
    "3. **Metriche**: per monitorare il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSOOsCi_42M-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615472969,
     "user_tz": -60,
     "elapsed": 12,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "f7d04395-b325-4eb9-d882-abbc5a27ebba"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Modello compilato e pronto per il training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGAmKzvk42M-"
   },
   "source": [
    "**Note sulle loss functions:**\n",
    "\n",
    "- `sparse_categorical_crossentropy`: quando le label sono intere (0, 1, 2, ..., 9)\n",
    "- `categorical_crossentropy`: quando le label sono one-hot encoded\n",
    "- `binary_crossentropy`: per classificazione binaria\n",
    "\n",
    "### 4.5 Training del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ilj0IAD42M_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615487922,
     "user_tz": -60,
     "elapsed": 14953,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "45b2e811-01d7-4f4b-fc4b-add1086f58e1"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# Preparazione dati\n",
    "X_train_tensor = torch.FloatTensor(X_train_norm).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "# Split training/validation (80/20)\n",
    "n_val = int(len(X_train_tensor) * 0.2)\n",
    "indices = torch.randperm(len(X_train_tensor))\n",
    "train_indices = indices[n_val:]\n",
    "val_indices = indices[:n_val]\n",
    "\n",
    "X_tr = X_train_tensor[train_indices]\n",
    "y_tr = y_train_tensor[train_indices]\n",
    "X_val = X_train_tensor[val_indices]\n",
    "y_val = y_train_tensor[val_indices]\n",
    "\n",
    "train_dataset = TensorDataset(X_tr, y_tr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_acc = (val_predicted == y_val).sum().item() / len(y_val)\n",
    "\n",
    "    history['loss'].append(train_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} - loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}')\n",
    "\n",
    "print(\"\\nTraining completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc9ynQ4442M_"
   },
   "source": [
    "**Parametri di training:**\n",
    "\n",
    "- **epochs**: numero di passaggi completi sul dataset\n",
    "- **batch_size**: numero di sample processati prima di aggiornare i pesi\n",
    "  - Batch piccoli: più rumore, ma converge più velocemente\n",
    "  - Batch grandi: gradienti più stabili, ma serve più memoria\n",
    "- **validation_split**: frazione dei dati per validation\n",
    "\n",
    "### 4.6 Visualizzazione Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "a3XpmRSS42NA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615488421,
     "user_tz": -60,
     "elapsed": 482,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "fdceca3d-68c1-4f9a-8ff4-01793183531d"
   },
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['loss'], label='Training Loss')\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss durante Training')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['accuracy'], label='Training Accuracy')\n",
    "axes[1].plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy durante Training')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXmT6NlY42NA"
   },
   "source": [
    "### 4.7 Valutazione sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8e6qXdQL42NA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615492569,
     "user_tz": -60,
     "elapsed": 4147,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "840664db-ec65-48f8-e18c-8a81caeb2874"
   },
   "outputs": [],
   "source": [
    "# Valutazione\n",
    "X_test_tensor = torch.FloatTensor(X_test_norm).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor).item()\n",
    "    _, y_pred_tensor = torch.max(test_outputs, 1)\n",
    "    test_accuracy = (y_pred_tensor == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predizioni\n",
    "y_pred = y_pred_tensor.cpu().numpy()\n",
    "y_pred_proba = torch.softmax(test_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualizzazione predizioni\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    ax.imshow(X_test[idx], cmap='gray')\n",
    "\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    confidence = y_pred_proba[idx][pred_label]\n",
    "\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.2f})\", color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Predizioni su Test Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esercizio 2"
   ],
   "metadata": {
    "id": "exGxFvG8VX3B"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# ESERCIZIO 2: Costruzione e Training Rete Neurale Multi-Layer\n",
    "# ============================================================================\n",
    "# Task: Costruire rete neurale per classificazione binaria con diverse configurazioni\n",
    "# Dataset: MNIST binario - classificare cifre pari vs dispari (60000 campioni)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Preparazione dataset binario: pari (0) vs dispari (1)\n",
    "np.random.seed(456)\n",
    "torch.manual_seed(456)\n",
    "mnist_train_ex2 = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_test_ex2 = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "X_mnist = mnist_train_ex2.data.numpy()\n",
    "y_mnist = mnist_train_ex2.targets.numpy()\n",
    "X_test_mnist = mnist_test_ex2.data.numpy()\n",
    "y_test_mnist = mnist_test_ex2.targets.numpy()\n",
    "\n",
    "y_train_binary = (y_mnist % 2).astype(int)\n",
    "y_test_binary = (y_test_mnist % 2).astype(int)\n",
    "\n",
    "X_train_binary = X_mnist.reshape(-1, 784) / 255.0\n",
    "X_test_binary = X_test_mnist.reshape(-1, 784) / 255.0\n",
    "\n",
    "print(f\"Dataset MNIST Binario (Pari vs Dispari)\")\n",
    "print(f\"Train: {X_train_binary.shape}\")\n",
    "print(f\"Distribuzione: Pari={np.sum(y_train_binary==0)}, Dispari={np.sum(y_train_binary==1)}\")\n",
    "\n",
    "# Visualizzazione esempi\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(X_mnist[y_train_binary==0][i], cmap='gray')\n",
    "    axes[0, i].set_title(f'Pari: {y_mnist[y_train_binary==0][i]}')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(X_mnist[y_train_binary==1][i], cmap='gray')\n",
    "    axes[1, i].set_title(f'Dispari: {y_mnist[y_train_binary==1][i]}')\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Helper function for training binary models\n",
    "def train_binary_model(model, X_train_np, y_train_np, epochs=15, batch_size=128, val_split=0.2):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    X_t = torch.FloatTensor(X_train_np).to(device)\n",
    "    y_t = torch.FloatTensor(y_train_np).to(device)\n",
    "\n",
    "    n_val = int(len(X_t) * val_split)\n",
    "    indices = torch.randperm(len(X_t))\n",
    "    X_tr = X_t[indices[n_val:]]\n",
    "    y_tr = y_t[indices[n_val:]]\n",
    "    X_v = X_t[indices[:n_val]]\n",
    "    y_v = y_t[indices[:n_val]]\n",
    "\n",
    "    train_ds = TensorDataset(X_tr, y_tr)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for bx, by in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(bx).squeeze()\n",
    "            loss = criterion(out, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * bx.size(0)\n",
    "            predicted = (torch.sigmoid(out) > 0.5).float()\n",
    "            total += by.size(0)\n",
    "            correct += (predicted == by).sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(X_v).squeeze()\n",
    "            val_loss = criterion(val_out, y_v).item()\n",
    "            val_pred = (torch.sigmoid(val_out) > 0.5).float()\n",
    "            val_acc = (val_pred == y_v).sum().item() / len(y_v)\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f'  Epoch {epoch+1}/{epochs} - loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}')\n",
    "\n",
    "    return history\n",
    "\n",
    "# Step 1: Costruzione modello shallow (1 hidden layer)\n",
    "model_shallow = nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1)\n",
    ").to(device)\n",
    "\n",
    "print(\"Architettura Shallow:\")\n",
    "print(model_shallow)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_shallow.parameters()):,}')\n",
    "\n",
    "# Step 2: Costruzione modello deep (3 hidden layers)\n",
    "model_deep_ex2 = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nArchitettura Deep:\")\n",
    "print(model_deep_ex2)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_deep_ex2.parameters()):,}')\n",
    "\n",
    "# Step 3: Training entrambi i modelli\n",
    "print(\"\\nTraining Shallow Model...\")\n",
    "history_shallow = train_binary_model(model_shallow, X_train_binary, y_train_binary, epochs=15)\n",
    "\n",
    "print(\"\\nTraining Deep Model...\")\n",
    "history_deep = train_binary_model(model_deep_ex2, X_train_binary, y_train_binary, epochs=15)\n",
    "\n",
    "# Step 4: Confronto performance\n",
    "def evaluate_binary(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_t = torch.FloatTensor(X).to(device)\n",
    "        out = model(X_t).squeeze()\n",
    "        loss = nn.BCEWithLogitsLoss()(out, torch.FloatTensor(y).to(device)).item()\n",
    "        pred = (torch.sigmoid(out) > 0.5).float()\n",
    "        acc = (pred.cpu().numpy() == y).mean()\n",
    "    return loss, acc\n",
    "\n",
    "test_loss_shallow, test_acc_shallow = evaluate_binary(model_shallow, X_test_binary, y_test_binary)\n",
    "test_loss_deep, test_acc_deep = evaluate_binary(model_deep_ex2, X_test_binary, y_test_binary)\n",
    "\n",
    "train_acc_shallow = max(history_shallow['accuracy'])\n",
    "val_acc_shallow = max(history_shallow['val_accuracy'])\n",
    "train_acc_deep = max(history_deep['accuracy'])\n",
    "val_acc_deep = max(history_deep['val_accuracy'])\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'modello': 'Shallow',\n",
    "        'train_acc': train_acc_shallow,\n",
    "        'val_acc': val_acc_shallow,\n",
    "        'test_acc': test_acc_shallow,\n",
    "        'num_params': sum(p.numel() for p in model_shallow.parameters())\n",
    "    },\n",
    "    {\n",
    "        'modello': 'Deep',\n",
    "        'train_acc': train_acc_deep,\n",
    "        'val_acc': val_acc_deep,\n",
    "        'test_acc': test_acc_deep,\n",
    "        'num_params': sum(p.numel() for p in model_deep_ex2.parameters())\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFRONTO SHALLOW vs DEEP\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualizzazione learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history_shallow['accuracy'], label='Shallow Train', linestyle='--')\n",
    "axes[0].plot(history_shallow['val_accuracy'], label='Shallow Val', linestyle='--')\n",
    "axes[0].plot(history_deep['accuracy'], label='Deep Train')\n",
    "axes[0].plot(history_deep['val_accuracy'], label='Deep Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy: Shallow vs Deep')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_shallow['loss'], label='Shallow Train', linestyle='--')\n",
    "axes[1].plot(history_shallow['val_loss'], label='Shallow Val', linestyle='--')\n",
    "axes[1].plot(history_deep['loss'], label='Deep Train')\n",
    "axes[1].plot(history_deep['val_loss'], label='Deep Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Loss: Shallow vs Deep')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Analisi errori\n",
    "best_model_ex2 = model_deep_ex2 if test_acc_deep > test_acc_shallow else model_shallow\n",
    "best_name_ex2 = 'Deep' if test_acc_deep > test_acc_shallow else 'Shallow'\n",
    "\n",
    "best_model_ex2.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.FloatTensor(X_test_binary).to(device)\n",
    "    y_pred_probs = torch.sigmoid(best_model_ex2(X_test_t).squeeze()).cpu().numpy()\n",
    "y_pred_ex2 = (y_pred_probs > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test_binary, y_pred_ex2)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pari', 'Dispari'],\n",
    "            yticklabels=['Pari', 'Dispari'])\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title(f'Confusion Matrix - Modello {best_name_ex2}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nClassification Report - Modello {best_name_ex2}:')\n",
    "print(classification_report(y_test_binary, y_pred_ex2, target_names=['Pari', 'Dispari']))\n",
    "\n",
    "# Confronto parametri vs performance\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "models_data = comparison_df['modello'].values\n",
    "params = comparison_df['num_params'].values\n",
    "test_accs = comparison_df['test_acc'].values\n",
    "\n",
    "scatter = ax.scatter(params, test_accs, s=200, alpha=0.6, c=['blue', 'red'])\n",
    "for i, txt in enumerate(models_data):\n",
    "    ax.annotate(txt, (params[i], test_accs[i]), fontsize=12, ha='center')\n",
    "\n",
    "ax.set_xlabel('Numero Parametri')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Trade-off: Complessita vs Performance')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEsercizio 2 completato!\")"
   ],
   "metadata": {
    "id": "xWJ-IHkUVY7W",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615538722,
     "user_tz": -60,
     "elapsed": 46151,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "9ca0a693-bee3-4ca3-fb4e-2ade5901dbd4"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qmgm8zJ042NB"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Come Ridurre l'Overfitting\n",
    "\n",
    "L'**overfitting** si verifica quando il modello memorizza il training set invece di generalizzare.\n",
    "\n",
    "**Segnali di overfitting:**\n",
    "- Training accuracy alta, validation accuracy bassa\n",
    "- Gap crescente tra training e validation loss\n",
    "\n",
    "### 5.1 Dropout\n",
    "\n",
    "**Dropout** disattiva casualmente una frazione di neuroni durante il training, forzando la rete a non dipendere da singoli neuroni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "-6yiIe-u42NB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615538798,
     "user_tz": -60,
     "elapsed": 74,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "6b62dd9c-4194-45fa-da51-9ef622a3599a"
   },
   "outputs": [],
   "source": [
    "# Modello con Dropout\n",
    "model_dropout = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "criterion_dropout = nn.CrossEntropyLoss()\n",
    "optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=0.001)\n",
    "\n",
    "print(model_dropout)\n",
    "total_params = sum(p.numel() for p in model_dropout.parameters())\n",
    "print(f\"Total params: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twsB9ZE142NB"
   },
   "source": [
    "### 5.2 Regularization (L1/L2)\n",
    "\n",
    "**Regularization** penalizza pesi grandi, forzando il modello a usare tutti i neuroni in modo equilibrato.\n",
    "\n",
    "- **L1**: $\\lambda \\sum |w_i|$ (favorisce sparsità)\n",
    "- **L2**: $\\lambda \\sum w_i^2$ (favorisce pesi piccoli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpsl2Flx42NC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615538798,
     "user_tz": -60,
     "elapsed": 7,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "7cddac48-f275-42b6-e1ba-4b4c84e71ab1"
   },
   "outputs": [],
   "source": [
    "# Modello con L2 regularization (weight_decay nell'optimizer)\n",
    "model_reg = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "criterion_reg = nn.CrossEntropyLoss()\n",
    "# weight_decay corrisponde a L2 regularization\n",
    "optimizer_reg = optim.Adam(model_reg.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "print(\"Modello con L2 regularization creato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHqqzVR742NC"
   },
   "source": [
    "### 5.3 Early Stopping\n",
    "\n",
    "**Early Stopping** ferma il training quando la validation loss smette di migliorare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oFeibbW42NC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615566229,
     "user_tz": -60,
     "elapsed": 27433,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "15ec9774-e283-4c2e-8ab3-785b419da82e"
   },
   "outputs": [],
   "source": [
    "# Training con early stopping\n",
    "# Preparazione dati\n",
    "X_train_t = torch.FloatTensor(X_train_norm).to(device)\n",
    "y_train_t = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "n_val = int(len(X_train_t) * 0.2)\n",
    "indices_es = torch.randperm(len(X_train_t))\n",
    "X_tr_es = X_train_t[indices_es[n_val:]]\n",
    "y_tr_es = y_train_t[indices_es[n_val:]]\n",
    "X_val_es = X_train_t[indices_es[:n_val]]\n",
    "y_val_es = y_train_t[indices_es[:n_val]]\n",
    "\n",
    "train_ds_es = TensorDataset(X_tr_es, y_tr_es)\n",
    "train_loader_es = DataLoader(train_ds_es, batch_size=128, shuffle=True)\n",
    "\n",
    "# Early stopping manuale\n",
    "epochs = 20\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_state = None\n",
    "history_es = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_dropout.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader_es:\n",
    "        optimizer_dropout.zero_grad()\n",
    "        outputs = model_dropout(batch_X)\n",
    "        loss = criterion_dropout(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer_dropout.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model_dropout.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = model_dropout(X_val_es)\n",
    "        val_loss = criterion_dropout(val_out, y_val_es).item()\n",
    "        _, val_pred = torch.max(val_out, 1)\n",
    "        val_acc = (val_pred == y_val_es).sum().item() / len(y_val_es)\n",
    "\n",
    "    history_es['loss'].append(train_loss)\n",
    "    history_es['accuracy'].append(train_acc)\n",
    "    history_es['val_loss'].append(val_loss)\n",
    "    history_es['val_accuracy'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} - loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_state = {k: v.clone() for k, v in model_dropout.state_dict().items()}\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            model_dropout.load_state_dict(best_state)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_waZ4-342ND"
   },
   "source": [
    "### 5.4 Data Augmentation\n",
    "\n",
    "**Data Augmentation** aumenta artificialmente il dataset applicando trasformazioni alle immagini:\n",
    "- Rotazioni\n",
    "- Traslazioni\n",
    "- Zoom\n",
    "- Flip\n",
    "\n",
    "Questo aiuta il modello a generalizzare meglio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "xA9F-cha42ND",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615566692,
     "user_tz": -60,
     "elapsed": 461,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "9daea052-db04-4ce4-9fea-89a56fa1efeb"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation con torchvision.transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomAffine(degrees=0, scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Visualizzazione augmentation\n",
    "sample_img = X_train[0]  # (28, 28) numpy array\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title('Originale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Genera 9 versioni augmented\n",
    "sample_tensor = torch.from_numpy(sample_img).unsqueeze(0).to(torch.uint8)  # (1, 28, 28)\n",
    "for i in range(1, 10):\n",
    "    augmented = augmentation_transforms(sample_tensor)\n",
    "    axes[i].imshow(augmented.squeeze().numpy(), cmap='gray')\n",
    "    axes[i].set_title(f'Augmented {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pBJvuA542ND"
   },
   "source": [
    "### 5.5 Batch Normalization\n",
    "\n",
    "**Batch Normalization** normalizza gli input di ogni layer, stabilizzando e accelerando il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "Z-6SFB1B42NE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615566714,
     "user_tz": -60,
     "elapsed": 24,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "46f03479-4869-450a-fe7e-c42578cb1eb0"
   },
   "outputs": [],
   "source": [
    "# Modello con Batch Normalization\n",
    "model_bn = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "print(model_bn)\n",
    "total_params = sum(p.numel() for p in model_bn.parameters())\n",
    "print(f\"Total params: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlfR3F1L42NE"
   },
   "source": [
    "### 5.6 Confronto Tecniche Anti-Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "PBsTch9I42NE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615633303,
     "user_tz": -60,
     "elapsed": 66582,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "2240fcf4-5a1d-4c66-c9b8-a43949070870"
   },
   "outputs": [],
   "source": [
    "# Training da zero per confronto equo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_model_multiclass(model, X_train_np, y_train_np, epochs=10, batch_size=128, val_split=0.2, weight_decay=0.0):\n",
    "    \"\"\"Helper function per training modelli multiclasse.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "\n",
    "    X_t = torch.FloatTensor(X_train_np).to(device)\n",
    "    y_t = torch.LongTensor(y_train_np).to(device)\n",
    "\n",
    "    n_val = int(len(X_t) * val_split)\n",
    "    idx = torch.randperm(len(X_t))\n",
    "    X_tr, y_tr = X_t[idx[n_val:]], y_t[idx[n_val:]]\n",
    "    X_vl, y_vl = X_t[idx[:n_val]], y_t[idx[:n_val]]\n",
    "\n",
    "    train_ds = TensorDataset(X_tr, y_tr)\n",
    "    loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for bx, by in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_np, y_np):\n",
    "    \"\"\"Valuta un modello e ritorna accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_t = torch.FloatTensor(X_np).to(device)\n",
    "        y_t = torch.LongTensor(y_np).to(device)\n",
    "        out = model(X_t)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        acc = (pred == y_t).sum().item() / len(y_t)\n",
    "    return acc\n",
    "\n",
    "# Ricreo tutti i modelli da zero\n",
    "model_baseline_new = nn.Sequential(\n",
    "    nn.Linear(784, 128), nn.ReLU(),\n",
    "    nn.Linear(128, 64), nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "model_dropout_new = nn.Sequential(\n",
    "    nn.Linear(784, 128), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "model_reg_new = nn.Sequential(\n",
    "    nn.Linear(784, 128), nn.ReLU(),\n",
    "    nn.Linear(128, 64), nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "model_bn_new = nn.Sequential(\n",
    "    nn.Linear(784, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64), nn.ReLU(), nn.BatchNorm1d(64), nn.Dropout(0.3),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "# Training con stesse condizioni\n",
    "EPOCHS = 10\n",
    "risultati = []\n",
    "\n",
    "models_compare = {\n",
    "    'Baseline': (model_baseline_new, 0.0),\n",
    "    'Dropout': (model_dropout_new, 0.0),\n",
    "    'L2 Regularization': (model_reg_new, 0.001),\n",
    "    'Batch Normalization': (model_bn_new, 0.0)\n",
    "}\n",
    "\n",
    "for nome, (modello, wd) in models_compare.items():\n",
    "    print(f'Training {nome}...')\n",
    "    train_model_multiclass(modello, X_train_norm, y_train, epochs=EPOCHS, weight_decay=wd)\n",
    "    test_acc = evaluate_model(modello, X_test_norm, y_test)\n",
    "    risultati.append({\n",
    "        'Modello': nome,\n",
    "        'Test Accuracy': test_acc\n",
    "    })\n",
    "    print(f'  {nome}: {test_acc:.4f}')\n",
    "\n",
    "# Confronto risultati\n",
    "df_risultati = pd.DataFrame(risultati).sort_values(\n",
    "    'Test Accuracy', ascending=False\n",
    ")\n",
    "print(\"\\nConfronto Tecniche:\")\n",
    "print(df_risultati.to_string(index=False))\n",
    "\n",
    "# Visualizzazione\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(\n",
    "    df_risultati['Modello'],\n",
    "    df_risultati['Test Accuracy']\n",
    ")\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.title('Confronto Tecniche Anti-Overfitting')\n",
    "plt.xlim([0.9, 1.0])\n",
    "for i, v in enumerate(df_risultati['Test Accuracy']):\n",
    "    plt.text(v + 0.001, i, f'{v:.4f}', va='center')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esercizio 3"
   ],
   "metadata": {
    "id": "2WOExwGNVdAq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# ESERCIZIO 3: Tecniche di Regolarizzazione per Ridurre Overfitting\n",
    "# ============================================================================\n",
    "# Task: Confrontare Dropout, L2 Regularization e Batch Normalization\n",
    "# Dataset: CIFAR-10 subset con 2 classi (10000 campioni)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Caricamento subset CIFAR-10: solo classi 0 (airplane) e 1 (automobile)\n",
    "np.random.seed(789)\n",
    "torch.manual_seed(789)\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "X_cifar = cifar_train.data  # (50000, 32, 32, 3)\n",
    "y_cifar = np.array(cifar_train.targets)\n",
    "X_test_cifar = cifar_test.data\n",
    "y_test_cifar = np.array(cifar_test.targets)\n",
    "\n",
    "mask_train = (y_cifar == 0) | (y_cifar == 1)\n",
    "mask_test = (y_test_cifar == 0) | (y_test_cifar == 1)\n",
    "\n",
    "X_train_cifar = X_cifar[mask_train]\n",
    "y_train_cifar = y_cifar[mask_train]\n",
    "X_test_cifar_sub = X_test_cifar[mask_test]\n",
    "y_test_cifar_sub = y_test_cifar[mask_test]\n",
    "\n",
    "X_train_cifar = X_train_cifar.reshape(-1, 32*32*3) / 255.0\n",
    "X_test_cifar_sub = X_test_cifar_sub.reshape(-1, 32*32*3) / 255.0\n",
    "\n",
    "print(f\"Dataset CIFAR-10 Binario (Airplane vs Automobile)\")\n",
    "print(f\"Train: {X_train_cifar.shape}, Test: {X_test_cifar_sub.shape}\")\n",
    "print(f\"Distribuzione train: Airplane={np.sum(y_train_cifar==0)}, Auto={np.sum(y_train_cifar==1)}\")\n",
    "\n",
    "# Helper function for training binary CIFAR models with early stopping\n",
    "def train_binary_cifar(model, X_train_np, y_train_np, epochs=20, batch_size=128, val_split=0.2, patience=3, weight_decay=0.0):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "\n",
    "    X_t = torch.FloatTensor(X_train_np).to(device)\n",
    "    y_t = torch.FloatTensor(y_train_np.astype(np.float32)).to(device)\n",
    "\n",
    "    n_val = int(len(X_t) * val_split)\n",
    "    idx = torch.randperm(len(X_t))\n",
    "    X_tr, y_tr = X_t[idx[n_val:]], y_t[idx[n_val:]]\n",
    "    X_vl, y_vl = X_t[idx[:n_val]], y_t[idx[:n_val]]\n",
    "\n",
    "    train_ds = TensorDataset(X_tr, y_tr)\n",
    "    loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for bx, by in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(bx).squeeze()\n",
    "            loss = criterion(out, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * bx.size(0)\n",
    "            predicted = (torch.sigmoid(out) > 0.5).float()\n",
    "            total += by.size(0)\n",
    "            correct += (predicted == by).sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(X_vl).squeeze()\n",
    "            val_loss_val = criterion(val_out, y_vl).item()\n",
    "            val_pred = (torch.sigmoid(val_out) > 0.5).float()\n",
    "            val_acc = (val_pred == y_vl).sum().item() / len(y_vl)\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss_val)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        if val_loss_val < best_val_loss:\n",
    "            best_val_loss = val_loss_val\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                model.load_state_dict(best_state)\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "def evaluate_binary_cifar(model, X_np, y_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_t = torch.FloatTensor(X_np).to(device)\n",
    "        out = model(X_t).squeeze()\n",
    "        pred = (torch.sigmoid(out) > 0.5).float().cpu().numpy()\n",
    "        acc = (pred == y_np).mean()\n",
    "    return acc\n",
    "\n",
    "# Step 1: Modello baseline (senza regolarizzazione)\n",
    "model_baseline_c = nn.Sequential(\n",
    "    nn.Linear(3072, 256), nn.ReLU(),\n",
    "    nn.Linear(256, 128), nn.ReLU(),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)\n",
    "\n",
    "print(\"Modello Baseline:\")\n",
    "print(model_baseline_c)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_baseline_c.parameters()):,}')\n",
    "\n",
    "# Step 2: Modello con Dropout\n",
    "model_dropout_c = nn.Sequential(\n",
    "    nn.Linear(3072, 256), nn.ReLU(), nn.Dropout(0.4),\n",
    "    nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.4),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)\n",
    "\n",
    "# Step 3: Modello con L2 Regularization (weight_decay nell'optimizer)\n",
    "model_l2_c = nn.Sequential(\n",
    "    nn.Linear(3072, 256), nn.ReLU(),\n",
    "    nn.Linear(256, 128), nn.ReLU(),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)\n",
    "\n",
    "# Step 4: Modello con Batch Normalization\n",
    "model_bn_c = nn.Sequential(\n",
    "    nn.Linear(3072, 256), nn.ReLU(), nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)\n",
    "\n",
    "# Training tutti i modelli\n",
    "models_dict_c = {\n",
    "    'Baseline': (model_baseline_c, 0.0),\n",
    "    'Dropout': (model_dropout_c, 0.0),\n",
    "    'L2 Regularization': (model_l2_c, 0.01),\n",
    "    'Batch Normalization': (model_bn_c, 0.0)\n",
    "}\n",
    "\n",
    "histories_c = {}\n",
    "results_c = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MODELLI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, (model_c, wd) in models_dict_c.items():\n",
    "    print(f'\\nTraining {name}...')\n",
    "    history = train_binary_cifar(model_c, X_train_cifar, y_train_cifar, epochs=20, weight_decay=wd)\n",
    "    histories_c[name] = history\n",
    "\n",
    "    train_acc = max(history['accuracy'])\n",
    "    val_acc = max(history['val_accuracy'])\n",
    "    test_acc = evaluate_binary_cifar(model_c, X_test_cifar_sub, y_test_cifar_sub)\n",
    "    overfitting_gap = train_acc - val_acc\n",
    "\n",
    "    results_c.append({\n",
    "        'modello': name,\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'epochs': len(history['loss'])\n",
    "    })\n",
    "\n",
    "    print(f'{name}: Test Acc={test_acc:.4f}, Overfitting Gap={overfitting_gap:.4f}')\n",
    "\n",
    "results_df_c = pd.DataFrame(results_c).sort_values('test_acc', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFRONTO TECNICHE REGOLARIZZAZIONE\")\n",
    "print(\"=\"*70)\n",
    "print(results_df_c.to_string(index=False))\n",
    "\n",
    "# Step 5: Visualizzazione learning curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, history) in enumerate(histories_c.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(history['accuracy'], label='Train')\n",
    "    ax.plot(history['val_accuracy'], label='Validation')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confronto overfitting gap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "models_names = results_df_c['modello'].values\n",
    "gaps = results_df_c['overfitting_gap'].values\n",
    "colors = ['red' if gap > 0.05 else 'green' for gap in gaps]\n",
    "\n",
    "ax.barh(models_names, gaps, color=colors, alpha=0.7)\n",
    "ax.axvline(x=0.05, color='orange', linestyle='--', label='Soglia Overfitting')\n",
    "ax.set_xlabel('Overfitting Gap (Train Acc - Val Acc)')\n",
    "ax.set_title('Confronto Overfitting: Tecniche di Regolarizzazione')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_model_name_c = results_df_c.iloc[0]['modello']\n",
    "print(f'\\nMigliore tecnica: {best_model_name_c}')\n",
    "print(f\"Test Accuracy: {results_df_c.iloc[0]['test_acc']:.4f}\")\n",
    "print(f\"Overfitting Gap: {results_df_c.iloc[0]['overfitting_gap']:.4f}\")\n",
    "\n",
    "print(\"\\nEsercizio 3 completato!\")"
   ],
   "metadata": {
    "id": "PjbZvAxWVeXP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615680119,
     "user_tz": -60,
     "elapsed": 46814,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "391696e1-092a-419e-d9be-9cd7ac5b951c"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpAd_Vxp42NF"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Introduzione alla Computer Vision\n",
    "\n",
    "La **Computer Vision** è il campo dell'AI che permette ai computer di \"vedere\" e interpretare immagini.\n",
    "\n",
    "### 6.1 Rappresentazione Digitale delle Immagini\n",
    "\n",
    "Un'immagine digitale è una matrice di pixel:\n",
    "\n",
    "- **Grayscale**: matrice 2D (altezza × larghezza), valori 0-255\n",
    "- **RGB**: matrice 3D (altezza × larghezza × 3 canali)\n",
    "  - Canale Rosso (R)\n",
    "  - Canale Verde (G)\n",
    "  - Canale Blu (B)\n",
    "\n",
    "### 6.2 Task Principali di Computer Vision\n",
    "\n",
    "1. **Image Classification**: assegnare una label all'immagine\n",
    "2. **Object Detection**: localizzare e classificare oggetti multipli\n",
    "3. **Semantic Segmentation**: classificare ogni pixel\n",
    "4. **Instance Segmentation**: segmentare singole istanze di oggetti\n",
    "5. **Face Recognition**: identificare persone\n",
    "6. **Pose Estimation**: rilevare posizioni corporee\n",
    "\n",
    "### 6.3 Evoluzione della Computer Vision\n",
    "\n",
    "**Era Pre-Deep Learning (fino al 2012):**\n",
    "- Feature engineering manuale\n",
    "- SIFT, HOG, SURF\n",
    "- Classificatori tradizionali (SVM, Random Forest)\n",
    "\n",
    "**Era Deep Learning (2012-oggi):**\n",
    "- CNN apprendono feature automaticamente\n",
    "- Transfer Learning con modelli pre-trained\n",
    "- State-of-the-art: Vision Transformers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epFGdCcp42NF"
   },
   "source": [
    "## 7. Progetto di Computer Vision Classico\n",
    "\n",
    "Prima dell'era del deep learning, i progetti di CV seguivano questa pipeline:\n",
    "\n",
    "```\n",
    "Immagine → Feature Extraction → Classificatore ML → Predizione\n",
    "```\n",
    "\n",
    "Implementeremo un classificatore di cifre usando feature estratte manualmente.\n",
    "\n",
    "### 7.1 Feature Extraction: HOG (Histogram of Oriented Gradients)\n",
    "\n",
    "**HOG** descrive un'immagine attraverso la distribuzione delle direzioni dei gradienti:\n",
    "1. Calcola gradienti dei pixel\n",
    "2. Divide l'immagine in celle\n",
    "3. Crea istogramma delle direzioni dei gradienti per cella\n",
    "4. Normalizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "YkDcF7w-42NG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615680256,
     "user_tz": -60,
     "elapsed": 117,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "f1669ec2-e4d7-4a5e-da2b-93219d082780"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimensione feature vector HOG: 144\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Estrazione HOG features da un'immagine\n",
    "sample_img = X_train[0]\n",
    "\n",
    "# Calcola HOG\n",
    "features, hog_image = hog(\n",
    "    sample_img,\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    "    visualize=True\n",
    ")\n",
    "\n",
    "print(f\"Dimensione feature vector HOG: {len(features)}\")\n",
    "\n",
    "# Visualizzazione\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title('Immagine Originale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "axes[1].imshow(hog_image_rescaled, cmap='gray')\n",
    "axes[1].set_title('HOG Features Visualizzate')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZgPs7NS42NG"
   },
   "source": [
    "### 7.2 Estrazione Feature per tutto il Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kmqo-3C42NG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615683291,
     "user_tz": -60,
     "elapsed": 3023,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "5feb5d0b-49ea-4ed8-a2ed-bc7a70c48395"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estrazione HOG features...\n",
      "Shape HOG features training: (10000, 144)\n",
      "Shape HOG features test: (2000, 144)\n",
      "Estrazione completata\n"
     ]
    }
   ],
   "source": [
    "def extract_hog_features(images):\n",
    "    \"\"\"\n",
    "    Estrae HOG features da un array di immagini.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "\n",
    "    for img in images:\n",
    "        features = hog(\n",
    "            img,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2),\n",
    "            visualize=False\n",
    "        )\n",
    "        features_list.append(features)\n",
    "\n",
    "    return np.array(features_list)\n",
    "\n",
    "\n",
    "# Estrazione per un subset (per velocità)\n",
    "print(\"Estrazione HOG features...\")\n",
    "n_samples = 10000\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train[:n_samples])\n",
    "X_test_hog = extract_hog_features(X_test[:2000])\n",
    "y_train_subset = y_train[:n_samples]\n",
    "y_test_subset = y_test[:2000]\n",
    "\n",
    "print(f\"Shape HOG features training: {X_train_hog.shape}\")\n",
    "print(f\"Shape HOG features test: {X_test_hog.shape}\")\n",
    "print(\"Estrazione completata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_Ca42RQ42NH"
   },
   "source": [
    "### 7.3 Classificazione con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "io9JG7tc42NH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615686501,
     "user_tz": -60,
     "elapsed": 3221,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "981242f0-7389-4d89-cf26-1acad6d8830a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training SVM...\n",
      "Training completato\n",
      "\n",
      "Accuracy SVM con HOG: 0.9455\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       175\n",
      "           1       0.97      0.99      0.98       234\n",
      "           2       0.93      0.98      0.96       219\n",
      "           3       0.95      0.93      0.94       207\n",
      "           4       0.94      0.94      0.94       217\n",
      "           5       0.96      0.93      0.94       179\n",
      "           6       0.93      0.95      0.94       178\n",
      "           7       0.94      0.93      0.93       205\n",
      "           8       0.91      0.91      0.91       192\n",
      "           9       0.95      0.91      0.93       194\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.94      0.94      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training SVM\n",
    "print(\"Training SVM...\")\n",
    "svm_classifier = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "svm_classifier.fit(X_train_hog, y_train_subset)\n",
    "print(\"Training completato\")\n",
    "\n",
    "# Predizioni\n",
    "y_pred_svm = svm_classifier.predict(X_test_hog)\n",
    "\n",
    "# Valutazione\n",
    "accuracy_svm = accuracy_score(y_test_subset, y_pred_svm)\n",
    "print(f\"\\nAccuracy SVM con HOG: {accuracy_svm:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_subset, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsvYfeYj42NH"
   },
   "source": [
    "### 7.4 Confronto: Approccio Classico vs Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "R72HAR6O42NZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615686663,
     "user_tz": -60,
     "elapsed": 138,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "a4918a65-54cd-4a0a-f168-b99b9cb25aa9"
   },
   "outputs": [],
   "source": [
    "# Confronto equo: valutazione entrambi sullo stesso test set (2000 campioni)\n",
    "# L'SVM e' stato valutato su X_test[:2000], quindi valutiamo anche la NN sullo stesso subset\n",
    "X_test_subset_tensor = torch.FloatTensor(X_test_norm[:2000]).to(device)\n",
    "y_test_subset_tensor = torch.LongTensor(y_test[:2000]).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_subset_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    nn_accuracy_subset = (predicted == y_test_subset_tensor).sum().item() / len(y_test_subset_tensor)\n",
    "\n",
    "# Confronto performance\n",
    "confronto = pd.DataFrame({\n",
    "    'Approccio': ['HOG + SVM (Classico)', 'Neural Network (Deep Learning)'],\n",
    "    'Accuracy': [accuracy_svm, nn_accuracy_subset],\n",
    "    'Feature Engineering': ['Manuale (HOG)', 'Automatico (appreso)'],\n",
    "    'Parametri': ['~100K (SVM)', '~109K (NN)']\n",
    "})\n",
    "\n",
    "print(\"Confronto Approcci (su 2000 campioni di test):\")\n",
    "print(confronto.to_string(index=False))\n",
    "\n",
    "# Visualizzazione\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(confronto['Approccio'], confronto['Accuracy'], color=['coral', 'steelblue'])\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Confronto: Computer Vision Classica vs Deep Learning')\n",
    "plt.xlim([0.85, 1.0])\n",
    "for i, v in enumerate(confronto['Accuracy']):\n",
    "    plt.text(v + 0.005, i, f'{v:.4f}', va='center')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV6ftRq742NZ"
   },
   "source": [
    "**Osservazioni:**\n",
    "\n",
    "1. **Performance**: Le reti neurali tipicamente superano gli approcci classici su dataset complessi\n",
    "2. **Feature Engineering**: DL elimina il bisogno di feature engineering manuale\n",
    "3. **Dati**: DL richiede più dati, approcci classici possono funzionare con dataset piccoli\n",
    "4. **Interpretabilità**: HOG + SVM è più interpretabile\n",
    "5. **Computazione**: DL richiede più risorse (GPU)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esercizio 4"
   ],
   "metadata": {
    "id": "9TBJZlKDViZL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# ESERCIZIO 4: Architetture Neurali Avanzate per Image Classification\n",
    "# ============================================================================\n",
    "# Task: Confrontare diverse architetture neurali su task di classificazione multi-classe\n",
    "# Dataset: Fashion MNIST completo (70000 immagini, 10 classi)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Caricamento dataset\n",
    "np.random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "fmnist_train_ex4 = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "fmnist_test_ex4 = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "X_fmnist = fmnist_train_ex4.data.numpy().reshape(-1, 784) / 255.0\n",
    "y_fmnist = fmnist_train_ex4.targets.numpy()\n",
    "X_test_fmnist = fmnist_test_ex4.data.numpy().reshape(-1, 784) / 255.0\n",
    "y_test_fmnist = fmnist_test_ex4.targets.numpy()\n",
    "\n",
    "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Dataset Fashion MNIST Completo\")\n",
    "print(f\"Train: {X_fmnist.shape}, Test: {X_test_fmnist.shape}\")\n",
    "print(f\"Classi: {len(class_names)}\")\n",
    "\n",
    "# Helper function for training with early stopping and LR reduction\n",
    "def train_fmnist_model(model, X_train_np, y_train_np, epochs=25, batch_size=256, val_split=0.15, patience_es=5, patience_lr=3, weight_decay=0.0):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "    X_t = torch.FloatTensor(X_train_np).to(device)\n",
    "    y_t = torch.LongTensor(y_train_np).to(device)\n",
    "\n",
    "    n_val = int(len(X_t) * val_split)\n",
    "    idx = torch.randperm(len(X_t))\n",
    "    X_tr, y_tr = X_t[idx[n_val:]], y_t[idx[n_val:]]\n",
    "    X_vl, y_vl = X_t[idx[:n_val]], y_t[idx[:n_val]]\n",
    "\n",
    "    train_ds = TensorDataset(X_tr, y_tr)\n",
    "    loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for bx, by in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * bx.size(0)\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            total += by.size(0)\n",
    "            correct += (predicted == by).sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(X_vl)\n",
    "            val_loss = criterion(val_out, y_vl).item()\n",
    "            _, val_pred = torch.max(val_out, 1)\n",
    "            val_acc = (val_pred == y_vl).sum().item() / len(y_vl)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience_es:\n",
    "                model.load_state_dict(best_state)\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "def evaluate_fmnist(model, X_np, y_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_t = torch.FloatTensor(X_np).to(device)\n",
    "        y_t = torch.LongTensor(y_np).to(device)\n",
    "        out = model(X_t)\n",
    "        loss = nn.CrossEntropyLoss()(out, y_t).item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        acc = (pred == y_t).sum().item() / len(y_t)\n",
    "    return loss, acc\n",
    "\n",
    "# Step 1: Architettura Wide (pochi layer, molti neuroni)\n",
    "model_wide = nn.Sequential(\n",
    "    nn.Linear(784, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(256, 10)\n",
    ").to(device)\n",
    "\n",
    "print(\"Architettura WIDE:\")\n",
    "print(model_wide)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_wide.parameters()):,}')\n",
    "\n",
    "# Step 2: Architettura Deep (molti layer, meno neuroni)\n",
    "model_deep_ex4 = nn.Sequential(\n",
    "    nn.Linear(784, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "    nn.Linear(128, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "    nn.Linear(128, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "    nn.Linear(128, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "    nn.Linear(128, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nArchitettura DEEP:\")\n",
    "print(model_deep_ex4)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_deep_ex4.parameters()):,}')\n",
    "\n",
    "# Step 3: Architettura Pyramid (neuroni decrescenti)\n",
    "model_pyramid = nn.Sequential(\n",
    "    nn.Linear(784, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(0.25),\n",
    "    nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(0.25),\n",
    "    nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.25),\n",
    "    nn.Linear(128, 64), nn.ReLU(), nn.BatchNorm1d(64), nn.Dropout(0.25),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nArchitettura PYRAMID:\")\n",
    "print(model_pyramid)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_pyramid.parameters()):,}')\n",
    "\n",
    "# Step 4: Architettura Residual-like (con skip connections)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResidualModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            ResidualBlock(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model_residual = ResidualModel().to(device)\n",
    "\n",
    "print(\"\\nArchitettura RESIDUAL-LIKE:\")\n",
    "print(model_residual)\n",
    "print(f'Parametri: {sum(p.numel() for p in model_residual.parameters()):,}')\n",
    "\n",
    "# Training tutti i modelli\n",
    "models_dict_ex4 = {\n",
    "    'Wide': model_wide,\n",
    "    'Deep': model_deep_ex4,\n",
    "    'Pyramid': model_pyramid,\n",
    "    'Residual': model_residual\n",
    "}\n",
    "\n",
    "histories_ex4 = {}\n",
    "results_ex4 = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ARCHITETTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, model_arch in models_dict_ex4.items():\n",
    "    print(f'\\nTraining {name}...')\n",
    "    history = train_fmnist_model(model_arch, X_fmnist, y_fmnist, epochs=25)\n",
    "    histories_ex4[name] = history\n",
    "\n",
    "    test_loss, test_acc = evaluate_fmnist(model_arch, X_test_fmnist, y_test_fmnist)\n",
    "    n_params = sum(p.numel() for p in model_arch.parameters())\n",
    "\n",
    "    results_ex4.append({\n",
    "        'architettura': name,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'num_params': n_params,\n",
    "        'epochs_trained': len(history['loss'])\n",
    "    })\n",
    "\n",
    "    print(f\"{name}: Test Acc={test_acc:.4f}, Params={n_params:,}, Epochs={len(history['loss'])}\")\n",
    "\n",
    "results_df_ex4 = pd.DataFrame(results_ex4).sort_values('test_accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFRONTO ARCHITETTURE\")\n",
    "print(\"=\"*70)\n",
    "print(results_df_ex4.to_string(index=False))\n",
    "\n",
    "# Step 5: Analisi performance migliore architettura\n",
    "best_arch_name = results_df_ex4.iloc[0]['architettura']\n",
    "best_model_arch = models_dict_ex4[best_arch_name]\n",
    "\n",
    "best_model_arch.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.FloatTensor(X_test_fmnist).to(device)\n",
    "    y_pred_probs = torch.softmax(best_model_arch(X_test_t), dim=1).cpu().numpy()\n",
    "y_pred_ex4 = np.argmax(y_pred_probs, axis=1)\n",
    "cm = confusion_matrix(y_test_fmnist, y_pred_ex4)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title(f'Confusion Matrix - Architettura {best_arch_name}')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nClassification Report - {best_arch_name}:')\n",
    "print(classification_report(y_test_fmnist, y_pred_ex4, target_names=class_names))\n",
    "\n",
    "# Visualizzazione learning curves per tutte le architetture\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, history) in enumerate(histories_ex4.items()):\n",
    "    axes[idx].plot(history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[idx].plot(history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    axes[idx].set_xlabel('Epoch')\n",
    "    axes[idx].set_ylabel('Accuracy')\n",
    "    axes[idx].set_title(f'{name} Architecture')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confronto parametri vs performance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "archs = results_df_ex4['architettura'].values\n",
    "params = results_df_ex4['num_params'].values / 1000\n",
    "test_accs = results_df_ex4['test_accuracy'].values\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange'][:len(archs)]\n",
    "scatter = ax.scatter(params, test_accs, s=300, alpha=0.6, c=colors)\n",
    "\n",
    "for i, txt in enumerate(archs):\n",
    "    ax.annotate(txt, (params[i], test_accs[i]), fontsize=11, ha='center')\n",
    "\n",
    "ax.set_xlabel('Numero Parametri (K)')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Trade-off: Complessita Architettura vs Performance')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confronto finale\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(archs))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x, test_accs, width, label='Test Accuracy', alpha=0.8, color=colors)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Architettura')\n",
    "ax.set_title('Confronto Performance Architetture')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(archs)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMigliore architettura: {best_arch_name}\")\n",
    "print(f\"Test Accuracy: {results_df_ex4.iloc[0]['test_accuracy']:.4f}\")\n",
    "print(f\"Parametri: {results_df_ex4.iloc[0]['num_params']:,}\")\n",
    "\n",
    "print(\"\\nEsercizio 4 completato!\")"
   ],
   "metadata": {
    "id": "l7uxD23UVkEX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615810088,
     "user_tz": -60,
     "elapsed": 123423,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "aa5acf54-5480-42a1-8ac6-8a5246d5c508"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rctn7BsM42NZ"
   },
   "source": [
    "## 8. Esercitazione: Sistema di Riconoscimento Completo\n",
    "\n",
    "Implementa un sistema completo di riconoscimento cifre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RnSzVgDV42Na",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771615825516,
     "user_tz": -60,
     "elapsed": 15422,
     "user": {
      "displayName": "Samuele Bolotta",
      "userId": "18417992837056093821"
     }
    },
    "outputId": "25c4df47-d826-432a-cb47-a2373db671ad"
   },
   "outputs": [],
   "source": [
    "class SistemaRiconoscimentoCifre:\n",
    "    \"\"\"\n",
    "    Sistema completo per riconoscimento cifre.\n",
    "    Supporta sia approccio classico che deep learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, approccio='deep_learning'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            approccio: 'classico' o 'deep_learning'\n",
    "        \"\"\"\n",
    "        self.approccio = approccio\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.is_trained = False\n",
    "        self.device = device\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"\n",
    "        Preprocessa un'immagine singola.\n",
    "\n",
    "        Args:\n",
    "            image: array numpy (28, 28)\n",
    "\n",
    "        Returns:\n",
    "            Immagine preprocessata\n",
    "        \"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            features = hog(\n",
    "                image,\n",
    "                orientations=9,\n",
    "                pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2),\n",
    "                visualize=False\n",
    "            )\n",
    "            return features\n",
    "        else:\n",
    "            img_normalized = image / 255.0\n",
    "            return img_normalized.flatten()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Costruisce il modello in base all'approccio.\n",
    "        \"\"\"\n",
    "        if self.approccio == 'classico':\n",
    "            self.model = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
    "\n",
    "        elif self.approccio == 'deep_learning':\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(784, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(64, 10)\n",
    "            ).to(self.device)\n",
    "\n",
    "    def train(self, X_train_imgs, y_train_labels, X_val=None, y_val=None, epochs=10):\n",
    "        \"\"\"\n",
    "        Addestra il modello.\n",
    "        \"\"\"\n",
    "        print(f'Preprocessing {len(X_train_imgs)} immagini per {self.approccio}...')\n",
    "        X_train_processed = np.array([self.preprocess_image(img) for img in X_train_imgs])\n",
    "\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "\n",
    "        print(f'Training {self.approccio}...')\n",
    "\n",
    "        if self.approccio == 'classico':\n",
    "            self.model.fit(X_train_processed, y_train_labels)\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "            X_t = torch.FloatTensor(X_train_processed).to(self.device)\n",
    "            y_t = torch.LongTensor(y_train_labels).to(self.device)\n",
    "\n",
    "            n_val = int(len(X_t) * 0.2)\n",
    "            idx = torch.randperm(len(X_t))\n",
    "            X_tr, y_tr = X_t[idx[n_val:]], y_t[idx[n_val:]]\n",
    "            X_val_split, y_val_split = X_t[idx[:n_val]], y_t[idx[:n_val]]\n",
    "\n",
    "            train_ds = TensorDataset(X_tr, y_tr)\n",
    "            loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "            # Early stopping\n",
    "            patience = 3\n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            best_state = None\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                self.model.train()\n",
    "                for bx, by in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    out = self.model(bx)\n",
    "                    loss = criterion(out, by)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                if epochs >= 5:\n",
    "                    self.model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        val_out = self.model(X_val_split)\n",
    "                        val_loss = criterion(val_out, y_val_split).item()\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        patience_counter = 0\n",
    "                        best_state = {k: v.clone() for k, v in self.model.state_dict().items()}\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= patience:\n",
    "                            self.model.load_state_dict(best_state)\n",
    "                            break\n",
    "\n",
    "        self.is_trained = True\n",
    "        print('Training completato')\n",
    "\n",
    "    def predict(self, images):\n",
    "        \"\"\"\n",
    "        Predice le cifre per un batch di immagini.\n",
    "\n",
    "        Args:\n",
    "            images: array di immagini\n",
    "\n",
    "        Returns:\n",
    "            Array di predizioni\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Il modello deve essere addestrato prima\")\n",
    "\n",
    "        X_processed = np.array([self.preprocess_image(img) for img in images])\n",
    "\n",
    "        if self.approccio == 'classico':\n",
    "            return self.model.predict(X_processed)\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                X_t = torch.FloatTensor(X_processed).to(self.device)\n",
    "                outputs = self.model(X_t)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "            return predictions.cpu().numpy()\n",
    "\n",
    "    def evaluate(self, X_test_imgs, y_test_labels):\n",
    "        \"\"\"\n",
    "        Valuta il modello sul test set.\n",
    "\n",
    "        Returns:\n",
    "            Dizionario con metriche\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test_imgs)\n",
    "\n",
    "        accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "        cm = confusion_matrix(y_test_labels, y_pred)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predetto')\n",
    "        plt.ylabel('Reale')\n",
    "        plt.title(f'Confusion Matrix - {self.approccio}')\n",
    "        plt.show()\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': classification_report(y_test_labels, y_pred)\n",
    "        }\n",
    "\n",
    "    def visualizza_predizioni(self, images, n=10):\n",
    "        \"\"\"\n",
    "        Visualizza predizioni su sample di immagini.\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Il modello deve essere addestrato prima\")\n",
    "\n",
    "        indices = np.random.choice(len(images), min(n, len(images)), replace=False)\n",
    "        sample_images = images[indices]\n",
    "\n",
    "        predictions = self.predict(sample_images)\n",
    "\n",
    "        n_cols = 5\n",
    "        n_rows = (n + n_cols - 1) // n_cols\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 3 * n_rows))\n",
    "        if hasattr(axes, 'flatten'):\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, (img, pred) in enumerate(zip(sample_images, predictions)):\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(img, cmap='gray')\n",
    "                axes[i].set_title(f'Predizione: {pred}', fontsize=12, fontweight='bold')\n",
    "                axes[i].axis('off')\n",
    "\n",
    "        for i in range(len(sample_images), len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.suptitle(f'Predizioni - {self.approccio}', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Test del sistema\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SISTEMA RICONOSCIMENTO CIFRE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Test Approccio Deep Learning:\")\n",
    "print(\"=\" * 60)\n",
    "sistema_dl = SistemaRiconoscimentoCifre(approccio='deep_learning')\n",
    "sistema_dl.train(X_train[:10000], y_train[:10000], epochs=15)\n",
    "metriche_dl = sistema_dl.evaluate(X_test[:1000], y_test[:1000])\n",
    "print(f\"\\nAccuracy: {metriche_dl['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Test Approccio Classico:\")\n",
    "print(\"=\" * 60)\n",
    "sistema_classico = SistemaRiconoscimentoCifre(approccio='classico')\n",
    "sistema_classico.train(X_train[:5000], y_train[:5000])\n",
    "metriche_classico = sistema_classico.evaluate(X_test[:1000], y_test[:1000])\n",
    "print(f\"\\nAccuracy: {metriche_classico['accuracy']:.4f}\")\n",
    "\n",
    "# Visualizzazione\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Visualizzazione Predizioni\")\n",
    "print(\"=\" * 60)\n",
    "sistema_dl.visualizza_predizioni(X_test, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHYdn4HB42Na"
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusioni\n",
    "\n",
    "In questo notebook abbiamo esplorato:\n",
    "\n",
    "- **Fondamenti Deep Learning**: definizione, evoluzione storica\n",
    "- **Reti Neurali Artificiali**: neuroni, layer, forward/backpropagation\n",
    "- **TensorFlow e Keras**: implementazione pratica di reti neurali\n",
    "- **Training**: compilazione, fit, valutazione\n",
    "- **Tecniche anti-overfitting**: Dropout, L2 Regularization, Early Stopping, Data Augmentation, Batch Normalization\n",
    "- **Computer Vision**: rappresentazione immagini, task principali\n",
    "- **Approccio classico**: HOG + SVM\n",
    "- **Confronto**: CV classica vs Deep Learning\n",
    "\n",
    "### Prossimi passi\n",
    "\n",
    "Nel prossimo notebook approfondiremo:\n",
    "- **Convolutional Neural Networks (CNN)**: architetture specifiche per immagini\n",
    "- **Transfer Learning**: uso di modelli pre-trained\n",
    "- **Fine-tuning**: adattamento di foundation models\n",
    "- **Progetti avanzati di Computer Vision**\n",
    "\n",
    "### Concetti chiave da ricordare\n",
    "\n",
    "1. **Deep Learning = Feature Learning**: il modello impara le feature automaticamente\n",
    "2. **Overfitting è il nemico principale**: usa sempre tecniche di regolarizzazione\n",
    "3. **Normalizzazione è essenziale**: scala sempre i dati\n",
    "4. **Validation set è obbligatorio**: per monitorare overfitting\n",
    "5. **L'approccio classico ha ancora valore**: su dataset piccoli o quando serve interpretabilità\n",
    "\n",
    "### Risorse per approfondire\n",
    "\n",
    "- [Deep Learning Specialization - Andrew Ng](https://www.coursera.org/specializations/deep-learning)\n",
    "- [TensorFlow Documentation](https://www.tensorflow.org/)\n",
    "- [Keras Documentation](https://keras.io/)\n",
    "- [Deep Learning Book - Goodfellow et al.](https://www.deeplearningbook.org/)\n",
    "- [CS231n: Computer Vision - Stanford](http://cs231n.stanford.edu/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}